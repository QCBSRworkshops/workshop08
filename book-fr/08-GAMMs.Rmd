# Intro rapide aux modèles additifs généralisés à effets mixtes (GAMMs)

Lorsque les observations ne sont pas indépendantes, les GAMs peuvent
être utilisés soit pour incorporer:

- une structure de corrélation pour modéliser les résidus autocorrélés, comme:
 - le modèle autorégressif (AR, en anglais _autoregressive_); 
 - le modèle avec moyenne mobile (MA, en anglais _moving average_); ou,
 - une combinaison des deux modèles (ARMA, en anglais, _autoregressive moving average_).
- des effets aléatoires qui modélisent l'indépendance entre les observations d'un même site.

En plus de changer la fonction de base, nous pouvons aussi complexifier
le modèle en intégrant une structure d'auto-corrélation (ou même des
effets mixtes) en utilisant les fonctions `gamm()` dans la librairie `mgcv`. Bien que nous ne l'utilisions pas ici, la librairie [`gamm4`](https://cran.r-project.org/web/packages/gamm4/gamm4.pdf) peut également être utilisé pour estimer des modèles GAMMs dans R.

## L'autocorrelation des résidus

**L'autocorrélation des résidus** désigne le degré de corrélation entre les résidus (les différences entre les valeurs réelles et les valeurs prédites) d'un modèle de série temporelle.

En d'autres termes, s'il y a autocorrélation des résidus dans un modèle de série temporelle, cela signifie qu'il existe un modèle ou une relation entre les résidus à un moment donné et les résidus à d'autres moments.

L'autocorrélation des résidus est généralement mesurée à l'aide des graphiques **ACF (fonction d'autocorrélation)** et **pACF (fonction d'autocorrélation partielle)**, qui montrent la corrélation entre les résidus à différents retards. 

#### La fonction d'autocorrélation 

La fonction d'autocorrélation (ACF) d'une série temporelle stationnaire peut être définie à l'aide de l'équation suivante :

$$ACF(k) = Corr(Y_t, Y_{t-k})$$
où $Y_t$ est la valeur de la série temporelle au temps $t$, $Y_{t-k}$ est la valeur de la série temporelle au temps $t-k$, et $Corr()$ est le coefficient de corrélation entre deux variables aléatoires.

En d'autres termes, l'ACF($k$) est la corrélation entre les valeurs de la série temporelle $Y_t$ et $Y_{t-k}$, où $k$ est le décalage entre les deux points dans le temps. L'ACF est une mesure de l'intensité de la corrélation entre chaque valeur de la série temporelle et ses valeurs décalées à différents moments.

#### La fonction d'autocorrélation partielle

La fonction d'autocorrélation partielle (pACF) d'une série temporelle stationnaire peut être définie à l'aide de la formule récursive suivante :

$$pACF(1) = Corr(Y_1, Y_2)$$

$$pACF(k) = [ Corr(Y_k, Y_{k+1} - \hat{\phi}{k,1}Y{k}) ] / [ Corr(Y_1, Y_2 - \hat{\phi}_{1,1}Y_1) ]$$

pour $k > 1$

où $Y_t$ est la valeur de la série temporelle au temps $t$, $\hat{\phi}{k,1}$, $\hat{\phi}{1,1}$, $...$ $\hat{\phi}{k-1,k-1}$ sont les coefficients du modèle autorégressif d'ordre $k-1$ ajusté à la série temporelle, et $Corr()$ est le coefficient de corrélation entre deux variables aléatoires.

En d'autres termes, le pACF($k$) est la corrélation entre les valeurs des séries temporelles $Y_k$ et $Y_{k+j}$ après suppression de l'influence des décalages intermédiaires $Y_{k+1}, Y_{k+2}, ..., Y_{k+j-1}$ à l'aide d'un modèle autorégressif d'ordre $k-1$. 
Le pACF mesure la corrélation entre $Y_k$ et $Y_{k+j}$ après avoir éliminé l'effet de tout délai intermédiaire plus court.

Si les graphiques **ACF** ou **pACF** montrent des corrélations significatives à des retards non nuls, il y a des preuves d'autocorrélation des résidus et le modèle peut devoir être modifié ou amélioré pour mieux capturer les modèles sous-jacents dans les données.

Voyons comment cela fonctionne avec notre modèle `year_gam`!

Pour commencer, nous allons jeter un coup d'œil à un modèle avec de l'autocorrélation temporelle dans les résidus. Revenons au modèle
de la température de Nottingham pour vérifier si les résidus sont corrélés en faisant appel à la fonction (partielle) d'autocorrélation.

```{r, echo = TRUE, eval = FALSE}
par(mfrow = c(1,2))
acf(resid(year_gam), lag.max = 36, main = "ACF")
pacf(resid(year_gam), lag.max = 36, main = "pACF")
```

Dans le graphique ACF, la région ombrée en bleu représente l'intervalle de confiance et les lignes rouges en pointillé représentent les limites de la signification statistique.

La __fonction d'autocorrelaton__ (ACF; première figure) évalue la corrélation croisée d'une série temporelle entre points à différents décalages (donc, la similarité entre observations progressivement décalés).

En contraste, la __fonction partielle d'autocorrelation__ (PACF: deuxième figure) évalue la corrélation croisée d'une série temporelle entre points à différents décalages, après avoir contrôlé les valeurs de la série temporelle à tous les décalages plus courts.

Les graphiques ACF et pACF sont donc utilisés pour identifier le temps nécessaire avant que les observations ne sont plus autocorrélées.

Les graphiques des fonctions d'autocorrélation suggèrent qu'un modèle AR de faible ordre est nécessaire (avec un ou deux intervalles de temps décalés).

Nous pouvons tester cet hypothèse en ajoutant des structures d'autocorrelation au modèle de température de Nottingham. Créons un modèle `AR(1)` (corrélation à 1 intervalle de temps décalé), et un modèle `AR(2)` (corrélation à 2 intervalles de temps décalés), et comparons-les avec AIC pour déterminer le modèle le mieux ajusté.

```{r}
df <- data.frame(nottem, nottem_year, nottem_month)

year_gam <- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"), data = df)

year_gam_AR1 <- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"),
                     correlation = corARMA(form = ~ 1|nottem_year, p = 1),
                     data = df)

year_gam_AR2 <- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"),
                     correlation = corARMA(form = ~ 1|nottem_year, p = 2),
                     data = df)
```

Quel modèle est mieux ajusté?

```{r}
AIC(year_gam$lme, year_gam_AR1$lme, year_gam_AR2$lme)
```

Le modèle avec la structure AR(1) donne un meilleur ajustement comparé au premier modèle (`year_gam`), il y a très peu d'amélioration en passant au `AR(2)`. Il est donc préférable d'inclure uniquement la structure `AR(1)` dans notre modèle.

## Modélisation avec effets mixtes

Comme nous l'avons vu dans la section précédente, `bs` spécifie la
fonction de base sous-jacente. Pour les facteurs aléatoires (origine et
pente linéaire), nous utilisons `bs = "re"` et pour les pentes
aléatoires non linéaires, nous utilisons `bs = "fs"`.

__Trois types d'effets aléatoires différents__ sont possibles lors de
l'utilisation des GAMMs (où `fac` représente une variable qualitative
utilisée pou l'effet aléatoire et `x0` est un effet quantitatif fixe) :

-   *interceptes aléatoires* ajustent la hauteur des termes du modèle
    avec une valeur constante de pente : `s(fac, bs = "re")`
-   *pentes aléatoires* ajustent la pente d'une variable explicative
    numérique: `s(fac, x0, bs = "re")`
-   *surfaces lisses aléatoires* ajustent la tendance d'une prédiction
    numérique de façon non linéaire: `s(x0, fac, bs = "fs", m = 1)` où
    l'argument $m=1$ met une plus grande pénalité au lissage qui
    s'éloigne de 0, ce qui entraîne un retrait vers la moyenne.

:::explanation
Pour plus de détails sur les effets aléatoires, voir l'[Atelier 7](https://r.qcbs.ca/fr/workshops/r-workshop-07/).
:::

:::noway
Ceci est une introduction (très!) brève aux effets aléatoires dans les GAMMs. Pour plus de détails, nous recommandons _fortement_ @pedersen2019hierarchical, un article très accessible qui décrit plusieurs façons de spécifier des GAMMs pour répondre à des questions écologiques.
:::

### GAMM avec un intercepte aléatoire

Nous allons utiliser `gamSim()` pour générer un ensemble de données, cette fois-ci avec un effet aléatoire. Ensuite, nous construirons un modèle avec un intercepte aléatoire en utilisant `fac` comme facteur aléatoire.

```{r}
# Simuler des données
gam_data2 <- gamSim(eg = 6)
head(gam_data2)
```

```{r}
# Rouler un modèle avec intercepte aléatoire
gamm_intercept <- gam(y ~ s(x0) + s(fac, bs = "re"), data = gam_data2, method = "REML")

# Voir la sortie du modèle
summary(gamm_intercept)$s.table
```

Notez qu'il y a maintenant un terme aléatoire dans le sommaire du modèle. Vous pouvez visualiser les intercepts aléatoires pour chaque niveau de `fac` comme ceci:

```{r}
plot(gamm_intercept, select = 2)
# select = 2 parce que le terme aléatoire se trouve sur la 2e ligne du tableau sommaire.
```

Nous pouvons également utiliser la fonction `plot_smooth` pour visualiser le modèle, qui nous permet de visualisés des
effets sommés d'un GAM (basé sur les prédictions). Cette fonction permet également de supprimer les effets aléatoires en définissant `rm.ranef = TRUE`.

On peut premièrement visualiser l'effet combiné de `x0` sans les niveaux de l'effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l'effet aléatoire `fac`:

```{r, results='hide', fig.width=10, fig.height=6}
par(mfrow = c(1,2), cex = 1.1)

# Visualiser les effets combinés de x0 (sans effets aléatoires)
plot_smooth(gamm_intercept, view = "x0", rm.ranef = TRUE,
            main = "intercept + s(x1)")

# Visualiser chaque niveau de l'effet aléatoire
plot_smooth(gamm_intercept, view = "x0", rm.ranef = FALSE,
            cond = list(fac="1"),
            main = "... + s(fac)", col = 'orange', ylim = c(0,25))
plot_smooth(gamm_intercept, view = "x0", rm.ranef = FALSE,
            cond = list(fac = "2"),
            add = TRUE, col = 'red')
plot_smooth(gamm_intercept, view="x0", rm.ranef = FALSE,
            cond = list(fac = "3"),
            add = TRUE, col = 'purple')
plot_smooth(gamm_intercept, view="x0", rm.ranef = FALSE,
            cond = list(fac = "4"),
            add = TRUE, col = 'turquoise')
```


### GAMM avec une pente aléatoire

Ensuite, spécifions un modèle avec une pente aléatoire:

```{r}
gamm_slope <- gam(y ~ s(x0) + s(x0, fac, bs = "re"), data = gam_data2, method = "REML")

summary(gamm_slope)$s.table
```

On peut encore une fois visualiser l'effet combiné de `x0` sans les niveaux de l'effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l'effet aléatoire `fac`:

```{r, results='hide', fig.width=10, fig.height=6}
par(mfrow = c(1,2), cex = 1.1)

# Visualiser les effets combinés de x0 (sans effets aléatoires)
plot_smooth(gamm_slope, view = "x0", rm.ranef = TRUE,
            main = "intercept + s(x1)")

# Visualiser chaque niveau de l'effet aléatoire
plot_smooth(gamm_slope, view = "x0", rm.ranef = FALSE,
            cond = list(fac="1"),
            main = "... + s(fac, x0)", col = 'orange', ylim = c(0,25))
plot_smooth(gamm_slope, view = "x0", rm.ranef = FALSE,
            cond = list(fac = "2"),
            add = TRUE, col = 'red')
plot_smooth(gamm_slope, view="x0", rm.ranef = FALSE,
            cond = list(fac = "3"),
            add = TRUE, col = 'purple')
plot_smooth(gamm_slope, view="x0", rm.ranef = FALSE,
            cond = list(fac = "4"),
            add = TRUE, col = 'turquoise')
```


### GAMM avec un intercept et une pente aléatoire

On peut aussi inclure un intercept et une pente aléatoire.

```{r}
gamm_int_slope <- gam(y ~ s(x0) + s(fac, bs = "re") + s(fac, x0, bs = "re"),
                      data = gam_data2, method = "REML")

summary(gamm_int_slope)$s.table
```

On peut encore une fois visualiser l'effet combiné de `x0` sans les niveaux de l'effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l'effet aléatoire `fac`:

```{r, results='hide', fig.width=10, fig.height=6}
par(mfrow = c(1,2), cex = 1.1)

# Visualiser les effets combinés de x0 (sans effets aléatoires)
plot_smooth(gamm_int_slope, view = "x0", rm.ranef = TRUE,
            main = "intercept + s(x1)")

# Visualiser chaque niveau de l'effet aléatoire
plot_smooth(gamm_int_slope, view = "x0", rm.ranef = FALSE,
            cond = list(fac="1"),
            main = "... + s(fac) + s(fac, x0)", col = 'orange', ylim = c(0,25))
plot_smooth(gamm_int_slope, view = "x0", rm.ranef = FALSE,
            cond = list(fac = "2"),
            add = TRUE, col = 'red')
plot_smooth(gamm_int_slope, view="x0", rm.ranef = FALSE,
            cond = list(fac = "3"),
            add = TRUE, col = 'purple')
plot_smooth(gamm_int_slope, view="x0", rm.ranef = FALSE,
            cond = list(fac = "4"),
            add = TRUE, col = 'turquoise')
```

Notez que la pente aléatoire est statique dans ce cas:

```{r}
plot(gamm_int_slope, select=3)
# select = 3 parce que la pente aléatoire est sur la troisième ligne de notre tableau sommaire.
```

### GAMM avec une surface lisse aléatoire

Finalement, spécifions un modèle avec une surface lisse aléatoire.

```{r}
gamm_smooth <- gam(y ~ s(x0) + s(x0, fac, bs = "fs", m = 1),
                   data = gam_data2, method = "REML")

summary(gamm_smooth)$s.table
```

Si la pente aléatoire variait selon `x0`, on verrait différentes courbes pour chaque niveau:

```{r, echo = TRUE}
plot(gamm_smooth, select=1)
# select = 1 parce que la surface lisse aléatoire est sur la première ligne de notre tableau sommaire.
```

On peut encore une fois visualiser l'effet combiné de `x0` sans les niveaux de l'effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l'effet aléatoire `fac`:

```{r, results='hide', fig.width=10, fig.height=6}
par(mfrow = c(1,2), cex = 1.1)

# Visualiser les effets combinés de x0 (sans effets aléatoires)
plot_smooth(gamm_smooth, view = "x0", rm.ranef = TRUE,
            main = "intercept + s(x1)")

# Visualiser chaque niveau de l'effet aléatoire
plot_smooth(gamm_smooth, view = "x0", rm.ranef = FALSE,
            cond = list(fac="1"),
            main = "... + s(fac) + s(fac, x0)", col = 'orange', ylim = c(0,25))
plot_smooth(gamm_smooth, view = "x0", rm.ranef = FALSE,
            cond = list(fac = "2"),
            add = TRUE, col = 'red')
plot_smooth(gamm_smooth, view="x0", rm.ranef = FALSE,
            cond = list(fac = "3"),
            add = TRUE, col = 'purple')
plot_smooth(gamm_smooth, view="x0", rm.ranef = FALSE,
            cond = list(fac = "4"),
            add = TRUE, col = 'turquoise')
```


### Comparaison de GAMM

Tous les GAMMs de cette section peuvent être comparé avec `AIC()` pour trouver le modèle le mieux ajusté:

```{r}
AIC(gamm_intercept, gamm_slope, gamm_int_slope, gamm_smooth)
```

Le meilleur modèle de ces trois modèles serait donc le GAMM avec un intercept aléatoire.
