[["index.html", "Atelier 8 : Modèles additifs généralisés en R Série d’ateliers R du CSBQ Préface 0.1 Code de conduit 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 8 : Modèles additifs généralisés en R Série d’ateliers R du CSBQ Développé et maintenu par les contributeurs et contributrices de la Série d’ateliers R du CSBQ1. 2023-01-13 17:05:24 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduit La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Cet atelier a été développé à l’origine par Eric Pedersen et Zofia Taranu, et originalement révisé en français by Cédric Frenette Dussault. Depuis 2014, plusieurs membres du CSBQ ont contribué à développer et à mettre à jour cet atelier collaborativement sur une base régulière, dans le cadre du Prix d’apprentissage et de développement du Centre de science de la biodiversité du Québec. Ces membres sont: Daniel Schoenig, Laurie Maynard, Marie-Hélène Brice, Kevin Cazelles, Pedro Henrique P. Braga, Esteban Gongora, Linley Sherin, Eric Pedersen, Zofia Taranu, Cédric Frenette Dussault, Emmanuelle Chrétien, Vincent Fugère. 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. Les contributeurs et contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage L’objectif de l’atelier d’aujourd’hui sera d’examiner ce que nous entendons par un modèle non-linéaire et comment les GAMs (modèles additifs généralisés) nous permettent de modéliser les relations non-linéaires. Nous examinerons également comment tracer et interpréter ces relations non-linéaires, comment ajouter des interactions, comment prendre en compte la non-indépendance des données (e.g. erreurs autocorrélées) et comment inclure des effets aléatoires en se basant sur les ateliers précédents. Enfin, nous allons brièvement aborder la mécanique derrière le fonctionnement des GAMs. Nous vous recommandons d’avoir une certaine expérience de R, en particulier de la consultation de données et d’objets dans des scripts R, et une connaissance de base de la régression linéaire avant de suivre cet atelier. Plus spécifiquement, cet atelier portera sur comment: Utiliser la librairie mgcv pour modéliser les relations non linéaires Évaluer la sortie d’un GAM afin de mieux comprendre nos données Utiliser des tests pour déterminer si nos relations correspondent à des modèles non linéaires ou linéaires Ajouter des interactions non linéaires entre les variables explicatives Comprendre l’idée d’une fonction de base (basis function) et la raison pour laquelle ça rend les GAMs si puissants ! Comment modéliser la dépendance dans les données (autocorrélation, structure hiérarchique) en utilisant les GAMMs "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Tout le matériel de l’atelier se trouve sur r.qcbs.ca/fr/workshops/r-workshop-08/. Cela inclut un script R qui rassemble tous les morceaux de code présentés dans ce livre. Pour cet atelier, nous travaillerons avec les jeux de données suivants : ISIT.csv Vous devriez également vous assurer que vous avez téléchargé, installé et chargé les librairies R suivants: ggplot2 itsadug mgcv install.packages(&quot;ggplot2&quot;) install.packages(&quot;mgcv&quot;) install.packages(&quot;itsadug&quot;) library(ggplot2) library(mgcv) library(itsadug) "],["intro-linear-models.html", "Chapitre 3 Le modèle linéaire… et où il échoue", " Chapitre 3 Le modèle linéaire… et où il échoue Que veut-on dire par “modèle linéaire”? La régression est la base des statistiques. La régression linéaire est ce que la plupart des gens apprennent avant tout en statistiques et est parmi les méthodes les plus performantes. Elle nous permet de modéliser une variable réponse en fonction de facteurs prédictifs et d’une erreur résiduelle. Comme on a vu dans l’Atelier 4: Modèles linéaires, le modèle linéaire fait quatre suppositions importantes: Relation linéaire entre les variables de réponse et les variables prédicteurs: \\[y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\] L’erreur est distribuée normalement: \\[\\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^2)\\] La variance des erreurs est constante Chaque erreur est indépendante des autres (homoscédasticité) Un modèle linéaire peut parfois s’adapter à certains types de réponses non linéaires (par exemple \\(x^2\\)), mais cette approche repose fortement sur des décisions qui peuvent être soit arbitraires, soit bien informées, et est beaucoup moins flexible que l’utilisation d’un modèle additif. Par exemple, ce modèle linéaire à prédicteurs multiples peut traiter une réponse non linéaire, mais devient rapidement difficile à interpréter et à maîtriser: \\[y_i = \\beta_0 + \\beta_1x_{1,i}+\\beta_2x_{2,i}+\\beta_3x_{3,i}+...+\\beta_kx_{k,i} + \\epsilon_i\\] Les modèles linéaires fonctionnent très bien dans certains cas spécifiques où tous ces critères sont respectés: En réalité, il est souvent impossible de respecter ces critères. Dans de nombreux cas, les modèles linéaires sont inappropriés: Alors, comment résoudre ce problème ? Pour répondre à cette question, nous devons d’abord considérer ce que le modèle de régression tente de faire. Un modèle linéaire essaye d’ajuster la meilleure droite qui passe au milieu des données sans sur-ajuster les données, ce qui se produirait si nous tracions simplement une ligne entre chaque point et ses voisins. En revanche, les modèles additifs (GAM) ajustent une fonction de lissage non-linéaire à travers les données, tout en contrôlant le degré de courbure de la ligne our éviter un ajustement excessif. Les modèles additifs peuvent donc capturer des relations non linéaires en ajustant une fonction lisse à travers les données, plutôt qu’une ligne droite. Nous reviendrons plus tard sur le degré de courbure de la ligne! "],["introduction-aux-gams.html", "Chapitre 4 Introduction aux GAMs 4.1 Test de linéarité 4.2 Défi 1", " Chapitre 4 Introduction aux GAMs Utilisons un exemple pour démontrer la différence entre une régression linéaire et un modèle additif. Nous allons utiliser le jeu de données ISIT. Ce jeu de donnée comporte des mesures de bioluminescence en relation à la profondeur (depth), la station de rechercher et la saison (Season). isit &lt;- read.csv(&quot;data/ISIT.csv&quot;) head(isit) ## SampleDepth Sources Station Time Latitude Longitude Xkm Ykm Month Year ## 1 517 28.73 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 2 582 27.90 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 3 547 23.44 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 4 614 18.33 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 5 1068 12.38 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 6 1005 11.23 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## BottomDepth Season Discovery RelativeDepth ## 1 3939 1 252 3422 ## 2 3939 1 252 3357 ## 3 3939 1 252 3392 ## 4 3939 1 252 3325 ## 5 3939 1 252 2871 ## 6 3939 1 252 2934 Prenons que les données de la deuxième saison pour l’instant: isit2 &lt;- subset(isit, Season == 2) Commençons par essayer d’ajuster un modèle de régression linéaire à la relation entre Sources et SampleDepth. Nous pouvons utiliser la commande gam() de la librairie mgcv pour modéliser une régression par les moindres carrés. Nous verrons plus loin comment utiliser gam() pour spécifier un terme lissé et non linéaire. linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2) summary(linear_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ SampleDepth ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 30.9021874 0.7963891 38.80 &lt;2e-16 *** ## SampleDepth -0.0083450 0.0003283 -25.42 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## R-sq.(adj) = 0.588 Deviance explained = 58.9% ## GCV = 60.19 Scale est. = 59.924 n = 453 Le modèle linéaire explique une bonne partie de la variance de notre jeu de données ( \\(R_{adj}\\) = 0.588), ce qui veut dire que notre modèle est super bon, non? Voyons comment notre modèle cadre avec les données: data_plot &lt;- ggplot(data = isit2, aes(y = Sources, x = SampleDepth)) + geom_point() + geom_line(aes(y = fitted(linear_model)), colour = &quot;red&quot;, size = 1.2) + theme_bw() ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. data_plot Les suppositions de la régression linéaire énumérées dans le Chapitre 4 sont-elles satisfaites dans ce cas? Comme vous l’avez peut-être remarqué, nous ne respectons pas les conditions du modèle linéaire: Il existe une forte relation non linéaire entre Sources et SampleDepth. L’erreur n’est pas normalement distribuée. La variance de l’erreur n’est pas homoscédastique. Les erreurs ne sont pas indépendantes les unes des autres. Comme nous l’avons brièvement mentionné au Chapitre 2, nous pouvons spécifier manuellement un modèle linéaire avec plusieurs variables prédicteurs pour essayer de prendre en compte cette réponse non linéaire. Par exemple, nous pourrions essayer de construire ce modèle linéaire avec plusieurs prédicteurs: \\[y_i = \\beta_0 + \\beta_1(x_{1,i}) + \\beta_2(x_{2,i}) + ... + \\epsilon\\] Cependant, l’ajustement de ce modèle serait déterminé manuellement sur la base de décisions prises lors de la modélisation, et deviendrait rapidement difficile à utiliser. Un des grands avantages d’utiliser un GAM est que la forme optimale de la non-linéarité, i.e. le degré de lissage de \\(f(x)\\) est contrôlée en utilisant une régression pénalisée qui est déterminée automatiquement est déterminée automatiquement selon la méthode d’ajustement (généralement le maximum de vraisemblance ou maximum likelihood). Nous reviendrons sur ceci un peu plus tard, mais brièvement, les GAMs sont une forme non paramétrique de la régression où le \\(\\beta x_i\\) d’une régression linéaire est remplacé par une fonction de lissage des variables explicatives, \\(f(x_i)\\), et le modèle devient : \\[y_i = f(x_i) + \\epsilon_i\\] où \\(y_i\\) est la variable réponse, \\(x_i\\) est la covariable, et \\(f\\) est la fonction lissage. Étant donné que la fonction de lissage \\(f(x_i)\\) est non linéaire et locale, l’ampleur de l’effet de la variable explicative peut varier en fonction de la relation entre la variable et la réponse. Autrement dit, contrairement à un coefficient fixe \\(\\beta x_i\\), la fonction \\(f\\) peut changer tout au long du gradient \\(x_i\\). Le degré de lissage de \\(f\\) est contrôlée en utilisant une régression pénalisée qui est déterminée automatiquement à l’aide d’une méthode de validation croisée généralisée (GCV) de la librairie mgcv (S. N. Wood 2006). Nous pouvons essayer de construire un modèle plus approprié en ajustant les données avec un terme lissé (non-linéaire). Dans mgcv::gam(), les termes lissés sont spécifiés par des expressions de la forme s(x), où \\(x\\) est la variable prédictive non linéaire que nous voulons lisser. Dans ce cas, nous voulons appliquer une fonction de lissage à SampleDepth. gam_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2) summary(gam_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(SampleDepth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.8937 0.2471 52.17 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.908 8.998 214.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.81 Deviance explained = 81.4% ## GCV = 28.287 Scale est. = 27.669 n = 453 La variance expliquée par notre modèle a augmenté de plus de 20% (\\(R_{adj}\\) = 0.81)! Lorsque nous comparons l’ajustement des modèles linéaire (rouge) et non linéaire (bleu), il est clair que ce dernier cadre mieux avec nos données: data_plot &lt;- data_plot + geom_line(aes(y = fitted(gam_model)), colour = &quot;blue&quot;, size = 1.2) data_plot Rappel: Contrairement à un coefficient fixe \\(\\beta\\), la fonction de lissage peut changer tout au long du gradient \\(x\\). La librairie mgcv comprend également une fonction plot qui, par défaut, nous permet de visualiser la non-linéarité du modèle. plot(gam_model) 4.1 Test de linéarité Comment tester si le modèle non linéaire offre une amélioration significative par rapport au modèle linéaire? On peut utiliser gam() et AIC() pour tester si une supposition de linéarité est justifiée. Pour ceci, on peut comparer la performance d’un modèle linéaire contenant x comme prédicteur linéaire à la performance d’un modèle non linéaire contenant s(x) comme prédicteur lisse. En d’autres termes, on demande si l’ajout d’une fonction lisse au modèle linéaire améliore l’ajustement du modèle à nos données. linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2) smooth_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2) AIC(linear_model, smooth_model) ## df AIC ## linear_model 3.00000 3143.720 ## smooth_model 10.90825 2801.451 Ici, l’AIC du GAM lissé est plus bas, ce qui indique que l’ajout d’une fonction de lissage améliore la performance du modèle. La linéarité n’est donc pas soutenue par nos données. Pour expliquer brièvement, le critère d’information d’Akaike (AIC) est une mesure comparative de la performance d’un modèle, où des valeurs plus basses indiquent qu’un modèle est “plus performant” par rapport aux autres modèles considérés. 4.2 Défi 1 Essayons maintenant de déterminer si les données enregistrées lors de la première saison doivent être modélisées par une régression linéaire ou par un modèle additif. Répétons le test de comparaison avec gam() et AIC() en utilisant les données de la première saison seulement: isit1 &lt;- subset(isit, Season == 1) Ajustez un modèle linéaire et un GAM à la relation entre Sources et SampleDepth. Déterminez si l’hypothèse de linéarité est justifiée pour ces données. Quels sont les degrés de liberté effectifs du terme non-linéaire? Nous n’avons pas encore discuté des degrés de liberté effectifs (EDF), mais ils sont un outil clé pour nous aider à interpréter l’ajustement d’un GAM. Gardez ce terme en tête. Plus sur ce sujet dans les prochaines sections! 4.2.1 Défi 1: Solution 1. Ajustez un modèle linéaire et un GAM à la relation entre Sources et SampleDepth. linear_model_s1 &lt;- gam(Sources ~ SampleDepth, data = isit1) smooth_model_s1 &lt;- gam(Sources ~ s(SampleDepth), data = isit1) 2. Déterminez si l’hypothèse de linéarité est justifiée pour ces données. Comme ci-dessus, la visualisation de la courbe du modèle sur notre ensemble de données est une excellente première étape pour déterminer si notre modèle est bien conçu. ggplot(isit1, aes(x = SampleDepth, y = Sources)) + geom_point() + geom_line(colour = &quot;red&quot;, size = 1.2, aes(y = fitted(linear_model_s1))) + geom_line(colour = &quot;blue&quot;, size = 1.2, aes(y = fitted(smooth_model_s1))) + theme_bw() On peut compléter cela par une comparaison quantitative des performances du modèle en utilisant AIC(). AIC(linear_model_s1, smooth_model_s1) ## df AIC ## linear_model_s1 3.000000 2324.905 ## smooth_model_s1 9.644938 2121.249 Le score AIC moins élevé indique que le modèle lissé est plus performant que le modèle linéaire, ce qui confirme que la linéarité n’est pas appropriée pour notre ensemble de données. 3. Quels sont les degrés de liberté effectifs du terme non-linéaire? Pour obtenir les degrés de liberté effectifs, il suffit d’imprimer notre objet du modèle: smooth_model_s1 ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(SampleDepth) ## ## Estimated degrees of freedom: ## 7.64 total = 8.64 ## ## GCV score: 32.13946 Les degrés de liberté effectifs (EDF) sont &gt;&gt; 1. Gardez cela à l’esprit, car nous reviendrons bientôt sur ceux-ci! References "],["fonctionnement.html", "Chapitre 5 Le fonctionnement des GAMs 5.1 Exemple: une base polynomiale 5.2 Exemple: une base de spline cubique", " Chapitre 5 Le fonctionnement des GAMs Nous allons maintenant prendre quelques minutes pour regarder comment fonctionnent les GAMs. Commençons en considérant d’abord un modèle qui contient une fonction lisse \\(f\\) d’une covariable, \\(x\\) : \\[y_i = f(x_i) + \\epsilon_i\\] Pour estimer la fonction \\(f\\), nous avons besoin de représenter l’équation ci-dessus de manière à ce qu’elle devienne un modèle linéaire. Cela peut être fait en définissant des fonctions de base, \\(b_j(x)\\), dont est composée \\(f\\) : \\[f(x) = \\sum_{j=1}^q b_j(x) \\times \\beta_j\\] 5.1 Exemple: une base polynomiale Supposons que \\(f\\) est considérée comme un polynôme d’ordre 4, de sorte que l’espace des polynômes d’ordre 4 et moins contient \\(f\\). Une base de cet espace serait alors : \\[b_0(x)=1 \\ , \\quad b_1(x)=x \\ , \\quad b_2(x)=x^2 \\ , \\quad b_3(x)=x^3 \\ , \\quad b_4(x)=x^4\\] Alors \\(f(x)\\) devient : \\[f(x) = \\beta_0 + x\\beta_1 + x^2\\beta_2 + x^3\\beta_3 + x^4\\beta_4\\] .. et le modèle complet devient : \\[y_i = \\beta_0 + x_i\\beta_1 + x^2_i\\beta_2 + x^3_i\\beta_3 + x^4_i\\beta_4 + \\epsilon_i\\] Chaque fonction de base est multipliée par un paramètre à valeur réelle, \\(\\beta_j\\), et est ensuite additionnée pour donner la courbe finale \\(f(x)\\). En faisant varier le coefficient \\(\\beta_j\\), on peut faire varier la forme de \\(f(x)\\) pour produire une fonction polynomiale d’ordre 4 ou moins. 5.2 Exemple: une base de spline cubique Un spline cubique est une courbe construite à partir de sections d’un polynôme cubique reliées entre elles de sorte qu’elles sont continues en valeur. Chaque section du spline a des coefficients différents. Voici une représentation d’une fonction lisse utilisant une base de régression spline cubique de rang 5 avec des nœuds situés à incréments de 0.2: Dans cet exemple, les nœuds sont espacés uniformément à travers la gamme des valeurs observées de x. Le choix du degré de finesse du modèle est pré-déterminé par le nombre de nœuds, qui était arbitraire. Y a-t-il une meilleure façon de sélectionner les emplacements des nœuds? 5.2.1 Contrôler le degré de lissage avec des splines de régression pénalisés Au lieu de contrôler le lissage (donc, la non linéarité de la courbe) en modifiant le nombre de nœuds, nous gardons celui-ci fixé à une taille un peu plus grande que raisonnablement nécessaire et on contrôle le lissage du modèle en ajoutant une pénalité sur le niveau de courbure. Donc, plutôt que d’ajuster le modèle en minimisant (comme avec la méthode des moindres carrés) : \\[||y - XB||^{2}\\] Le modèle peut être ajusté en minimisant : \\[||y - XB||^{2} + \\lambda \\int_0^1[f^{&#39;&#39;}(x)]^2dx\\] Quand \\(\\lambda\\) tend vers \\(\\infty\\), le modèle devient linéaire. Si \\(\\lambda\\) est trop élevé, les données seront trop lissées et si elle est trop faible, les données ne seront pas assez lissées. Idéalement, il serait bon de choisir une valeur \\(\\lambda\\) de sorte que le \\(\\hat{f}\\) prédit est aussi proche que possible du \\(f\\) observé. Un critère approprié pourrait être de choisir \\(\\lambda\\) pour minimiser : \\[M = 1/n \\times \\sum_{i=1}^n (\\hat{f_i} - f_i)^2\\] Étant donné que \\(f\\) est inconnue, \\(M\\) doit être estimé. Les méthodes recommandées pour ce faire sont le maximum de vraisemblance (maximum likelihood, ML) ou l’estimation par maximum de vraisemblance restreint (restricted maximum likelihood, REML). La validation croisée généralisée (GCV) est une autre possibilité. Il s’agit d’une technique qui élimine tour à tour chaque donnée des données et considère la capacité prédictive moyenne des modèles adaptés aux données restantes pour prédire la donnée éliminée. Pour plus de détails sur ces méthodes, voir (S. N. Wood 2006). Le principe de validation croisée Dans le premier panneau, la courbe correspond à un ajustement faible par rapport aux données et ne fait pas mieux avec le point manquant. Dans le troisième panneau, la courbe ajuste le bruit aussi bien que le signal et la variabilité supplémentaire induite l’amène à prédire la donnée manquante plutôt mal. Dans le deuxième panneau, cependant, nous voyons que l’ajustement de la courbe du signal sous-jacent est très bien, le lissage passe à travers le bruit et la donnée manquante est raisonnablement bien prédite. Dans le premier panneau, \\(\\lambda\\) est trop élevé, et la courbe est trop lissée. Ici, la courbe est mal ajustée aux données et prédit donc très difficilement le point manquant. Dans le troisième panneau, \\(\\lambda\\) est trop élevé, et la courbe est surajustée. Ici, la courbe s’ajuste très étroitement aux données, suivant le signal aussi bien que le bruit qui l’entoure. L’influence de cette variabilité supplémentaire (non informative) fait que le modèle prédit difficilement la donnée manquante. Dans le deuxième panneau, \\(\\lambda\\) est à peu près parfait. La courbe s’ajuste assez bien au signal sous-jacent, tout en lissant le bruit. La donnée manquante est raisonnablement bien prédite. References "],["gam-avec-plusieurs-termes-non-linéaires.html", "Chapitre 6 GAM avec plusieurs termes non linéaires 6.1 GAM à variables linéaires et non linéaires 6.2 Degrés de liberté effectifs (edf) 6.3 GAM à plusieurs variables linéaires et lisses 6.4 GAM à plusieurs variables non linéaires 6.5 Défi 2", " Chapitre 6 GAM avec plusieurs termes non linéaires 6.1 GAM à variables linéaires et non linéaires Avec les GAMs, il est facile d’ajouter des termes non-linéaires et linéaires dans un seul modèle, plusieurs termes non-linéaires ou même des interactions non-linéaires. Dans cette section, nous allons utiliser les données de ISIT de nouveau. Nous allons essayer de modéliser la réponse Sources avec les prédicteurs Season and SampleDepth simultanément. Rappelez-vous de ce jeu de données présenté dans les sections précédentes? Le jeu de données ISIT est composé des niveaux de bioluminescence (Sources) en fonction de la profondeur, des saisons et des différentes stations. Tout d’abord, nous devons convertir notre prédicteur qualitatif (Season) en facteur. head(isit) ## SampleDepth Sources Station Time Latitude Longitude Xkm Ykm Month Year ## 1 517 28.73 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 2 582 27.90 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 3 547 23.44 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 4 614 18.33 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 5 1068 12.38 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 6 1005 11.23 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## BottomDepth Season Discovery RelativeDepth ## 1 3939 1 252 3422 ## 2 3939 1 252 3357 ## 3 3939 1 252 3392 ## 4 3939 1 252 3325 ## 5 3939 1 252 2871 ## 6 3939 1 252 2934 isit$Season &lt;- as.factor(isit$Season) Commençons par un modèle de base comprenant un terme non-linéaire (SampleDepth) et un facteur qualitatif (Season avec 2 niveaux). basic_model &lt;- gam(Sources ~ Season + s(SampleDepth), data = isit, method = &quot;REML&quot;) basic_summary &lt;- summary(basic_model) La sortie de p.table donne des informations sur les termes linéaires: basic_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.253273 0.3612666 20.07734 1.430234e-72 ## Season2 6.156130 0.4825491 12.75752 5.525673e-34 Le tableau s.table nous donne donne des informations sur le terme non-linéaire: basic_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.706426 8.975172 184.3583 0 Les edf indiqués dans le s.table sont les degrés effectifs de liberté (EDF) du terme lisse s(SampleDepth). Plus le nombre de degrés de liberté est élevé, plus la courbe est complexe et ondulée. Lorsqu’un terme a une valeur EDF proche de 1, il est sur le point d’être un terme linéaire. Des valeurs plus élevées indiquent que la courbe est plus ondulée, ou en d’autres termes, fortement non-linéaire. Dans notre modèle de base, les EDF de la fonction lisse s(SampleDepth) sont ~9, ce qui suggère une courbe fortement non-linéaire. Traçons les termes lissés (s(SampleDepth)) et linéaires (Season) de notre modèle ajusté: par(mfrow = c(1, 2)) plot(basic_model, all.terms = TRUE) Que nous montrent ces graphiques sur la relation entre la bioluminescence, la profondeur de l’échantillon et les saisons? La bioluminescence varie de manière non-linéaire sur le gradient SampleDepth, avec des niveaux de bioluminescence les plus élevés à la surface, suivis d’un second maximum plus petit, juste au-dessus d’une profondeur de 1500, avec des niveaux décroissants à des profondeurs plus basses. Il y a également une différence prononcée dans la bioluminescence entre les saisons, avec des niveaux élevés pendant la saison 2, par rapport à la saison 1. 6.2 Degrés de liberté effectifs (edf) Revenons sur le concept de degrés de liberté effectifs (EDF). Les degrés de liberté effectifs nous donnent beaucoup d’informations sur la relation entre les prédicteurs du modèle et les variables de réponse. Vous reconnaissez peut-être le terme “degrés de liberté” suite à des ateliers précédents sur les modèles linéaires, mais attention ! Les degrés de liberté effectifs d’un GAM sont estimés différemment des degrés de liberté d’une régression linéaire, et sont interprétés différemment. Dans la régression linéaire, les degrés de liberté du modèle sont équivalents au nombre de paramètres libres non redondants, \\(p\\), dans le modèle (et les degrés de liberté résiduels sont égaux à \\(n-p\\)). Parce que le nombre de paramètres libres des splines de lissage (tel que les GAMs) est souvent difficile à définir, les EDF sont liés à \\(\\lambda\\), où l’effet de la pénalité est de réduire les degrés de liberté. La limite supérieure d’EDF est déterminée par les dimensions de base \\(k\\) de la fonction lisse (les EDF ne peut pas dépasser \\(k-1\\)) En pratique, le choix exact de \\(k\\) est arbitraire, mais il devrait être suffisamment grand pour permettre une fonction lisse suffisamment complexe. Nous discuterons du choix de \\(k\\) dans les sections qui suivent. Des EDF plus élevés impliquent une courbe plus complexe et plus ondulée. Lorsqu’un terme a une valeur EDF proche de 1, il est sur le point d’être un terme linéaire. Des valeurs plus élevées indiquent que le terme est plus ondulé, ou en d’autres termes, plus non-linéaire! 6.3 GAM à plusieurs variables linéaires et lisses Nous pouvons ajouter un second terme, RelativeDepth, mais spécifier une relation linéaire avec Sources. two_term_model &lt;- gam(Sources ~ Season + s(SampleDepth) + RelativeDepth, data = isit, method = &quot;REML&quot;) two_term_summary &lt;- summary(two_term_model) L’estimation du coefficient de régression pour ce nouveau terme linéaire, RelativeDepth, sera présenté dans le tableau p.table. Rappelez-vous, le tableau p.table montre des informations sur les effets paramétriques (termes linéaires) : two_term_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.808305503 0.6478741951 15.139213 1.446613e-45 ## Season2 6.041930627 0.4767977508 12.671894 1.380010e-33 ## RelativeDepth -0.001401908 0.0002968443 -4.722705 2.761048e-06 Dans s.table, nous trouverons encore une fois le terme non-linéaire, s(SampleDepth), et son paramètre de courbure (edf). Rappelez-vous, le tableau s.table montre des informations sur les effets additifs (termes non-linéaires): two_term_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.699146 8.97396 132.4801 0 Regardons les relations entre les prédicteurs linéaires et non-linéaires et notre variable réponse. par(mfrow = c(2, 2)) plot(two_term_model, all.terms = TRUE) 6.4 GAM à plusieurs variables non linéaires Si nous voulons vérifier que la relation entre Sources et RelativeDepth est non-linéaire, on peut modéliser RelativeDepth avec une fonction non-linéaire. Dans ce modèle, nous aurions deux termes lisses: two_smooth_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth), data = isit, method = &quot;REML&quot;) two_smooth_summary &lt;- summary(two_smooth_model) L’estimation du coefficient de régression pour le seul terme linéaire, Season, sera présenté dans le tableau p.table. Rappelez-vous, le tableau p.table montre des informations sur les effets paramétriques (termes linéaires) : two_smooth_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.937755 0.3452945 22.98836 1.888513e-89 ## Season2 4.963951 0.4782280 10.37988 1.029016e-23 Dans s.table, nous trouverons maintenant deux termes non-linéaires, s(SampleDepth) et s(RelativeDepth), et leurs paramètres de courbure (edf). Rappelez-vous, le tableau s.table montre des informations sur les effets additifs (termes non-linéaires): two_smooth_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.752103 8.973459 150.37263 0 ## s(RelativeDepth) 8.044197 8.749580 19.97476 0 Regardons les relations entre les prédicteurs linéaires et non-linéaires et notre variable réponse. par(mfrow = c(2, 2)) plot(two_smooth_model, all.terms = TRUE) Pensez-vous que la performance de notre modèle est amélioré par l’ajout de ce nouveau terme non-linéaire, pour mieux représenter la relation entre la bioluminescence et la profondeur relative? Comme précédemment, nous pouvons comparer nos modèles avec AIC pour tester si le terme non-linéaire améliore la performance de notre modèle: AIC(basic_model, two_term_model, two_smooth_model) ## df AIC ## basic_model 11.83374 5208.713 ## two_term_model 12.82932 5188.780 ## two_smooth_model 20.46960 5056.841 On peut voir que two_smooth_model a la plus petite valeur AIC. Le modèle le mieux ajusté comprend donc deux fonctions non-linéaires pour SampleDepth et RelativeDepth, et un terme linéaire pour Season. 6.5 Défi 2 Pour notre deuxième défi, nous allons développer notre modèle en ajoutant des variables qui, selon nous, pourraient être des prédicteurs écologiquement significatifs pour expliquer la bioluminescence. 1. Créez deux nouveaux modèles: Ajoutez la variable Latitude à two_smooth_model, premièrement comme paramètre linéaire, et ensuite comme fonction non-linéaire. 2. Est-ce que Latitude est un terme important à inclure dans le modèle? La Latitude a-t-elle un effet linéaire ou non-linéaire? Utilisez des graphiques, les tables des coefficients et la fonction AIC() pour répondre à ces questions. 6.5.1 Défi 2: Solution 1. Créez deux nouveaux modèles: Ajoutez la variable Latitude à two_smooth_model, premièrement comme paramètre linéaire, et ensuite comme fonction non-linéaire. # Ajouter Latitude comme terme linéaire three_term_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + Latitude, data = isit, method = &quot;REML&quot;) (three_term_summary &lt;- summary(three_term_model)) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + Latitude ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -102.7094 40.6913 -2.524 0.01180 * ## Season2 6.0345 0.6179 9.766 &lt; 2e-16 *** ## Latitude 2.2188 0.8159 2.719 0.00669 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.750 8.973 92.84 &lt;2e-16 *** ## s(RelativeDepth) 8.047 8.751 16.90 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.75 Deviance explained = 75.6% ## -REML = 2545.7 Scale est. = 34.309 n = 789 # Ajouter Latitude comme terme non-linéaire three_smooth_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + s(Latitude), data = isit, method = &quot;REML&quot;) (three_smooth_summary &lt;- summary(three_smooth_model)) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + s(Latitude) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.7045 0.4716 14.215 &lt;2e-16 *** ## Season2 7.1120 0.7441 9.557 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.767 8.976 68.951 &lt;2e-16 *** ## s(RelativeDepth) 8.007 8.731 17.639 &lt;2e-16 *** ## s(Latitude) 7.431 8.297 8.954 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.771 Deviance explained = 77.8% ## -REML = 2524.5 Scale est. = 31.487 n = 789 2. Est-ce que Latitude est un terme important à inclure dans le modèle? La Latitude a-t-elle un effet linéaire ou non-linéaire? Commençons par visualiser les 4 effets qui sont maintenant inclus dans chaque modèle: par(mfrow = c(2, 2)) plot(three_term_model, all.terms = TRUE) par(mfrow = c(2, 2)) plot(three_smooth_model, all.terms = TRUE) Nous devrions également examiner nos tableaux de coefficients. Qu’est-ce que les EDF nous disent à propos de l’ondulation, ou la non-linéarité, des effets de nos prédicteurs? three_smooth_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.766891 8.975682 68.950905 0 ## s(RelativeDepth) 8.007411 8.730625 17.639321 0 ## s(Latitude) 7.431116 8.296838 8.954349 0 Les EDF sont tous élevés pour nos variables, y compris Latitude. Cela nous indique que Latitude est assez ondulée, et qu’elle ne devrait probablement pas être incluse comme terme linéaire. Avant de décider quel modèle est le “meilleur”, nous devrions tester si l’effet Latitude est plus approprié comme terme linéaire ou lisse, en utilisant AIC(): AIC(three_smooth_model, three_term_model) ## df AIC ## three_smooth_model 28.20032 4990.546 ## three_term_model 21.47683 5051.415 Notre modèle incluant la Latitude comme terme non-linéaire a un score AIC inférieur, ce qui signifie qu’il est plus performant que notre modèle incluant la Latitude comme terme linéaire. Mais, est-ce que l’ajout de Latitude comme prédicteur non-linéaire améliore réellement notre “meilleur” modèle (two_smooth_model)? AIC(two_smooth_model, three_smooth_model) ## df AIC ## two_smooth_model 20.46960 5056.841 ## three_smooth_model 28.20032 4990.546 Notre three_smooth_model, qui inclut SampleDepth, RelativeDepth, et Latitude comme termes lisses, et Season comme terme linéaire, a un score AIC inférieur à notre meilleur modèle précédent (two_smooth_model), qui n’incluait pas Latitude. Ceci implique que Latitude est en effet un prédicteur informatif non-linéaire de la bioluminescence. "],["gam-avec-des-termes-dinteraction.html", "Chapitre 7 GAM avec des termes d’interaction 7.1 Interaction entre variables non-linéaire et qualitatif 7.2 Interaction entre variables non linéaires", " Chapitre 7 GAM avec des termes d’interaction Il y a deux façons de modéliser une interaction entre deux variables : pour deux variables non-linéaire : s(x1, x2) pour une variable non-linéaire et une variable linéaire (quantitative ou qualitative) : utiliser l’argument by, s(x1, by = x2) Quand x2 est qualitative, vous avez un terme non linéaire qui varie entre les différents niveaux de x2 Quand x2 est quantitative, l’effet linéaire de x2 varie avec x1 Quand x2 est qualitative, le facteur doit être ajouté comme effet principal dans le modèle 7.1 Interaction entre variables non-linéaire et qualitatif Nous allons examiner l’effet de l’interaction en utilisant notre variable qualitative Season et examiner si la non-linéarité de s(SampleDepth) varie selon les différents niveaux de Season. factor_interact &lt;- gam(Sources ~ Season + s(SampleDepth, by = Season) + s(RelativeDepth), data = isit, method = &quot;REML&quot;) summary(factor_interact)$s.table ## edf Ref.df F p-value ## s(SampleDepth):Season1 6.839386 7.552045 95.119422 0 ## s(SampleDepth):Season2 8.744574 8.966290 154.474325 0 ## s(RelativeDepth) 6.987223 8.055898 6.821074 0 par(mfrow = c(2, 2)) plot(factor_interact) Les deux premiers graphiques montrent l’effet d’interaction entre notre variable lisse SampleDepth et chaque niveau de notre variable factorielle, Season. Voyez-vous une différence entre les deux courbes ? Les graphiques montrent quelques différences entre la forme des termes lisses entre les deux niveaux de Season. La différence la plus notable est le pic dans le deuxième panneau, qui nous indique qu’il y a un effet de SampleDepth entre 1000 et 2000 qui est important dans la saison 2, mais qui ne se produit pas dans la saison 1. Ceci suggère que l’effet d’interaction pourrait être important à inclure dans notre modèle. Nous pouvons également représenter l’effet d’interaction en 3D sur un seul graphique, en utilisant vis.gam(). vis.gam(factor_interact, theta = 120, n.grid = 50, lwd = 0.4) On peut changer le degré de rotation de notre plan x-y avec l’argument theta. Pour vérifier notre hypothèse que cette interaction est importante, on peut faire une comparaison de modèles en utilisant l’AIC pour déterminer si le terme d’interaction améliore la performance de notre modèle. AIC(two_smooth_model, factor_interact) ## df AIC ## two_smooth_model 20.46960 5056.841 ## factor_interact 26.99693 4878.631 L’AIC de notre modèle avec une interaction factorielle entre le lisse SampleDepth et le Season a un score AIC plus bas, ce qui nous indique que ce modèle est plus performant que two_smooth_model. L’inclusion de cette interaction améliore la performance de notre modèle. 7.2 Interaction entre variables non linéaires Finalement, nous regardons les interactions entre deux termes non linéaires, SampleDepth et RelativeDepth. smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth), data = isit, method = &quot;REML&quot;) summary(smooth_interact)$s.table ## edf Ref.df F p-value ## s(SampleDepth,RelativeDepth) 27.12521 28.77 93.91722 0 Dans la section précédente, nous avons pu visualiser un effet d’interaction entre un terme non linéaire et un terme factoriel en dessinant une fonction lisse différente de SampleDepth pour chaque niveau de Season. Dans ce modèle, nous avons deux termes non linéaires, donc l’effet de SampleDepth varie de façon linéaire avec RelativeDepth, et vice-versa. Lorsque nous visualisons cette interaction, nous obtenons plutôt un gradient entre deux fonctions continues lissées : plot(smooth_interact, page = 1, scheme = 2) We can also plot this interaction on a 3D surface: vis.gam(smooth_interact, view = c(&quot;SampleDepth&quot;, &quot;RelativeDepth&quot;), theta = 50, n.grid = 50, lwd = 0.4) Rappelez-vous, ce graphique peut être réorienté en changeant la valeur de l’argument theta. On peut changer la couleur du graphique 3D en utilisant l’argument color. Essayez de spécifier color = \"cm\" dans vis.gam() ci-dessus, et consultez ?vis.gam pour plus d’options de couleurs. Les graphiques illustrent une interaction non linéaire, où Sources est plus faible à des valeurs élevées de SampleDepth et RelativeDepth, mais augmente avec RelativeDepth alors que SampleDepth est faible. Ainsi, il semble y avoir un effet d’interaction entre ces termes non linéaires. Est-ce que l’inclusion de l’interaction entre s(SampleDepth) et s(RelativeDepth) améliore notre modèle two_smooth_model? AIC(two_smooth_model, smooth_interact) ## df AIC ## two_smooth_model 20.46960 5056.841 ## smooth_interact 30.33625 4943.890 Le modèle avec l’interaction entre s(SampleDepth) et s(RelativeDepth) a un AIC inférieur, ce qui signifie que l’inclusion de cette interaction améliore la performance de notre modèle, et notre capacité à comprendre les déterminants de la bioluminescence. "],["validation-gam.html", "Chapitre 8 Validation d’un GAM 8.1 Choisir \\(k\\) 8.2 Choisir une distribution", " Chapitre 8 Validation d’un GAM Le modèle additif de base peut être étendu de plusieurs façons : Utiliser d’autres distributions pour la variable de réponse avec l’argument family (comme dans un GLM), Utiliser de différents types de fonctions de base, Utilisation de différents types d’effets aléatoires pour ajuster des modèles à effets mixtes. Nous allons maintenant examiner ces aspects. Jusqu’à présent, nous avons utilisé des modèles additifs Gaussiens (distribution Normale), l’équivalent non linéaire d’un modèle linéaire. Cependant, les jeux de données en écologie ne respectent souvent pas les conditions des modèles Gaussiens. Donc, que pouvons-nous faire si les observations de la variable de réponse ne suivent pas une distribution normale ? Ou si la variance n’est pas constante (hétéroscédasticité)? Tout comme les modèles linéaires généralisés (GLM), nous pouvons formuler des modèles additifs généralisés pour répondre à ces problèmes. Revenons au modèle d’interaction pour les données de bioluminescence : smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth), data = isit, method = &quot;REML&quot;) summary(smooth_interact)$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.077356 0.4235432 19.070912 1.475953e-66 ## Season2 4.720806 0.6559436 7.196969 1.480113e-12 summary(smooth_interact)$s.table ## edf Ref.df F p-value ## s(SampleDepth,RelativeDepth) 27.12521 28.77 93.91722 0 Comme pour un GLM, il est essentiel de vérifier si nous avons correctement spécifié le modèle, et surtout la distribution de la variable réponse. Il faut vérifier: Le choix des dimensions de base k. La distribution des résidus de notre modèle, comme on fait pour un GLM (voir Workshop 6). Heureusement, mgcv inclut des fonctions utiles pour la validation de modèle: k.check() vérifie les dimensions de base. gam.check() fait une visualisation des résidus, et fournit également la sortie de k.check(). 8.1 Choisir \\(k\\) Dans le Chapter 5, nous avons discuté du rôle du paramètre de lissage \\(\\lambda\\) pour contrôler les ondulations de nos fonctions de lissage. Cette ondulation est également contrôlé par la dimension de base \\(k\\), qui définit le nombre de fonctions de base utilisées pour créer une fonction lisse. Chaque fonction lisse dans un GAM est essentiellement la somme pondérée de nombreuses fonctions plus petites, appelées fonctions de base. Plus le nombre de fonctions de base utilisées pour construire une fonction lisse est élevé, plus la fonction lisse est “ondulée”. Comme vous pouvez le voir ci-dessous, une fonction lisse avec une petite dimension de base de \\(k\\) sera moins ondulée qu’une fonction lisse avec une grande dimension de base de \\(k\\). Tout au long de cet atelier, nous avons cherché à améliorer l’ajustement de notre modèle, c’est-à-dire que nous avons essayé de construire le meilleur GAM possible pour capturer les relations dans notre jeu de données. La clé pour obtenir un bon ajustement du modèle consiste à équilibrer le compromis entre deux éléments : Le paramètre de lissage \\(\\lambda\\), qui _pénalise les ondulations ; La dimension de base \\(k\\), qui permet plus de flexibilité au modèle (plus d’ondulations) en fonction de nos données. Avons-nous optimisé le compromis entre le lissage (\\(\\lambda\\)) et la flexibilité (\\(k\\)) dans notre modèle? 8.1.1 Est-ce que notre module est assez flexible? On n’a pas encore spécifié de valeur \\(k\\) dans notre modèle, mais gam() définit un \\(k\\) par défaut en fonction du nombre de variables sur lequel la fonction lisse est construite. Est-ce que le k est assez grand? k.check(smooth_interact) ## k&#39; edf k-index p-value ## s(SampleDepth,RelativeDepth) 29 27.12521 0.9448883 0.0675 Les EDF se rapprochent beaucoup de k. Ceci signifie que la flexibilité du modèle est restreinte par le k utilisé par défaut, et que notre modèle pourrait mieux s’ajuster aux données si on permettait plus d’ondulations. En d’autres mots, nous n’avons pas un compromis équilibré entre le lissage et l’ondulation du modèle. Recommençons le modèle avec un k plus élevé: smooth_interact_k60 &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60), data = isit, method = &quot;REML&quot;) Est-ce que le k est assez grand maintenant? k.check(smooth_interact_k60) ## k&#39; edf k-index p-value ## s(SampleDepth,RelativeDepth) 59 46.03868 1.048626 0.9025 Les EDF sont beaucoup plus petits que k, donc notre modèle s’adjuste mieux aux données avec plus d’ondulations. On peut donc remplacer notre modèle avec cette version plus flexible: smooth_interact &lt;- smooth_interact_k60 8.2 Choisir une distribution Comme pour tout modèle Normal, nous devons vérifier certaines conditions avant de continuer. Nous pouvons évaluer la distribution des résidus du modèle pour vérifier ces conditions, tout comme nous le ferions pour un GLM (voir Atelier 6). On peut visualiser les résidus du modèle avec gam.check(): par(mfrow = c(2, 2)) gam.check(smooth_interact) ## ## Method: REML Optimizer: outer newton ## full convergence after 4 iterations. ## Gradient range [-0.0005267781,0.0001620713] ## (score 2487.848 &amp; scale 27.40287). ## Hessian positive definite, eigenvalue range [15.84516,393.7878]. ## Model rank = 61 / 61 ## ## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may ## indicate that k is too low, especially if edf is close to k&#39;. ## ## k&#39; edf k-index p-value ## s(SampleDepth,RelativeDepth) 59 46 1.05 0.9 En plus des graphiques, gam.check() fournit également la sortie de k.check(). Pour plus de détails et d’explications au sujet de l’interprétation des résidus, nous vous recommandons de consulter l’Atelier 4 et l’Atelier 6. La visualisation des résidus met quelques problèmes en évidence: Figure 2: La variance des erreurs n’est pas constante (hétéroscédasticité). Figures 1 et 4: Quelques observations extrêmes. Il semble qu’une distribution Normale est inappropriée pour modéliser notre variable réponse! "],["autres-distributions.html", "Chapitre 9 Autres distributions 9.1 Défi 3", " Chapitre 9 Autres distributions Nous avons besoin d’une distribution de probabilité qui permet à la variance d’augmenter avec la moyenne. Une famille de distributions qui possède cette propriété et qui fonctionne bien dans un GAM est la famille Tweedie. Une fonction de liaison commune pour les distributions Tweedie est le \\(log\\). Comme dans un GLM, nous pouvons utiliser l’argument family = dans gam() pour ajuster des modèles avec d’autres distributions (y compris des distributions telles que binomial, poisson, gamma etc). Pour en savoir plus sur les familles disponibles dans mgcv : `?`(family.mgcv) 9.1 Défi 3 Ajuster un nouveau modèle smooth_interact_tw avec la même formule que le modèle smooth_interact, mais avec une distribution de la famille Tweedie (au lieu de la distribution Normale) et log comme fonction de liaison. Pour ce faire, on peut utiliser family = tw(link = \"log\") dans gam(). Vérifier le choix de k et la visualisation des résidus pour le nouveau modèle. Comparer smooth_interact_tw avec smooth_interact. Lequel est meilleur? Pour vous rappeler, voici notre modèle smooth_interact: # Indice! Parce que la distribution normale est le # paramètre par défaut, nous n&#39;avons pas encore spécifié la # distribution dans cet atelier. # Voici comment nous écririons le modèle pour spécifier la # distribution normale : smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60), family = gaussian(link = &quot;identity&quot;), data = isit, method = &quot;REML&quot;) 9.1.1 Défi 3: Solution 1. Premièrement, construisons un nouveau modèle avec une distribution Tweedie un lien log. smooth_interact_tw &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60), family = tw(link = &quot;log&quot;), data = isit, method = &quot;REML&quot;) summary(smooth_interact_tw)$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.3126641 0.03400390 38.60333 8.446478e-180 ## Season2 0.5350529 0.04837342 11.06089 1.961733e-26 summary(smooth_interact_tw)$s.table ## edf Ref.df F p-value ## s(SampleDepth,RelativeDepth) 43.23949 51.57139 116.9236 0 2. Vérifier le choix de k et la visualisation des résidus pour le nouveau modèle. Ensuite, on devrait vérifier le choix des dimensions de bases k: k.check(smooth_interact_tw) ## k&#39; edf k-index p-value ## s(SampleDepth,RelativeDepth) 59 43.23949 1.015062 0.805 Ainsi que la visualisation des résidus, pour valider que la distribution Tweedie est appropriée: par(mfrow = c(2, 2)) gam.check(smooth_interact_tw) ## ## Method: REML Optimizer: outer newton ## full convergence after 3 iterations. ## Gradient range [-0.0007646676,0.0001600484] ## (score 1791.138 &amp; scale 0.4355231). ## Hessian positive definite, eigenvalue range [12.02444,492.4714]. ## Model rank = 61 / 61 ## ## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may ## indicate that k is too low, especially if edf is close to k&#39;. ## ## k&#39; edf k-index p-value ## s(SampleDepth,RelativeDepth) 59.0 43.2 1.02 0.79 Les résidus semblent mieux distribués, mais il est évident que le modèle manque encore quelque chose. Il pourrait s’agir d’un effet spatial (longitude et latitude), ou d’un effet aléatoire (par exemple basé sur Station). 3. Comparer smooth_interact_tw avec smooth_interact. Lequel est meilleur? AIC(smooth_interact, smooth_interact_tw) ## df AIC ## smooth_interact 49.47221 4900.567 ## smooth_interact_tw 47.86913 3498.490 L’AIC nous permet de comparer des modèles qui sont basés sur des distributions différentes! Le score AIC pour smooth_interact_tw est beaucoup plus petit que celui de smooth_interact. Utiliser une distribution Tweedie au lieu d’une distribution Normale améliore beaucoup notre modèle! "],["changer-la-fonction-de-base.html", "Chapitre 10 Changer la fonction de base 10.1 Exemple: Données cycliques", " Chapitre 10 Changer la fonction de base Pour modéliser une surface lisse ou non-linéaire, nous pouvons construire des fonctions lisses de différentes manières: La fonction de lissage s() modélise un terme lisse 1-dimensionnelle ou une intéraction entre des variables mesurées sur la même échelle. Il s’agit de la fonction de lissage que nous avons utilisée tout au long de cet atelier. Il y a deux autres fonctions de lissage: te() et ti(), qui peuvent modéliser une surface d’interaction 2- ou n-dimensionnelle. La fonction te() est utile pour modéliser des variables qui ne sont pas sur la même échelle, incluant les surfaces qui comprennent les effets principaux. La fonction ti() est utile pour modéliser des surfaces d’interactions qui ne comprennent pas les effets principaux. Les fonctions lisses ont beaucoup de paramètres qui changent leur comportement. Les paramètres les plus souvent utilisés sont les suivants : k: dimensions de base - Détermine la limite supérieure du nombre de fonctions de base utilisées pour construire la courbe. - Contraint l’ondulation d’une fonction lisse. - Le \\(k\\) devrait être &lt; au nombre de données uniques. - La complexité (ou la non-linéarité) d’une fonction lisse dans un modèle ajusté est reflétée par ses degrés de liberté effectifs (EDF) bs: spécifie la fonction de base sous-jacente. - pour s() on utilise tp (thin plate regression spline) et pour te() et ti() on utilise la base cr (cubic regression spline). d: spécifie quelles variables d’une intéraction se trouvent sur la même échelle lorsqu’on utilise te() and ti(). - Par exemple, te(Temps, largeur, hauteur, d=c(1,2)), indique que la largeur et la hauteur sont sur la même échelle, mais que temps ne l’est pas. 10.1 Exemple: Données cycliques Lorsque l’on modélise des données cycliques, on souhaite généralement que le prédicteur soit identique aux deux bouts des phases. Pour y parvenir, nous devons modifier la fonction de base. Utilisons une série chronologique de données climatiques, divisées en mesures mensuelles, afin de déterminer s’il y a une tendance de température annuelle. Nous utiliserons la série temporelle de la température de Nottingham pour cela, qui est incluse dans R: # série temporelle de la température de Nottingham data(nottem) Voir ?nottem pour plus de détails sur le jeu de données. Commençons par visualiser les fluctuations mensuelles de température pour chaque année dans le jeu de données nottem: # nombre d&#39;années de données (20 ans) n_years &lt;- length(nottem)/12 # codage qualitatif pour les 12 mois de l&#39;année, pour # chaque année échantillonnée (série de 1 à 12, répétée 20 # fois) nottem_month &lt;- rep(1:12, times = n_years) # une variable où l&#39;année correspondant à chaque mois dans # nottem_month nottem_year &lt;- rep(1920:(1920 + n_years - 1), each = 12) # Visualiser la série temporelle qplot(x = nottem_month, y = nottem, colour = factor(nottem_year), geom = &quot;line&quot;) + theme_bw() Nous pouvons modéliser le changement cyclique de température à travers les mois et la tendance non-linéaire à travers les années, en utilisant une spline cubique, ou cc pour modéliser les effets de mois ainsi qu’un terme non-linéaire pour la variable année. year_gam &lt;- gam(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), method = &quot;REML&quot;) summary(year_gam)$s.table ## edf Ref.df F p-value ## s(nottem_year) 1.621375 2.011475 2.788093 0.06141004 ## s(nottem_month) 6.855132 8.000000 393.119285 0.00000000 plot(year_gam, page = 1, scale = 0) Il y a une augmentation d’environ 1 - 1,5ºC au cours de la série, mais au cours d’une année, il y a une variation d’environ 20ºC. Les données réelles varient autour de ces valeurs prédites et ceci représente donc la variance inexpliquée. Ici, nous pouvons voir l’un des avantages très intéressants de l’utilisation des GAMs. Nous pouvons soit tracer la surface réponse (valeurs prédites) ou les termes (contribution de chaque covariable) tel qu’indiqué ci-haut. Vous pouvez imaginer ce dernier en tant qu’une illustration de la variation des coefficients de régression et comment leur contribution (ou taille de leur effet) varie au fil du temps. Dans le premier graphique, nous voyons que les contributions positives de la température sont survenues après 1930. Visualiser les contributions de variables G. L. Simpson and Anderson (2009) ont modélisé des données paléolimnologiques avec des GAMs (voir Fig.3c), et ont visualisé la contribution (effet) de la température sur la composition des algues dans des lacs pour illustrer que les contributions significatives de la température ont seulement survenu au cours de deux périodes extrêmement froides. C’est-à-dire, la contribution est importante lorsque les intervalles de confiance n’incluent pas la valeur zéro, ce qu’on voit à environ 300 et 100 ans AVJC dans G. L. Simpson and Anderson (2009). Cela a permis aux auteurs de non seulement déterminer combien de variance est expliquée par la température au cours des derniers siècles, mais aussi de repérer dans le temps cet effet significatif. Si cela vous intéresse, le code pour visualiser soit la surface de réponse (type = \"response\") ou les termes (type = \"terms\") est disponible ci-dessous. Lorsque les termes sont sélectionnés, vous obtiendrez la même figure que celle ci-dessus. pred &lt;- predict(year_gam, type = &quot;terms&quot;, se = TRUE) I &lt;- order(nottem_year) plusCI &lt;- I(pred$fit[, 1] + 1.96 * pred$se[, 1]) minusCI &lt;- I(pred$fit[, 1] - 1.96 * pred$se[, 1]) xx &lt;- c(nottem_year[I], rev(nottem_year[I])) yy &lt;- c(plusCI[I], rev(minusCI[I])) plot(xx, yy, type = &quot;n&quot;, cex.axis = 1.2, xlab = &quot;Year&quot;, ylab = &quot;Temperature&quot;) polygon(xx, yy, col = &quot;light blue&quot;, border = &quot;light blue&quot;) lines(nottem_year[I], pred$fit[, 1][I], lty = 1, lwd = 2) abline(h = 0, lty = 2) References "],["intro-rapide-aux-modèles-additifs-généralisés-à-effets-mixtes-gamms.html", "Chapitre 11 Intro rapide aux modèles additifs généralisés à effets mixtes (GAMMs) 11.1 L’autocorrelation des résidus 11.2 Modélisation avec effets mixtes", " Chapitre 11 Intro rapide aux modèles additifs généralisés à effets mixtes (GAMMs) Lorsque les observations ne sont pas indépendantes, les GAMs peuvent être utilisés soit pour incorporer: une structure de corrélation pour modéliser les résidus autocorrélés (autorégressif (AR), moyenne mobile (MA), ou une combinaison des deux (ARMA)) des effets aléatoires qui modélisent l’indépendance entre les observations d’un même site. En plus de changer la fonction de base, nous pouvons aussi complexifier le modèle en intégrant une structure d’auto-corrélation (ou même des effets mixtes) en utilisant les fonctions gamm() dans la librairie mgcv. Bien que nous ne l’utilisions pas ici, la librairie gamm4 peut également être utilisé pour estimer des modèles GAMMs dans R. 11.1 L’autocorrelation des résidus Pour commencer, nous allons jeter un coup d’œil à un modèle avec de l’autocorrélation temporelle dans les résidus. Revenons au modèle de la température de Nottingham pour vérifier si les résidus sont corrélés en faisant appel à la fonction (partielle) d’autocorrélation. par(mfrow = c(1, 2)) acf(resid(year_gam), lag.max = 36, main = &quot;ACF&quot;) pacf(resid(year_gam), lag.max = 36, main = &quot;pACF&quot;) La fonction d’autocorrelaton (ACF; première figure) évalue la corrélation croisée d’une série temporelle entre points à différents décalages (donc, la similarité entre observations progressivement décalés). En contraste, la fonction partielle d’autocorrelation (PACF: deuxième figure) évalue la corrélation croisée d’une série temporelle entre points à différents décalages, après avoir contrôlé les valeurs de la série temporelle à tous les décalages plus courts. Les graphiques ACF et pACF sont donc utilisés pour identifier le temps nécessaire avant que les observations ne sont plus autocorrélées. Les graphiques des fonctions d’autocorrélation suggèrent qu’un modèle AR de faible ordre est nécessaire (avec un ou deux intervalles de temps décalés). Nous pouvons tester cet hypothèse en ajoutant des structures d’autocorrelation au modèle de température de Nottingham. Créons un modèle AR(1) (corrélation à 1 intervalle de temps décalé), et un modèle AR(2) (corrélation à 2 intervalles de temps décalés), et comparons-les avec AIC pour déterminer le modèle le mieux ajusté. df &lt;- data.frame(nottem, nottem_year, nottem_month) year_gam &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), data = df) year_gam_AR1 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), correlation = corARMA(form = ~1 | nottem_year, p = 1), data = df) year_gam_AR2 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), correlation = corARMA(form = ~1 | nottem_year, p = 2), data = df) Quel modèle est mieux ajusté? AIC(year_gam$lme, year_gam_AR1$lme, year_gam_AR2$lme) ## df AIC ## year_gam$lme 5 1109.908 ## year_gam_AR1$lme 6 1101.218 ## year_gam_AR2$lme 7 1101.598 Le modèle avec la structure AR(1) donne un meilleur ajustement comparé au premier modèle (year_gam), il y a très peu d’amélioration en passant au AR(2). Il est donc préférable d’inclure uniquement la structure AR(1) dans notre modèle. 11.2 Modélisation avec effets mixtes Comme nous l’avons vu dans la section précédente, bs spécifie la fonction de base sous-jacente. Pour les facteurs aléatoires (origine et pente linéaire), nous utilisons bs = \"re\" et pour les pentes aléatoires non linéaires, nous utilisons bs = \"fs\". Trois types d’effets aléatoires différents sont possibles lors de l’utilisation des GAMMs (où fac représente une variable qualitative utilisée pou l’effet aléatoire et x0 est un effet quantitatif fixe) : interceptes aléatoires ajustent la hauteur des termes du modèle avec une valeur constante de pente : s(fac, bs = \"re\") pentes aléatoires ajustent la pente d’une variable explicative numérique: s(fac, x0, bs = \"re\") surfaces lisses aléatoires ajustent la tendance d’une prédiction numérique de façon non linéaire: s(x0, fac, bs = \"fs\", m = 1) où l’argument \\(m=1\\) met une plus grande pénalité au lissage qui s’éloigne de 0, ce qui entraîne un retrait vers la moyenne. Pour plus de détails sur les effets aléatoires, voir l’Atelier 7. Ceci est une introduction (très!) brève aux effets aléatoires dans les GAMMs. Pour plus de détails, nous recommandons fortement Pedersen et al. (2019), un article très accessible qui décrit plusieurs façons de spécifier des GAMMs pour répondre à des questions écologiques. 11.2.1 GAMM avec un intercepte aléatoire Nous allons utiliser gamSim() pour générer un ensemble de données, cette fois-ci avec un effet aléatoire. Ensuite, nous construirons un modèle avec un intercepte aléatoire en utilisant fac comme facteur aléatoire. # Simuler des données gam_data2 &lt;- gamSim(eg = 6) ## 4 term additive + random effectGu &amp; Wahba 4 term additive model head(gam_data2) ## y x0 x1 x2 x3 f f0 ## 1 7.447214 0.01187972 0.2035120 0.4945059 0.73141941 7.337059 0.07462514 ## 2 22.628251 0.68667889 0.9666880 0.2213280 0.67339805 23.466335 1.66579998 ## 3 23.781802 0.58399076 0.2748391 0.1986483 0.45359493 21.224725 1.93077842 ## 4 19.418014 0.92468357 0.4035589 0.3976822 0.06634208 19.038438 0.46882376 ## 5 15.768860 0.86561852 0.8469147 0.2192735 0.33276781 18.132802 0.81948517 ## 6 11.283497 0.21012765 0.3788559 0.4912578 0.21573884 12.131255 1.22644773 ## f1 f2 f3 fac ## 1 1.502340 2.760094 0 1 ## 2 6.912808 8.887727 0 2 ## 3 1.732695 8.561251 0 3 ## 4 2.241438 4.328176 0 4 ## 5 5.440274 8.873043 0 1 ## 6 2.133389 2.771418 0 2 # Rouler un modèle avec intercepte aléatoire gamm_intercept &lt;- gam(y ~ s(x0) + s(fac, bs = &quot;re&quot;), data = gam_data2, method = &quot;REML&quot;) # Voir la sortie du modèle summary(gamm_intercept)$s.table ## edf Ref.df F p-value ## s(x0) 2.638784 3.277115 3.800617 0.008627317 ## s(fac) 2.969756 3.000000 98.050964 0.000000000 Notez qu’il y a maintenant un terme aléatoire dans le sommaire du modèle. Vous pouvez visualiser les intercepts aléatoires pour chaque niveau de fac comme ceci: plot(gamm_intercept, select = 2) # select = 2 parce que le terme aléatoire se trouve sur la # 2e ligne du tableau sommaire. Nous pouvons également utiliser la fonction plot_smooth pour visualiser le modèle, qui nous permet de visualisés des effets sommés d’un GAM (basé sur les prédictions). Cette fonction permet également de supprimer les effets aléatoires en définissant rm.ranef = TRUE. On peut premièrement visualiser l’effet combiné de x0 sans les niveaux de l’effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l’effet aléatoire fac: par(mfrow = c(1, 2), cex = 1.1) # Visualiser les effets combinés de x0 (sans effets # aléatoires) plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x1)&quot;) # Visualiser chaque niveau de l&#39;effet aléatoire plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac)&quot;, col = &quot;orange&quot;, ylim = c(0, 25)) plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) 11.2.2 GAMM avec une pente aléatoire Ensuite, spécifions un modèle avec une pente aléatoire: gamm_slope &lt;- gam(y ~ s(x0) + s(x0, fac, bs = &quot;re&quot;), data = gam_data2, method = &quot;REML&quot;) summary(gamm_slope)$s.table ## edf Ref.df F p-value ## s(x0) 2.450294 3.043891 2.207364 0.08440636 ## s(x0,fac) 2.962920 3.000000 83.852918 0.00000000 On peut encore une fois visualiser l’effet combiné de x0 sans les niveaux de l’effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l’effet aléatoire fac: par(mfrow = c(1, 2), cex = 1.1) # Visualiser les effets combinés de x0 (sans effets # aléatoires) plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x1)&quot;) # Visualiser chaque niveau de l&#39;effet aléatoire plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac, x0)&quot;, col = &quot;orange&quot;, ylim = c(0, 25)) plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) 11.2.3 GAMM avec un intercept et une pente aléatoire On peut aussi inclure un intercept et une pente aléatoire. gamm_int_slope &lt;- gam(y ~ s(x0) + s(fac, bs = &quot;re&quot;) + s(fac, x0, bs = &quot;re&quot;), data = gam_data2, method = &quot;REML&quot;) summary(gamm_int_slope)$s.table ## edf Ref.df F p-value ## s(x0) 2.579562 3.20239 3.145117 0.022324891 ## s(fac) 2.839378 3.00000 508.130983 0.000000000 ## s(fac,x0) 2.303797 3.00000 296.365269 0.004959271 On peut encore une fois visualiser l’effet combiné de x0 sans les niveaux de l’effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l’effet aléatoire fac: par(mfrow = c(1, 2), cex = 1.1) # Visualiser les effets combinés de x0 (sans effets # aléatoires) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x1)&quot;) # Visualiser chaque niveau de l&#39;effet aléatoire plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac) + s(fac, x0)&quot;, col = &quot;orange&quot;, ylim = c(0, 25)) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) Notez que la pente aléatoire est statique dans ce cas: plot(gamm_int_slope, select = 3) # select = 3 parce que la pente aléatoire est sur la # troisième ligne de notre tableau sommaire. 11.2.4 GAMM avec une surface lisse aléatoire Finalement, spécifions un modèle avec une surface lisse aléatoire. gamm_smooth &lt;- gam(y ~ s(x0) + s(x0, fac, bs = &quot;fs&quot;, m = 1), data = gam_data2, method = &quot;REML&quot;) ## Warning in gam.side(sm, X, tol = .Machine$double.eps^0.5): model has repeated ## 1-d smooths of same variable. summary(gamm_smooth)$s.table ## edf Ref.df F p-value ## s(x0) 2.423260 2.942415 2.43033 0.0764996 ## s(x0,fac) 7.292933 35.000000 8.85519 0.0000000 Si la pente aléatoire variait selon x0, on verrait différentes courbes pour chaque niveau: plot(gamm_smooth, select = 1) # select = 1 parce que la surface lisse aléatoire est sur # la première ligne de notre tableau sommaire. On peut encore une fois visualiser l’effet combiné de x0 sans les niveaux de l’effet aléatoire, et ensuite une courbe pour chacun de quatre niveaux de l’effet aléatoire fac: par(mfrow = c(1, 2), cex = 1.1) # Visualiser les effets combinés de x0 (sans effets # aléatoires) plot_smooth(gamm_smooth, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x1)&quot;) # Visualiser chaque niveau de l&#39;effet aléatoire plot_smooth(gamm_smooth, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac) + s(fac, x0)&quot;, col = &quot;orange&quot;, ylim = c(0, 25)) plot_smooth(gamm_smooth, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_smooth, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_smooth, view = &quot;x0&quot;, rm.ranef = FALSE, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) 11.2.5 Comparaison de GAMM Tous les GAMMs de cette section peuvent être comparé avec AIC() pour trouver le modèle le mieux ajusté: AIC(gamm_intercept, gamm_slope, gamm_int_slope, gamm_smooth) ## df AIC ## gamm_intercept 8.064772 2241.613 ## gamm_slope 8.043350 2267.827 ## gamm_int_slope 10.876422 2237.523 ## gamm_smooth 13.408792 2239.421 Le meilleur modèle de ces trois modèles serait donc le GAMM avec un intercept aléatoire. References "],["ressources.html", "Chapitre 12 Ressources", " Chapitre 12 Ressources Cet atelier présente une brève introduction aux concepts de base et aux packages populaires pour vous aider à estimer, évaluer et visualiser les GAMs dans R, mais les GAMs offrent bien d’autres possibilités! Nous avons quelques ressources à vous suggérer si vous souhaitez approfondir le sujet des GAMs et comment les implémenter dans R. Beaucoup de ces ressources ont inspiré et contribué au contenu de cet atelier. Il ne s’agit pas d’une liste exhaustive, mais de quelques pistes très utiles. Le livre Generalized Additive Models: An Introduction with R de Simon Wood (l’auteur du paquet mgcv) est probablement la ressource la plus complète que vous pouvez trouver sur les GAMs. Le blogue de Gavin Simpson, From the bottom of the heap, discute de nombreux aspects des GAMs et de leur implémentation dans R. Le paquet de Gavin Simpson, gratia, est une réimplémentation utile des outils de visualisation des GAMs dans ggplot2. Generalized Additive Models: An Introduction with R par Noam Ross est un cours bien conçu, interactif et gratuit qui couvre les GAMs plus en détail. Overview GAMM analysis of time series data par Jacolien van Rij est un tutoriel utile et approfondi sur les GAMM qui a largement inspiré la section GAMM de cet atelier. Simon Wood catalogue également des conférences et des notes sur les GAMM sur son site Web (maths.ed.ac.uk/~swood34/). Hierarchical generalized additive models in ecology: an introduction with mgcv de Pedersen et al. (2019) est une excellente introduction aux GAM hiérarchiques, à la façon de les concevoir et à leur mise en œuvre dans R. Enfin, les pages d’aide, disponibles via ?gam dans R, constituent toujours une excellente ressource. "],["references.html", "Chapitre 13 References", " Chapitre 13 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
