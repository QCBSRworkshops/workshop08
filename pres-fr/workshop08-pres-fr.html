<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Atelier 8: Modèles additifs généralisés</title>
    <meta charset="utf-8" />
    <meta name="author" content="Centre de la Science de la Biodiversité du Québec" />
    <link href="assets/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
    <link rel="stylesheet" href="qcbsR.css" type="text/css" />
    <link rel="stylesheet" href="qcbsR-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Atelier 8: Modèles additifs généralisés
## Série d’ateliers R
### Centre de la Science de la Biodiversité du Québec

---







class: inverse, center, middle



# À propos de cet atelier
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=repo&amp;message=dev&amp;color=6f42c1&amp;logo=github)](https://github.com/QCBSRworkshops/workshop08)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=wiki&amp;message=08&amp;logo=wikipedia)](https://wiki.qcbs.ca/r_atelier8)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=Diapos&amp;message=08&amp;color=red&amp;logo=html5)](https://qcbsrworkshops.github.io/workshop08/pres-fr/workshop08-pres-fr.html)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=Diapos&amp;message=08&amp;color=red&amp;logo=adobe-acrobat-reader)](https://qcbsrworkshops.github.io/workshop08/workshop08-fr/workshop08-fr.pdf)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=script&amp;message=08&amp;color=2a50b8&amp;logo=r)](https://qcbsrworkshops.github.io/workshop08/workshop08-fr/workshop08-fr.R)

---

# Packages requis

* [ggplot2](https://cran.r-project.org/package=ggplot2)
* [itsadug](https://cran.r-project.org/package=itsadug)
* [mgcv](https://cran.r-project.org/package=mgcv)

&lt;br&gt;

```R
install.packages(c('ggplot2', 'itsadug', 'mgcv'))
```

---


# Aperçu

1. Le modèle linéaire ... et où il échoue
2. Introduction aux GAMs
3. GAM avec plusieurs termes non-linéaires
4. Interactions
5. Généralisation du modèle additif
6. Changer la fonction de base
7. Intro rapide aux GAMMs

---
# Objectifs d'apprentissage

1. Utiliser la librairie `mgcv` pour modéliser les relations non linéaires,
2. Évaluer la sortie d'un Modèle Additif Généralisé (GAM) afin de mieux comprendre nos données,
3. Utiliser des tests pour déterminer si nos relations correspondent à des modèles non linéaires ou linéaires,
4. Ajouter des interactions non linéaires entre les variables explicatives,
5. Comprendre l'idée d'une fonction de base (basis function) et la raison pour laquelle ça rend les GAMs si puissants !,
6. Comment modéliser la dépendance dans les données (autocorrélation, structure hiérarchique) en utilisant les GAMMs.

---
# Prérequis

&gt; Expérience du logiciel R (assez pour être en mesure d'exécuter un script et d'examiner les données et les objets dans R).

&gt; Une connaissance de base de la régression linéaire.

---
class: inverse, center, middle
# 1. Le modèle linéaire

&lt;hr&gt;

## ...et où il échoue

---
# La régression linéaire

La régression linéaire est ce que la plupart des gens apprennent avant tout en statistiques et est parmi les méthodes les plus performantes. Elle nous permet de modéliser une variable réponse en fonction de facteurs prédictifs et d'une erreur résiduelle.

--
Tel que vu dans l'[atelier sur les modèles linéaires](http://qcbs.ca/wiki/r_workshop4), le modèle linéaire fait quatre suppositions importantes :

1. Relation linéaire entre les variables de réponse et les variables prédicteurs:  `$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$`
2. L'erreur est distribuée normalement: `$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$`
3. La variance des erreurs est constante
4. Chaque erreur est indépendante des autres (homoscédasticité)

&lt;br&gt;

--

*Modèle linéaire avec plusieurs prédicteurs:*

`$$y_i = \beta_0 + \beta_1x_{1,i}+\beta_2x_{2,i}+\beta_3x_{3,i}+...+\beta_kx_{k,i} + \epsilon_i$$`

---
# La régression linéaire

Les modèles linéaires fonctionnent très bien dans certains cas spécifiques où tous ces critères sont respectés:

.center[
![](images/linreg.png)
]


---
# La régression linéaire

Et pourtant tant de façons pour qu'il ne le soit pas :

.center[
![:scale 60%](images/linreg_bad.png)
]

---
# La régression linéaire

**Quel est le problème et comment le régler?**

Un **modèle linéaire** essaye d'ajuster la meilleure **droite** qui passe au milieu des données, cela ne fonctionne donc pas pour tous les jeux de données.

En revanche, les **GAM** font cela en ajustant une **fonction de lissage non-linéaire** à travers les données, mais tout en contrôlant le degré de courbure de la ligne (*plus d'information sur cela plus bas*).

---
class: inverse, center, middle

## 2. Introduction aux GAMs
---
# Modèle Additif Généralisé (GAM)

Examinons un exemple! Nous allons utiliser le jeu de données `ISIT`.


```r
isit &lt;- read.csv("data/ISIT.csv")
head(isit)
```

Ce jeu de donnée comporte des mesures de bioluminescence en relation à la profondeur (*depth*), la station de rechercher et la saison (*Season*).



Prenons que les données de la deuxième saison pour l'instant



```r
isit2 &lt;- subset(isit, Season==2)
```

---
# GAM

Si nous modélisions la mesure de bioluminescence selon la profondeur par une régression linéaire, les résultats ne respecteraient pas les suppositions énumérées ci-dessus.

```r
linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2)
data_plot &lt;- ggplot(isit2, aes(y = Sources, x = SampleDepth)) + geom_point() +
             geom_line(colour = "red", size = 1.2, aes(y = fitted(linear_model))) + theme_bw()
data_plot
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-5-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
exclude:true
# Modèles Additifs Généralisés (GAMs)

Examinons un exemple! Premièrement, nous allons générer des données et les représenter graphiquement.


```r
library(ggplot2)
set.seed(10)
n &lt;- 250
x &lt;- runif(n,0,5)
y_model &lt;- 3*x/(1+2*x)
y_obs &lt;- rnorm(n,y_model,0.1)
data_plot &lt;- qplot(x, y_obs) +
  geom_line(aes(y=y_model)) +
  theme_bw()
data_plot
```

---
exclude:true
# GAM




---
exclude:true
# GAM

Si nous modélisions cette relation par une régression linéaire, les résultats ne respecteraient pas les suppositions énumérées ci-dessus.



---
# GAM

**Relation entre la variable réponse et le prédicteur**

Une variable prédicteur:
`$$y_i = \beta_0 + f(x_i) + \epsilon$$`

Plusieurs variables prédicteurs:
`$$y_i = \beta_0 + f_1(x_{1,i}) + f_2(x_{2,i}) + ... + \epsilon$$`


Un des grands avantages d'utiliser un GAM est que la forme optimale de la non-linéarité, i.e. **le degré de lissage** de `\(f(x)\)` est contrôlée en utilisant une régression pénalisée qui est déterminée automatiquement est déterminée automatiquement selon la méthode d'ajustement (généralement le *maximum de vraisemblance* ou *maximum likelihood*).

???

- Au sens strict, les équations concernent un GAM gaussien avec lien d'identité, qui est aussi appelé "modèle additif" (sans "généralisé").

---
#GAM
Essayons de modéliser les données à l'aide d'une fonction de lissage `s(x)` avec `mgcv::gam()`



```r
gam_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2)
```
--



```
...
# Family: gaussian 
# Link function: identity 
# 
# Parametric coefficients:
#             Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept)  12.8937     0.2471   52.17   &lt;2e-16 ***
# 
# Approximate significance of smooth terms:
#                  edf Ref.df     F p-value    
# s(SampleDepth) 8.908  8.998 214.1  &lt;2e-16 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# R-sq.(adj) =   0.81   Deviance explained = 81.4%
# GCV = 28.287  Scale est. = 27.669    n = 453
...
```

---
#GAM

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-11-1.png" width="432" style="display: block; margin: auto;" /&gt;

Note: contrairement à un coefficient fixe `\(\beta\)`, la fonction de lissage peut changer tout au long du gradient `\(x\)`.

---
exclude:true
# GAM

Essayons de modéliser les données à l'aide d'une fonction de lissage `s(x)` avec `mgcv::gam()`


```r
library(mgcv)
gam_model &lt;- gam(y_obs ~ s(x))
summary(gam_model)

data_plot &lt;- data_plot +
     geom_line(colour = "blue", size = 1.2, aes(y = fitted(gam_model)))
data_plot
```

---
exclude:true
# GAM



---
exclude:true
# GAM



.comment[Note: contrairement à un coefficient fixe `\(\beta\)`, la fonction de lissage peut changer tout au long du gradient `\(x\)`]


---
# GAM

La librairie `mgcv` comprend également une fonction plot qui, par défaut, nous permet de visualiser la non-linéarité du modèle :


```r
plot(gam_model)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-15-1.png" width="396" style="display: block; margin: auto;" /&gt;

---
# Test de linéarité avec GAM

Nous pouvons utiliser les fonctions `gam()` et `AIC()` pour tester formellement si une hypothèse de linéarité est justifiée. Nous devons simplement le configurer de sorte que notre modèle non-linéaire soit emboîté dans notre modèle linéaire.


```r
linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2) # fit a regular linear model using gam()
nested_gam_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2)
AIC(linear_model, nested_gam_model)
#                        df      AIC
# linear_model      3.00000 3143.720
# nested_gam_model 10.90825 2801.451
```

**Le modèle linéaire à une valeur de AIC plus élevé, donc l'hypothèse de linéarité n'est pas acceptée.**

.comment[Noté que le modèle `y ~ s(x)` est emboité dans  `y ~ x`.]

---
exclude:true
# Test de linéarité avec GAM

On peut utiliser `gam()` et `AIC()` pour tester si une supposition de linéarité est justifiée. Ici, on demande si l'ajout d'une fonction lisse au modèle linéaire améliore l'ajustement du modèle à nos données:


```r
linear_model &lt;- gam(y_obs ~ x) # ajuster un modèle linéaire régulier avec gam()
nested_gam_model &lt;- gam(y_obs ~ s(x) + x)
AIC(linear_model, nested_gam_model, test = "Chisq")
```

---
exclude:true
# Test de linéarité avec GAM


```r
linear_model &lt;- gam(y_obs ~ x) # ajuster un modèle linéaire régulier avec gam()
nested_gam_model &lt;- gam(y_obs ~ s(x) + x)
anova(linear_model, nested_gam_model, test = "Chisq")
```

.comment[Notez que le modèle `y_obs ~ s(x)` donne exactement les même résultats que `y_obs ~ s(x) + x`. Nous utilisons `\(s(x) + x\)` pour illustrer l'imbrication du modèle, mais le `\(+ x\)` peut être omis.]

---
# Défi 1 ![:cube]()

Nous allons maintenant essayer cela avec les données du de la saison 1.


```r
isit1 &lt;- subset(isit, Season==1)
```


1. Ajustez un modèle linéaire et un GAM à la relation entre `Sources` et `SampleDepth`.
2. Déterminez si l'hypothèse de linéarité est justifiée pour ces données.
3. Quels sont les degrés de liberté effectifs du terme non-linéaire ?


&lt;!-- nous n'Avons pas encore parler du **edf** --&gt;
---
# Défi 1 - Solution ![:cube]()


```r
linear_model_s1 &lt;- gam(Sources ~ SampleDepth, data = isit1)
gam_model_s1 &lt;- gam(Sources ~ s(SampleDepth), data = isit1)
```

---
# Défi 1 - Solution ![:cube]()

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-21-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
# Défi 1 - Solution ![:cube]()


```r
linear_model_s1 &lt;- gam(Sources ~ SampleDepth, data = isit1)
nested_gam_model_s1 &lt;- gam(Sources ~ s(SampleDepth) + SampleDepth,data = isit1)

AIC(linear_model_s1, nested_gam_model_s1)
#                           df      AIC
# linear_model_s1     3.000000 2324.905
# nested_gam_model_s1 9.644938 2121.249
```


---
# Défi 1 - Solution ![:cube]()


```r
nested_gam_model_s1
# 
# Family: gaussian 
# Link function: identity 
# 
# Formula:
# Sources ~ s(SampleDepth) + SampleDepth
# 
# Estimated degrees of freedom:
# 7.44  total = 8.64 
# 
# GCV score: 32.13946     rank: 10/11
```


**Réponse** Oui, la non-linéarité est justifiée. Les degrés de liberté effectifs (**EDF**) sont &gt;&gt; 1 (on reviendra la dessus bientôt).

---
exclude:true
# Défi 1 ![:cube]()

Nous allons maintenant essayer cela avec d'autres données générées aléatoirement.


```r
n &lt;- 250
x_test &lt;- runif(n, -5, 5)
y_test_fit &lt;- 4 * dnorm(x_test)
y_test_obs &lt;- rnorm(n, y_test_fit, 0.2)
```

1. Ajustez un modèle linéaire et un GAM à la relation entre `x_test` et `y_test_obs`.
2. Déterminez si l'hypothèse de linéarité est justifiée pour ces données.
3. Quels sont les degrés de liberté effectifs du terme non-linéaire ?


&lt;!-- nous n'avons pas parlé de degrés de liberté avant... --&gt;

---
exclude:true
# Défi 1 - Solution ![:cube]()


```r
linear_model_test &lt;- gam(y_test_obs ~ x_test)
nested_gam_model_test &lt;- gam(y_test_obs ~ s(x_test) + x_test)

AIC(linear_model_test, nested_gam_model_test, test="Chisq")
```

---
exclude:true
# Défi 1 - Solution ![:cube]()


```r
qplot(x_test, y_test_obs) +
  geom_line(aes(y = y_test_fit)) +
  theme_bw()
```

---
exclude:true
# Défi 1 - Solution ![:cube]()


```r
nested_gam_model_test
```

**Réponse** Oui la non-linéarité est justifiée. Les degrés de liberté effectifs (**EDF**) sont &gt;&gt; 1 (on reviendra la dessus bientôt).

---
# Le fonctionnement des GAMs

Nous allons maintenant prendre quelques minutes pour regarder comment fonctionnent les GAMs. Commençons en considérant d'abord un modèle qui contient une fonction lisse `\(f\)` d'une covariable, `\(x\)` :

`$$y_i = f(x_i) + \epsilon_i$$`

Pour estimer la fonction `\(f\)`, nous avons besoin de représenter l'équation ci-dessus de manière à ce qu'elle devienne un modèle linéaire. Cela peut être fait en définissant des fonctions de base, `\(b_j(x)\)`, dont est composée `\(f\)` :

`$$f(x) = \sum_{j=1}^q b_j(x) \times \beta_j$$`

---
# Exemple : une base polynomiale

Supposons que `\(f\)` est considérée comme un polynôme d'ordre 4, de sorte que l'espace des polynômes d'ordre 4 et moins contient `\(f\)`. Une base de cet espace serait alors :

`$$b_0(x)=1 \ , \quad b_1(x)=x \ , \quad b_2(x)=x^2 \ , \quad b_3(x)=x^3 \ , \quad b_4(x)=x^4$$`

Alors `\(f(x)\)` devient :

`$$f(x) = \beta_0 + x\beta_1 +  x^2\beta_2 + x^3\beta_3 + x^4\beta_4$$`

... et le modèle complet devient :

`$$y_i = \beta_0 + x_i\beta_1 +  x^2_i\beta_2 + x^3_i\beta_3 + x^4_i\beta_4 + \epsilon_i$$`

---
# Exemple : une base polynomiale

Chaque fonction de base est multipliée par un paramètre à valeur réelle, `\(\beta_j\)`, et est ensuite additionnée pour donner la &lt;font color="orange"&gt;courbe finale `\(f(x)\)`&lt;/font&gt;.

.center[
![:scale 85%](images/polynomial_basis_example.png)
]

En faisant varier le coefficient `\(\beta_j\)`, on peut faire varier la forme de `\(f(x)\)` pour produire une fonction polynomiale d'ordre 4 ou moins.

---
# Exemple : une base de spline cubique

Un spline cubique est une courbe construite à partir de sections d'un polynôme cubique reliées entre elles de sorte qu'elles sont continues en valeur. Chaque section du spline a des coefficients différents.

.center[
![](images/cubic_spline.png)
]

---
# Exemple : une base de spline cubique

Voici une représentation d'une fonction lisse utilisant une base de régression spline cubique de rang 5 avec des nœuds situés à incréments de 0.2:

.center[
![:scale 40%](images/cubic_spline5.jpg)
]

Dans cet exemple, les nœuds sont espacés uniformément à travers la gamme des valeurs observées de x. Le choix du degré de finesse du modèle est pré-déterminé par le nombre de nœuds, qui était arbitraire.

.comment[Y a-t-il une meilleure façon de sélectionner les emplacements des nœuds?]

---
# Contrôler le degré de lissage avec des splines de régression pénalisés

Au lieu de contrôler le lissage (non linéarité) en modifiant le nombre de nœuds, nous gardons celui-ci fixé à une taille un peu plus grande que raisonnablement nécessaire et on contrôle le lissage du modèle en ajoutant une pénalité sur le niveau de courbure. Donc, plutôt que d'ajuster le modèle en minimisant (comme avec la méthode des moindres carrés) :

`$$||y - XB||^{2}$$`

Le modèle peut être ajusté en minimisant:

`$$||y - XB||^{2} + \lambda \int_0^1[f^{''}(x)]^2dx$$`

Quand `\(\lambda\)` tend vers `\(∞\)`, le modèle devient linéaire.

---
# Contrôler le degré de lissage avec des splines de régression pénalisés

Si `\(\lambda\)` est trop élevé, les données seront trop lissées et si elle est trop faible, les données ne seront pas assez lissées. Idéalement, il serait bon de choisir une valeur `\(\lambda\)` de sorte que le `\(\hat{f}\)` prédit est aussi proche que possible du `\(f\)` observé. Un critère approprié pourrait être de choisir `\(\lambda\)` pour minimiser :

`$$M = 1/n \times \sum_{i=1}^n (\hat{f_i} - f_i)^2$$`

Étant donné que `\(f\)` est inconnue, `\(M\)` doit être estimé. Les méthodes recommandées pour ce faire sont le maximum de vraisemblance (maximum likelihood, *ML*) ou l'estimation par maximum de vraisemblance restreint (restricted maximum likelihood, *REML*). La validation croisée généralisée (*GCV*) est une autre possibilité.

---
exclude:true
# Principe de validation croisée

.center[
![:scale 60%](images/smooth_sel.png)
]

1. ajustement faible par rapport aux données et ne fait pas mieux avec le point manquant.



2. très bon ajustement de la courbe du signal sous-jacent, le lissage passe à travers le bruit et la donnée manquante est plutôt bien prédite.



3. la courbe ajuste le bruit aussi bien que le signal, la variabilité supplémentaire amène à prédire la donnée manquante plutôt mal.

---
exclude:true
# Principe de validation croisée

.center[
![](images/gcv.png)
]


---
class: inverse, center, middle

## 3. GAM avec plusieurs termes non-linéaires
---
# GAM à plusieurs variables

Avec les GAMs, il est facile d'ajouter des termes non linéaires et linéaires dans un seul modèle, plusieurs termes non linéaires ou même des interactions non linéaires.

Dans cette section, nous allons utiliser les données de `ISIT` de nouveau.


```r
isit
isit$Season &lt;- as.factor(isit$Season)
```

Nous allons essayer de modéliser la réponse `Sources` avec les prédicteurs `Season` and `SampleDepth` simultanément.

.comment[La variable `Season` doit etre convertie en facteur]

---
# GAM à plusieurs variables

Commençons par un modèle de base comprenant un terme non linéaire (`SampleDepth`) et un facteur qualitatif (`Season` avec 2 niveaux).



```r
isit$Season &lt;- as.factor(isit$Season)
basic_model &lt;- gam(Sources ~ Season + s(SampleDepth), data = isit, method = "REML")
basic_summary &lt;- summary(basic_model)
```

La sortie de `p.table` donne des informations sur les termes paramétriques :


```r
basic_summary$p.table
#             Estimate Std. Error  t value     Pr(&gt;|t|)
# (Intercept) 7.253273  0.3612666 20.07734 1.430234e-72
# Season2     6.156130  0.4825491 12.75752 5.525673e-34
```

Le tableau `s.table` nous donne donne des informations sur le terme non linéaire :


```r
basic_summary$s.table
#                     edf   Ref.df        F p-value
# s(SampleDepth) 8.706426 8.975172 184.3583       0
```


---
exclude:true
# GAM à plusieurs variables

Avec les GAMs, il est facile d'ajouter des termes non linéaires et linéaires dans un seul modèle, plusieurs termes non linéaires ou même des interactions non linéaires.

Dans cette section, nous allons utiliser un ensemble de données générées automatiquement par `mgcv::gamSim()`.


```r
# ?gamSim
gam_data &lt;-  gamSim(eg = 5)
head(gam_data)
```

Nous allons essayer de modéliser la réponse `y` avec les prédicteurs `x0` à `x3`.

---
exclude:true
# GAM à plusieurs variables

Commençons par un modèle de base comprenant un terme non linéaire (`x1`) et un facteur qualitatif (`x0` avec 4 niveaux).


```r
basic_model &lt;- gam(y ~ x0 + s(x1), data = gam_data)
basic_summary &lt;- summary(basic_model)
basic_summary$p.table

basic_summary$s.table
```
.comment[La sortie de `p.table` fournit le tableau de résultats pour chaque terme paramétrique

Le tableau `s.table` nous donne les résultats du terme non linéaire.
]

---
# GAM à plusieurs variables


```r
plot(basic_model, all.terms = TRUE,page = 1)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-35-1.png" width="864" style="display: block; margin: auto;" /&gt;

--

Entre les saisons, il y a une différence marquée dans la bioluminescence.

---
# Degrés de liberté effectifs (EDF)


```r
basic_summary$s.table
#                     edf   Ref.df        F p-value
# s(SampleDepth) 8.706426 8.975172 184.3583       0
```

Les `edf` indiqués dans le tableau `s.table` correspond aux **degrés de liberté effectifs** de la fonction lisse -– essentiellement, plus d'**EDF**, plus la non-linéarité est forte.

- Une valeur proche de 1 se rapproche d'un terme linéaire.

- Une valeur elevée signifie que la courbe est non-linéaire.

&gt; Dans notre modèle de base, les **EDF** du terme non-linéaire `s(SampleDepth)` sont ~9, ce qui suggère une courbe fortement non-linéaire.

---
# Degrés de liberté effectifs (EDF)

Les **EDF** dans un GAM sont estimés différemment des degrés de liberté dans une régression linéaire.

Dans la régression linéaire, les degrés de liberté du *modèle* sont équivalents au nombre de paramètres libres non redondants, `\(p\)`, dans le modèle (et les degrés de liberté *résiduels* sont égaux à `\(n-p\)`).

Parce que le nombre de paramètres libres des splines de lissage (tel que les GAMs) est souvent difficile à définir, les **EDF** sont liés à `\(\lambda\)`, où l'effet de la pénalité est de réduire les degrés de liberté.

---

# Dimensions de base et EDF

La limite supérieure d'**EDF** est déterminée par les dimensions de base `\(k\)` de la fonction lisse (les **EDF** ne peut pas dépasser `\(k-1\)`)

En pratique, le choix exact de `\(k\)` est arbitraire, mais il devrait être **suffisamment grand** pour permettre une fonction lisse suffisamment complexe.

Nous discuterons du choix de `\(k\)` dans la section 5.

---

# GAM à plusieurs variables linéaires et lisses

Nous pouvons ajouter un second terme, `RelativeDepth`, mais spécifier une relation linéaire avec `Sources`


```r
two_term_model &lt;- gam(Sources ~ Season + s(SampleDepth) + RelativeDepth,
                      data = isit, method = "REML")
two_term_summary &lt;- summary(two_term_model)
```

Informations sur les effets paramétriques (termes linéaires) :


```r
two_term_summary$p.table
#                   Estimate   Std. Error   t value     Pr(&gt;|t|)
# (Intercept)    9.808305503 0.6478741951 15.139213 1.446613e-45
# Season2        6.041930627 0.4767977508 12.671894 1.380010e-33
# RelativeDepth -0.001401908 0.0002968443 -4.722705 2.761048e-06
```

Informations sur les effets additifs (termes non linéaires) :


```r
two_term_summary$s.table
#                     edf  Ref.df        F p-value
# s(SampleDepth) 8.699146 8.97396 132.4801       0
```

---

# GAM à plusieurs variables

Nous pouvons ajouter un second terme, `RelativeDepth`, mais spécifier une relation linéaire avec `Sources`


```r
plot(two_term_model, page=1, all.terms = T)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-40-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# GAM à plusieurs variables


Nous pouvons aussi vérifier que la relation entre `Sources` et `RelativeDepth` est non-linéaire.


```r
two_smooth_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth),
                        data = isit, method = "REML")
two_smooth_summary &lt;- summary(two_smooth_model)
```

Informations sur les effets paramétriques (termes linéaires) :


```r
two_smooth_summary$p.table
#             Estimate Std. Error  t value     Pr(&gt;|t|)
# (Intercept) 7.937755  0.3452945 22.98836 1.888513e-89
# Season2     4.963951  0.4782280 10.37988 1.029016e-23
```

Informations sur les effets additifs (termes non linéaires) :


```r
two_smooth_summary$s.table
#                       edf   Ref.df         F p-value
# s(SampleDepth)   8.752103 8.973459 150.37263       0
# s(RelativeDepth) 8.044197 8.749580  19.97476       0
```


---
# GAM à plusieurs variables


Nous pouvons aussi vérifier que la relation entre `Sources` et `RelativeDepth` est non-linéaire.


```r
plot(two_smooth_model, page = 1, all.terms = TRUE)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-44-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# GAM à plusieurs variables


Comme précédemment, nous pouvons comparer nos modèles avec AIC pour tester si le terme non-linéaire améliore la performance de notre modèle:


```r
AIC(basic_model, two_term_model, two_smooth_model)
#                        df      AIC
# basic_model      11.83374 5208.713
# two_term_model   12.82932 5188.780
# two_smooth_model 20.46960 5056.841
```

.alert[Le meilleur modèle est le modèle avec deux fonctions non linéaires.]

---
exclude:true
# GAM à plusieurs variables

Nous pouvons ajouter un second terme, `x2`, mais spécifier une relation linéaire avec `y`


```r
two_term_model &lt;- gam(y ~ x0 + s(x1) + x2, data = gam_data)
two_term_summary &lt;- summary(two_term_model)
two_term_summary$p.table

two_term_summary$s.table
```

---
exclude:true
# GAM à plusieurs variables

Nous pouvons ajouter un second terme, `x2`, mais spécifier une relation linéaire avec `y`


```r
plot(two_term_model, all.terms = TRUE)
```


---
exclude:true
# GAM à plusieurs variables

Nous pouvons aussi explorer si la relation entre `y` et `x2` est non-linéaire


```r
two_smooth_model &lt;- gam(y ~ x0 + s(x1) + s(x2), data = gam_data)
two_smooth_summary &lt;- summary(two_smooth_model)
two_smooth_summary$p.table

two_smooth_summary$s.table
```

---
exclude:true
# GAM à plusieurs variables

Nous pouvons aussi explorer si la relation entre `y` et `x2` est non-linéaire


```r
plot(two_smooth_model, page = 1, all.terms = TRUE)
```

---
exclude:true
# GAM à plusieurs variables

Comme avant, nous pouvons faire une AIC pour tester si le terme non-linéaire est nécessaire


```r
AIC(basic_model, two_term_model, two_smooth_model)
```

--

On peut voir que `two_smooth_model` a la plus petite valeur AIC.

.alert[Le modèle le mieux ajusté comprend donc deux fonctions non-linéaires pour `SampleDepth` et `RelativeDepth`, et un terme linéaire pour `Season`.]

---
# Défi 2 ![:cube]()

&lt;br&gt;

Pour notre deuxième défi, nous allons développer notre modèle en ajoutant des variables qui, selon nous, pourraient être des prédicteurs écologiquement significatifs pour expliquer la bioluminescence. 

1. Créez deux nouveaux modèles: Ajoutez la variable `Latitude` à `two_smooth_model`, premièrement comme paramètre linéaire, et ensuite comme fonction non-linéaire.

2. Est-ce que `Latitude` est un terme important à inclure dans le modèle? La `Latitude` a-t-elle un effet linéaire ou non-linéaire? 

Utilisez des graphiques, les tables des coefficients et la fonction `AIC()` pour répondre à ces questions.


---
exclude:true
# Défi 2 ![:cube]()

&lt;br&gt;

1. Créez deux nouveaux modèles avec la variable `x3` comme paramètre linéaire et non linéaire.
2. Utilisez des graphiques, les tables des coefficients et la fonction `AIC()` afin de déterminer s'il est nécessaire d'inclure `x3` dans le modèle.

---
# Défi 2 - Solution ![:cube]()


```r
# Ajouter Latitude comme terme linéaire
three_term_model &lt;- gam(Sources ~ 
                          Season + s(SampleDepth) + s(RelativeDepth) + 
                          Latitude, 
                        data = isit, method = "REML")
three_term_summary &lt;- summary(three_term_model)

# Ajouter Latitude comme terme non-linéaire
three_smooth_model &lt;- gam(Sources ~ 
                            Season + s(SampleDepth) + s(RelativeDepth) + 
                            s(Latitude),
                          data = isit, method = "REML")
three_smooth_summary &lt;- summary(three_smooth_model)
```

---
# Défi 2 - Solution ![:cube]()

__2.__ Est-ce que `Latitude` est un terme important à inclure dans le modèle? 

Commençons par visualiser les 4 effets qui sont maintenant inclus dans chaque modèle. 
---
# Défi 2 - Solution ![:cube]()


```r
plot(three_term_model, page = 1, all.terms = TRUE)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-53-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Défi 2 - Solution ![:cube]()


```r
plot(three_smooth_model, page = 1, all.terms = TRUE)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-55-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
exclude:true
# Défi 2 - Solution ![:cube]()

&lt;br&gt;

```r
three_term_model &lt;- gam(y ~ x0 + s(x1) + s(x2) + x3, data = gam_data)
three_smooth_model &lt;- gam(y~x0 + s(x1) + s(x2) + s(x3), data = gam_data)
three_smooth_summary &lt;- summary(three_smooth_model)
```

---
# Défi 2 - Solution ![:cube]()


```r
plot(three_smooth_model, page = 1, all.terms = TRUE)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-58-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Défi 2 - Solution ![:cube]()

Nous devrions également examiner nos tableaux de coefficients. Qu'est-ce que les EDF nous disent à propos de _l'ondulation_, ou la non-linéarité, des effets de nos prédicteurs?


```r
three_smooth_summary$s.table
#                       edf   Ref.df         F p-value
# s(SampleDepth)   8.766891 8.975682 68.950905       0
# s(RelativeDepth) 8.007411 8.730625 17.639321       0
# s(Latitude)      7.431116 8.296838  8.954349       0
```

--

Les EDF sont tous élevés pour nos variables, y compris `Latitude`. 

Cela nous indique que `Latitude` est assez _ondulée_, et qu'elle ne devrait probablement pas être incluse comme terme linéaire.

---
# Défi 2 - Solution ![:cube]()

Avant de décider quel modèle est le "meilleur", nous devrions tester si l'effet `Latitude` est plus approprié comme terme linéaire ou lisse, en utilisant `AIC()`:


```r
AIC(three_smooth_model, three_term_model)
#                          df      AIC
# three_smooth_model 28.20032 4990.546
# three_term_model   21.47683 5051.415
```

--

Notre modèle incluant la `Latitude` comme terme _non-linéaire_ a un score AIC inférieur, ce qui signifie qu'il est plus performant que notre modèle incluant la `Latitude` comme terme _linéaire_. 

--

Mais, est-ce que l'ajout de `Latitude` comme prédicteur non-linéaire améliore réellement notre "meilleur" modèle (`two_smooth_model`)?

---
# Défi 2 - Solution ![:cube]()


```r
AIC(two_smooth_model, three_smooth_model)
#                          df      AIC
# two_smooth_model   20.46960 5056.841
# three_smooth_model 28.20032 4990.546
```

Notre `three_smooth_model` a un score AIC inférieur à notre meilleur modèle précédent (`two_smooth_model`), qui n'incluait pas `Latitude`. 

--

Ceci implique que `Latitude` est en effet un prédicteur informatif non-linéaire de la bioluminescence.

---
class: inverse, center, middle

## 4. Intéractions
---
# GAM avec des termes d'interaction

Il y a deux façons de modéliser une interaction entre deux variables :

- pour deux variables non-linéaire : `s(x1, x2)`
- pour une variable non-linéaire et une variable linéaire (quantitative ou qualitative) : utiliser l'argument `by`, `s(x1, by = x2)`
  - Quand `x2` est qualitative, vous avez un terme non linéaire qui varie entre les différents niveaux de `x2`
  - Quand `x2` est quantitative, l'effet linéaire de `x2` varie avec `x1`
  - Quand `x2` est qualitative, le facteur doit être ajouté comme effet principal dans le modèle

---
# GAM avec des termes d'interaction

Nous allons examiner l'effet de l'interaction en utilisant notre variable qualitative `Season` et examiner si la non-linéarité de `s(SampleDepth)` varie selon les différents niveaux de `Season`.


```r
factor_interact &lt;- gam(Sources ~ Season +
                         s(SampleDepth,by=Season) +
                         s(RelativeDepth),
                       data = isit, method = "REML")

summary(factor_interact)$s.table
#                             edf   Ref.df          F p-value
# s(SampleDepth):Season1 6.839386 7.552045  95.119422       0
# s(SampleDepth):Season2 8.744574 8.966290 154.474325       0
# s(RelativeDepth)       6.987223 8.055898   6.821074       0
```

---
exclude:true
# GAM avec des termes d'interaction

Nous allons examiner l'effet de l'interaction en utilisant notre variable qualitative `x0` et examiner si la non-linéarité de `s(x2)` varie selon les différents niveaux de `x0`.


```r
factor_interact &lt;- gam(y ~ x0 + s(x1) + s(x2, by = x0), data = gam_data)

summary(factor_interact)$s.table
```

---
# GAM avec des termes d'interaction


```r
plot(factor_interact, page = 1)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-64-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
exclude:true
# GAM avec des termes d'interaction

Nous pouvons aussi visualiser notre modèle en 3D avec `vis.gam`, où `theta` est le degré de rotation de notre plan x-y


```r
vis.gam(factor_interact, view = c("SampleDepth","Season"), theta = 40, n.grid = 500, border = NA)
```

---
# GAM avec des termes d'interaction

Faisons une comparaison de modèle avec AIC pour déterminer si le terme d'interaction est nécessaire


```r
AIC(two_smooth_model, factor_interact)
#                        df      AIC
# two_smooth_model 20.46960 5056.841
# factor_interact  26.99693 4878.631
```

À partir des graphiques, on voit que les formes des termes non-linéaires sont comparables parmi les 2 niveaux de `Season`. L'AIC confirme cela aussi.

---
# GAM avec des termes d'interaction

Finalement, nous regardons les interactions entre 2 termes non linéaires, `SampleDepth` et `RelativeDepth`.


```r
smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth),
                       data = isit, method = "REML")
summary(smooth_interact)$s.table
#                                   edf Ref.df        F p-value
# s(SampleDepth,RelativeDepth) 27.12521  28.77 93.91722       0
```

--

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-68-1.png" width="504" style="display: block; margin: auto;" /&gt;


---

# GAM avec des termes d'interaction


```r
vis.gam(smooth_interact, view = c("SampleDepth", "RelativeDepth"),
        cond = list(Season = 1), theta=40, n.grid = 50, color = "cm")
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-69-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# GAM avec des termes d'interaction


```r
AIC(two_smooth_model, smooth_interact)
#                        df      AIC
# two_smooth_model 20.46960 5056.841
# smooth_interact  30.33625 4943.890
```

Le modèle avec l'intéraction entre `s(SampleDepth)` et `s(RelativeDepth)` a une plus petite valeur d'AIC et le graphique en 2D illustre bien cette intéraction non-linéaire, où `Sources` est faible pour de fortes valeurs de `SampleDepth` mais élevé pour de moyennes à hautes  valeurs de `RelativeDepth`.

---
class: inverse, center, middle

# 5. Généralisation du modèle additif


---

# Généralisation du modèle additif

Le modèle additif de base peut être étendu de plusieurs façons :

1. Utiliser d'autres distributions pour la variable de réponse avec l'argument `family` (comme dans un GLM),
2. Utiliser de différents types de fonctions de base,
3. Utilisation de différents types d'effets aléatoires pour ajuster des modèles à effets mixtes.


Nous allons maintenant examiner ces aspects.


---

# Modèle additif généralisé

Jusqu'à présent, nous avons utilisé des modèles additifs simples (gaussiens), l'équivalent non linéaire d'un modèle linéaire.

--

Mais que pouvons-nous faire si :
- les observations de la variable de réponse ne **suivent pas une distribution normale** ?
- la **variance n'est pas constante** ? (hétéroscédasticité)

--

.comment[Ces situations se produisent fréquemment !]

Tout comme les modèles linéaires généralisés (GLM), nous pouvons formuler des modèles additifs **généralisés** pour répondre à ces problèmes.

---

# Modèle additif généralisé


Rappelons le modèle d'interaction pour les données de bioluminescence :


```r
smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth),
                       data = isit, method = "REML")

summary(smooth_interact)$p.table
#             Estimate Std. Error   t value     Pr(&gt;|t|)
# (Intercept) 8.077356  0.4235432 19.070912 1.475953e-66
# Season2     4.720806  0.6559436  7.196969 1.480113e-12

summary(smooth_interact)$s.table
#                                   edf Ref.df        F p-value
# s(SampleDepth,RelativeDepth) 27.12521  28.77 93.91722       0
```

---

# Validation d'un GAM

Comme pour un GLM, il est essentiel de vérifier si nous avons correctement spécifié le modèle, en particulier la *distribution* de la réponse.

**Il faut vérifier :**

1. Le choix des dimensions de base `k`.
2. Les tracés des résidus (comme pour un GLM).


--

&lt;br&gt;
Fonctions incluses dans `mgcv` :

- `k.check()` effectue une vérification des dimensions de base.
- `gam.check()` produit des tracés de résidus (et fournit également la sortie de `k.check()`.


---

# Validation d'un GAM

##### Première étape :

Avons-nous choisi `k` assez grand ?

.comment[Le défaut pour les interactions lisses est `k = 30`].


```r
k.check(smooth_interact)
#                              k'      edf   k-index p-value
# s(SampleDepth,RelativeDepth) 29 27.12521 0.9448883   0.055
```

--

Les **EDF se rapprochent beaucoup de** `k`, cela pourrait être problématique.

---

# Validation d'un GAM

Refaisons le modèle avec un `k` plus grand :


```r
smooth_interact_k60 &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60),
                           data = isit, method = "REML")
summary(smooth_interact_k60)$p.table
#             Estimate Std. Error   t value     Pr(&gt;|t|)
# (Intercept) 8.129512  0.4177659 19.459491 1.911267e-68
# Season2     4.629964  0.6512205  7.109672 2.741865e-12
summary(smooth_interact_k60)$s.table
#                                   edf   Ref.df        F p-value
# s(SampleDepth,RelativeDepth) 46.03868 54.21371 55.19817       0
```

--

Est-ce que `k` est assez grand ?


```r
k.check(smooth_interact_k60)
#                              k'      edf  k-index p-value
# s(SampleDepth,RelativeDepth) 59 46.03868 1.048626   0.905
```

--

C'est mieux, remplaçons l'ancien modèle :


```r
smooth_interact &lt;- smooth_interact_k60
```

---

# Validation d'un GAM

##### Deuxième étape :

Regardons les tracés des résidus, en utilisant `gam.check()` :


```r
par(mfrow = c(2,2)) # Afficher les 4 tracés à la fois
gam.check(smooth_interact)
```

.comment[En plus des graphiques, `gam.check()` fournit également la sortie de `k.check()`].

---

# Validation d'un GAM

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-77-1.png" width="576" style="display: block; margin: auto;" /&gt;

--
&lt;br&gt;

.alert[Hétéroscédasticité marquée et tendances dans les résidus]


???

- Ces tracés sont un peu différents de ceux produits par `plot` pour un modèle linéaire (par exemple, pas de tracé de levier).
- Les participants devraient déjà être familiarisés avec les graphiques de résidus (ils sont expliqués plus en détail dans les ateliers 4 et 6).
- Problème : hétéroscédasticité, visible dans "residuals vs. linear predictor".
- Autre problème : quelques observations extrêmes(visibles dans le tracé QQ, et "response vs. fitted").


---

# Autres distributions


Pour notre modèle d'interaction, nous avons besoin d'une distribution de probabilité qui permet à la **variance d'augmenter avec la moyenne**.

--

Une famille de distributions qui possède cette propriété et qui fonctionne bien dans un GAM est la famille **Tweedie**.

Une fonction de liaison commune pour les distributions *Tweedie* est le `\(log\)`.

--

&lt;br&gt;

Comme dans un GLM, nous pouvons utiliser l'argument `family = ` dans `gam()` pour ajuster des modèles avec d'autres distributions (y compris des distributions telles que `binomial`, `poisson`, `gamma` etc).

Pour en savoir plus sur les familles disponibles dans `mgcv` :

```r
?family.mgcv
```


---

# Défi 3 ![:cube]()

1. Ajuster un nouveau modèle `smooth_interact_tw` avec la même formule que le modèle `smooth_interact` mais avec une distribution de la famille *Tweedie* (au lieu de la distribution normale) et `log` comme fonction de liaison. Pour ce faire, on peut utiliser `family = tw(link = "log")` dans `gam()`.
2. Vérifier le choix de `k` et les tracés de résidus pour le nouveau modèle.
3. Comparer `smooth_interact_tw` avec `smooth_interact`. Lequel est meilleur ?

--

&lt;br&gt;

.comment[Indice :]


```r
# Distribution normale
smooth_interact &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60),
                          data = isit, method = "REML")
# Tweedie avec log comme fonction de liaison
smooth_interact_tw &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60),
                          family = tw(link = "log"),
                          data = isit, method = "REML")
```


---

# Défi 3 - Solution ![:cube]()

Ajuster le modèle :


```r
smooth_interact_tw &lt;- gam(Sources ~ Season + s(SampleDepth, RelativeDepth, k = 60),
                          family = tw(link = "log"),
                          data = isit, method = "REML")
summary(smooth_interact_tw)$p.table
#              Estimate Std. Error  t value      Pr(&gt;|t|)
# (Intercept) 1.3126641 0.03400390 38.60333 8.446478e-180
# Season2     0.5350529 0.04837342 11.06089  1.961733e-26
summary(smooth_interact_tw)$s.table
#                                   edf   Ref.df        F p-value
# s(SampleDepth,RelativeDepth) 43.23949 51.57139 116.9236       0
```

--

Vérifier les dimensions de base :

```r
k.check(smooth_interact_tw)
#                              k'      edf  k-index p-value
# s(SampleDepth,RelativeDepth) 59 43.23949 1.015062  0.8475
```

---

# Défi 3 - Solution ![:cube]()

Tracés des résidus :


```r
par(mfrow=c(2,2))
gam.check(smooth_interact_tw)
```


&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-83-1.png" width="576" style="display: block; margin: auto;" /&gt;


???
- Les résidus semblent meilleurs, mais il est évident que le modèle manque quelque chose. Il pourrait s'agir d'un effet spatial (longitude et latitude), ou d'un effet aléatoire (par exemple basé sur `Station`).

---

# Défi 3 - Solution ![:cube]()

Comparer les modèles:


```r
AIC(smooth_interact, smooth_interact_tw)
#                          df      AIC
# smooth_interact    49.47221 4900.567
# smooth_interact_tw 47.86913 3497.733
```

.comment[L'AIC nous permet de comparer des modèles qui sont basés sur des distributions différentes !]

--

Utiliser une distribution *Tweedie* au lieu d'une distribution *normale* améliore beaucoup notre modèle !


---
class: inverse, center, middle

## 6. Changer la fonction de base


---
# Fonctions lisses

Pour modéliser une surface lisse ou non-linéaire, nous pouvons construire des fonctions lisses de différentes manières:

`s()` ![:faic](arrow-right) pour modéliser un terme lisse 1-dimensionnel, ou pour modéliser une intéraction entre des variables mesurées sur la *même échelle*

`te()` ![:faic](arrow-right)  pour modéliser une surface d'interaction 2- ou n-dimensionnel entre des variables qui *ne sont pas sur la même échelle*. Comprend les effets principaux.

`ti()` ![:faic](arrow-right) pour modéliser une surface d'interaction 2- ou n-dimensionnel *qui ne comprend pas les effets principaux*.

---
# Paramètres des fonctions lisses

Les fonctions lisses ont beaucoup de paramètres qui pourraient changer leur comportement. Les paramètres les plus souvent utilisés sont les suivants :

`k` ![:faic](arrow-right) dimensions de base
  - détermine la limite supérieure du nombre de fonctions de base utilisées pour construire la courbe.
  - contraint l'ondulation d'une fonction lisse.
  - par défaut, `\(k\)` est 10 pour `s()`, et 5 pour chaque dimension de `te()` and `ti()`.
  - k devrait être &lt; au nombre de données uniques.
  - la comlexité (ou la non-linéarité) d'une fonction lisse dans un modèle ajusté est reflétée par ses degrés de liberté effectifs (**EDF**)

---
# Paramètres des fonctions lisses

Les fonctions lisses ont beaucoup de paramètres qui pourraient changer leur comportement. Les paramètres les plus souvent utilisés sont les suivants :


`d` ![:faic](arrow-right) spécifie quelles variables d'une intéraction se trouvent sur la même échelle lorsqu'on utilise `te()` and `ti()`.
  - Par exemple, `te(Temps, largeur, hauteur, d=c(1,2))`, indique que la `largeur` et la `hauteur` sont sur la même échelle, mais que `temps` ne l'est pas.

`bs` ![:faic](arrow-right) spécifie la fonction de base sous-jacente.
  - pour `s()` on utilise `tp` (*thin plate regression spline*) et pour `te()` et `ti()` on utilise la base `cr` (*cubic regression spline*).

&lt;!--last 2 slides were a copy-paste from this websites: http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html. However, as I'm not a specialist of GAM, I let them asis, but we should modify them or at least site the website--&gt;

---
# Exemple avec des données cycliques

Les données cycliques sont un bon exemple où changer la base est utile : vous voulez que le prédicteur corresponde à la fin.

Nous allons utiliser une série temporelle de données climatiques, divisées en mesures mensuelles, afin de déterminer s'il y a une tendance de température annuelle.


```r
data(nottem) # Nottingham temperature time series
n_years &lt;- length(nottem)/12
nottem_month &lt;- rep(1:12, times = n_years)
nottem_year &lt;- rep(1920:(1920 + n_years - 1), each = 12)
qplot(nottem_month, nottem, colour = factor(nottem_year), geom = "line") +
  theme_bw()
```

---
# Exemple avec des données cycliques

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-86-1.png" width="864" style="display: block; margin: auto;" /&gt;

---
# Exemple avec des données cycliques

Nous pouvons modéliser le changement cyclique de température à travers les mois et la tendance non-linéaire à travers les années, en utilisant une spline cubique, ou `cc` pour modéliser les effets de mois ainsi qu'un terme non-linéaire pour la variable année.


```r
year_gam &lt;- gam(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"), method = "REML")
summary(year_gam)$s.table
#                      edf   Ref.df          F    p-value
# s(nottem_year)  1.621375 2.011475   2.850888 0.06141004
# s(nottem_month) 6.855132 8.000000 393.119285 0.00000000
```

---
# Exemple avec des données cycliques


```r
plot(year_gam, page = 1, scale = 0)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-88-1.png" width="576" style="display: block; margin: auto;" /&gt;
Il y a une hausse d'environ 1-1.5 degrés au cours de la série, mais au cours d'une année, il y a une variation d'environ 20 degrés. Les données réelles varient autour de ces valeurs prédites et ceci représente donc la variance inexpliquée.


---
class: inverse, center, middle

# 7. Intro rapide aux GAMMs

---
# La non-indépendance des données

Lorsque les observations ne sont pas indépendantes, les GAMs peuvent être utilisés soit pour incorporer :

- une structure de corrélation pour modéliser les résidus autocorrélés (autorégressif (AR), moyenne mobile (MA), ou une combinaison des deux (ARMA)) ,
- des effets aléatoires qui modélisent l'indépendance entre les observations d'un même site.

---
# Modèle avec erreurs autocorrélées

Pour commencer, nous allons jeter un coup d’œil au premier cas; un modèle avec autocorrélation temporelle dans les résidus.

Ré-examinons le modèle de la température de Nottingham et vérifions si les résidus sont corrélés en faisant appel à la fonction (partielle) d'autocorrélation.


```r
par(mfrow = c(1,2))
acf(resid(year_gam), lag.max = 36, main = "ACF")
pacf(resid(year_gam), lag.max = 36, main = "pACF")
```

---
# Modèle avec erreurs autocorrélées

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-90-1.png" width="612" style="display: block; margin: auto;" /&gt;

.comment[ACF donne la corrélation croisée et pACF la corrélation partielle d'une série temporelle avec elle-même à différent décalage de temps.]

ACF et pACF sont utilisés pour identifier combien d'intervalle de temps sont nécessaires pour que les observations commencent à être indépendantes.

--

Les graphiques des fonctions d'autocorrélation suggèrent qu'un modèle AR de faible ordre est nécessaire (avec un ou deux intervalles de temps décalés).

---
# Modèle avec erreurs autocorrélées

Nous pouvons ajouter des structures d'autocorrelation au modèle :

- **AR(1)** : corrélation avec un intervalle de temps décalé, ou
- **AR(2)** : corrélation à 2 intervalles de temps décalés

--


```r

year_gam &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"))
year_gam_AR1 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"),
                     correlation = corARMA(form = ~ 1|nottem_year, p = 1),
                   data = data.frame(nottem, nottem_year, nottem_month))
year_gam_AR2 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = "cc"),
                     correlation = corARMA(form = ~ 1|nottem_year, p = 2),
                   data = data.frame(nottem, nottem_year, nottem_month))
```

---

# Modèle avec erreurs autocorrélées


```r
AIC(year_gam$lme, year_gam_AR1$lme, year_gam_AR2$lme)
#                  df      AIC
# year_gam$lme      5 1109.908
# year_gam_AR1$lme  6 1101.218
# year_gam_AR2$lme  7 1101.598
```

Le modèle avec la structure AR(1) donne un meilleur ajustement au premier modèle. Mais il y a peu d'intérêt à considérer le modèle AR(2).

---
# Modélisation avec effets mixtes

Comme nous l'avons vu dans la section précédente, `bs` spécifie la fonction de base sous-jacente. Pour les facteurs aléatoires (origine et pente linéaire), nous utilisons `bs = "re"` et pour les pentes aléatoires non linéaires, nous utilisons `bs = "fs"`.

---
# Modélisation avec effets mixtes

**3 types d'effets aléatoires différents** sont possibles lors de l'utilisation des GAMMs (où `fac` ![:faic](arrow-right) variable qualitative utilisée pour l'effet aléatoire; `x0` ![:faic](arrow-right) effet quantitatif fixe) :

- **interceptes aléatoires** ajustent la hauteur des termes du modèle avec une valeur constante de pente : `s(fac, bs = "re")`
- **pentes aléatoires** ajustent la pente d'une variable explicative numérique : `s(fac, x0, bs = "re")`
- **surfaces lisses aléatoires** ajustent la tendance d'une prédiction numérique de façon non linéaire: `s(x0, fac, bs = "fs", m = 1)`, où l'argument `\(m = 1\)` met une plus grande pénalité au lissage qui s'éloigne de 0, ce qui entraîne un retrait vers la moyenne.

---
# GAMM avec un intercepte aléatoire

Tel que vu précédemment, nous allons utiliser `gamSim()` pour générer un ensemble de données, cette fois-ci avec une composante d'effet aléatoire. Ensuite, nous construirons un modèle avec un intercepte aléatoire en utilisant `fac` comme facteur aléatoire.


```r
gam_data2 &lt;- gamSim(eg = 6)
# 4 term additive + random effectGu &amp; Wahba 4 term additive model
str(gam_data2)
# 'data.frame':	400 obs. of  11 variables:
#  $ y  : num  8.03 11.93 22.44 23.52 11.35 ...
#  $ x0 : num  0.111 0.752 0.455 0.958 0.45 ...
#  $ x1 : num  0.3549 0.2396 0.8521 0.0158 0.1478 ...
#  $ x2 : num  0.828 0.092 0.384 0.203 0.655 ...
#  $ x3 : num  0.108 0.865 0.811 0.271 0.296 ...
#  $ f  : num  6.37 11.99 21.21 21.94 9.6 ...
#  $ f0 : num  0.683 1.404 1.98 0.266 1.976 ...
#  $ f1 : num  2.03 1.61 5.5 1.03 1.34 ...
#  $ f2 : num  0.65 2.97 4.73 8.64 3.28 ...
#  $ f3 : num  0 0 0 0 0 0 0 0 0 0 ...
#  $ fac: Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 1 2 ...
```


---
# GAMM avec un intercepte aléatoire


```r
gamm_intercept &lt;- gam(y ~ s(x0) + s(fac, bs = "re"), data = gam_data2, method = "REML")
summary(gamm_intercept)$s.table
#             edf   Ref.df         F  p-value
# s(x0)  1.941991 2.427264  1.086143 0.294817
# s(fac) 2.969321 3.000000 96.603993 0.000000
plot(gamm_intercept, select = 2)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-94-1.png" width="396" style="display: block; margin: auto;" /&gt;

---
# GAMM avec un intercepte aléatoire

Nous allons premièrement tracer l'effet combiné de `x0` (sans les niveaux de l'effet aléatoire) et ensuite une courbe pour les 4 niveaux de `fac` :


```r
par(mfrow = c(1,2), cex = 1.1)

plot_smooth(gamm_intercept, view = "x0", rm.ranef = T,
            main = "intercept + s(x1)")

plot_smooth(gamm_intercept, view = "x0", cond = list(fac="1"),
            main = "... + s(fac)", col = 'orange', ylim = c(8,21))

plot_smooth(gamm_intercept, view = "x0", cond = list(fac = "2"), add = T, col = 'red')

plot_smooth(gamm_intercept, view="x0", cond = list(fac = "3"), add = T, col = 'purple')

plot_smooth(gamm_intercept, view="x0", cond = list(fac = "4"), add = T, col = 'turquoise')
```

---
# GAMM avec un intercepte aléatoire

&lt;br&gt;

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-96-1.png" width="864" style="display: block; margin: auto;" /&gt;

.pull-right[
&amp;nbsp; &lt;font color="orange"&gt;fac1&lt;/font&gt; &amp;nbsp; &lt;font color="red"&gt;fac2&lt;/font&gt; &amp;nbsp; &lt;font color="purple"&gt;fac3&lt;/font&gt; &amp;nbsp; &lt;font color="turquoise"&gt;fac4&lt;/font&gt;
]


---
# GAMM avec une pente aléatoire


```r
gamm_slope &lt;- gam(y ~ s(x0) + s(x0, fac, bs = "re"), data = gam_data2, method = "REML")

summary(gamm_slope)$s.table
#                edf   Ref.df           F   p-value
# s(x0)     1.005025 1.010032  0.08810443 0.7696836
# s(x0,fac) 2.951658 3.000000 62.47630405 0.0000000
```


---
# GAMM avec une pente aléatoire


```r
par(mfrow = c(1,2), cex = 1.1)

plot_smooth(gamm_slope, view = "x0", rm.ranef = T, main = "intercept + s(x0)")

plot_smooth(gamm_slope, view = "x0", cond = list(fac = "1"),
            main = "... + s(fac)", col = 'orange', ylim = c(7,22))

plot_smooth(gamm_slope, view = "x0", cond = list(fac = "2"), add = T, col = 'red')

plot_smooth(gamm_slope, view = "x0", cond = list(fac = "3"), add = T, col = 'purple')

plot_smooth(gamm_slope, view = "x0", cond = list(fac = "4"), add = T, col = 'turquoise')
```

---
# GAMM avec une pente aléatoire

&lt;br&gt;

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-99-1.png" width="864" style="display: block; margin: auto;" /&gt;

---
# GAMM avec un intercepte et une pente aléatoire


```r
gamm_int_slope &lt;- gam(y ~ s(x0) + s(fac, bs = "re") + s(fac, x0, bs = "re"),
                      data = gam_data2, method = "REML")

summary(gamm_int_slope)$s.table
#                    edf   Ref.df            F   p-value
# s(x0)     1.9419893171 2.427261 1.086045e+00 0.2948499
# s(fac)    2.9692942849 3.000000 9.668629e+01 0.0000000
# s(fac,x0) 0.0008880209 3.000000 9.253175e-05 0.8298992
```

---
# GAMM avec un intercepte et une pente aléatoire


```r
par(mfrow = c(1,2), cex = 1.1)

plot_smooth(gamm_int_slope, view = "x0", rm.ranef = T, main = "intercept + s(x0)")

plot_smooth(gamm_int_slope, view = "x0", cond = list(fac = "1"),
            main="... + s(fac) + s(fac, x0)", col = 'orange', ylim = c(7,22))

plot_smooth(gamm_int_slope, view = "x0", cond = list(fac = "2"), add = T, col='red')

plot_smooth(gamm_int_slope, view = "x0", cond = list(fac = "3"), add = T, col = 'purple')

plot_smooth(gamm_int_slope, view = "x0", cond = list(fac = "4"), add = T, col = 'turquoise')
```

---
# GAMM avec un intercepte et une pente aléatoire

&lt;br&gt;

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-102-1.png" width="864" style="display: block; margin: auto;" /&gt;

---
# GAMM avec un intercepte et une pente aléatoire

Notez que la pente aléatoire est statique dans ce cas :


```r
plot(gamm_int_slope, select = 3)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-103-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# GAMM avec une surface lisse aléatoire


```r
gamm_smooth &lt;- gam(y ~ s(x0) + s(x0, fac, bs = "fs", m = 1),
                   data = gam_data2, method = "REML")

summary(gamm_smooth)$s.table
#                edf    Ref.df        F   p-value
# s(x0)     1.941962  2.427206 1.085964 0.2948811
# s(x0,fac) 2.970993 35.000000 8.280364 0.0000000
```

---
# GAMM avec une surface lisse aléatoire

Ici, si les pentes aléatoires variaient selon `x0`, nous aurons des courbes variables pour chaque niveau :


```r
plot(gamm_smooth, select = 1)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-105-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# GAMM avec une surface lisse aléatoire


```r
par(mfrow = c(1,2), cex = 1.1)

plot_smooth(gamm_smooth, view = "x0", rm.ranef = T, main = "intercept + s(x0)")

plot_smooth(gamm_smooth, view = "x0", cond = list(fac = "1"),
            main="... + s(x0, fac)", col = 'orange', ylim = c(7,22))

plot_smooth(gamm_smooth, view = "x0", cond = list(fac = "2"), add = T, col='red')

plot_smooth(gamm_smooth, view = "x0", cond = list(fac = "3"), add = T, col = 'purple')

plot_smooth(gamm_smooth, view = "x0", cond = list(fac = "4"), add = T, col = 'turquoise')
```

---
# GAMM avec une surface lisse aléatoire

&lt;br&gt;

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-107-1.png" width="864" style="display: block; margin: auto;" /&gt;

.comment[Ici, si la pente aléatoire varie selon `x0`, nous aurons des courbes variables pour chaque niveau.]

---
# GAMM

Tous ces modèles mixtes peuvent être comparés en utilisant la fonction `AIC()` pour trouver le meilleur modèle.


```r
AIC(gamm_intercept, gamm_slope, gamm_int_slope, gamm_smooth)
#                      df      AIC
# gamm_intercept 7.426922 2245.633
# gamm_slope     6.009251 2308.917
# gamm_int_slope 7.428640 2245.636
# gamm_smooth    7.430181 2245.638
```


---
# Ressources

Cet atelier présente une brève introduction aux concepts de base et aux librairies populaires pour vous aider à estimer, évaluer et visualiser les GAMs dans R, mais il y a beaucoup plus à explorer!
&lt;br&gt;&lt;br&gt;
* Le livre [Generalized Additive Models: An Introduction with R](https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331) par Simon Wood (auteur de la librairie `mgcv`).
* Le site web de Simon Wood, [maths.ed.ac.uk/~swood34/](https://www.maths.ed.ac.uk/~swood34/).
* Le blogue de Gavin Simpson, [From the bottom of the heap](https://fromthebottomoftheheap.net/).
* La librairie [`gratia`](https://cran.r-project.org/web/packages/gratia/index.html) de Gavin Simpson for GAM visualisation in `ggplot2`.
* Le cours [Generalized Additive Models: An Introduction with R](https://noamross.github.io/gams-in-r-course/) de Noam Ross.
* [Overview GAMM analysis of time series data](https://jacolienvanrij.com/Tutorials/GAMM.html) tutoriel de Jacolien van Rij.
* [Hierarchical generalized additive models in ecology: an introduction with mgcv](https://peerj.com/articles/6876/) de Pedersen et al. (2019).

Enfin, les pages d'aide, disponibles via `?gam` dans R sont une excellente ressource.

---
class: inverse, center, bottom

# Merci pour votre participation à cet atelier!

&lt;hr&gt;
&lt;br&gt;

![:scale 50%](images/qcbs_logo.png)

---
class: inverse, center, middle

# Exemple supplémentaire avec d'autres distributions

---
# GAM avec d'autres distributions

Un bref aperçu de l'utilisation des GAMs lorsque la variable réponse ne suit pas une distribution normale ou que les données sont des abondances ou proportions (par exemple, distribution Gamma, binomiale, Poisson, binomiale négative).

Nous allons utiliser un exemple de données où une répartition binomiale sera nécessaire; la variable réponse représente le nombre de succès (l'événement a eu lieu) en fonction des défaillances au cours d'une expérience.


```r
gam_data3 &lt;- read.csv("data/other_dist.csv")
str(gam_data3)
# 'data.frame':	514 obs. of  4 variables:
#  $ prop : num  1 1 1 1 0 1 1 1 1 1 ...
#  $ total: int  4 20 20 18 18 18 20 20 20 20 ...
#  $ x1   : int  550 650 750 850 950 650 750 850 950 550 ...
#  $ fac  : chr  "f1" "f1" "f1" "f1" ...
```

&lt;!-- should change the name of the variables in the csv files, to make them meaningful--&gt;

---
# GAM avec d'autres distributions


```r
plot(range(gam_data3$x1), c(0,1), type = "n",
     main = "Probabilités de succès dans le temps",
     ylab = "Probabilité", xlab = "x1 (temps)")
abline(h = 0.5)

avg &lt;- aggregate(prop ~ x1, data=gam_data3, mean)
lines(avg$x1, avg$prop, col = "orange", lwd = 2)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-110-1.png" width="288" style="display: block; margin: auto;" /&gt;

---
# GAM avec d'autres distributions

Nous allons tester si cette tendance est linéaire ou non avec un GAM logistique (nous utilisons une famille de distributions binomiales parce que nous avons des données de proportion).


```r
prop_model &lt;- gam(prop ~ s(x1), data = gam_data3, weights = total,
                  family = "binomial", method = "REML")
prop_summary &lt;- summary(prop_model)
```

&lt;!--Warning messages:
1: In eval(family$initialize) : non-integer #successes in a binomial glm!??--&gt;

--

.comment[Qu'est ce que représente l'intercepte dans ce modèle?]


```r
prop_summary$p.table
#             Estimate Std. Error  z value Pr(&gt;|z|)
# (Intercept) 1.174024 0.02709868 43.32402        0
```

--

.comment[Qu'est ce que le terme de lissage indique?]


```r
prop_summary$s.table
#            edf   Ref.df   Chi.sq p-value
# s(x1) 4.750198 5.791279 799.8463       0
```

---
# GAM avec d'autres distributions


```
#             Estimate Std. Error  z value Pr(&gt;|z|)
# (Intercept) 1.174024 0.02709868 43.32402        0
```

.comment[Que représente l'intercepte dans ce modèle?]

**Rappel** le modèle utilise le nombre de succès vs échecs pour calculer le *logit*, qui est la logarithme du rapport entre les succès et échecs :

.small[
- Si succès = échecs, le rapport = 1 et le logit est de 0 (log(1) = 0).
- Si succès &gt; échecs, le rapport &gt; 1 et le logit a une valeur positive (log(2) = 0.69).
- Si succès &lt; échecs, le rapport &lt; 1 et le logit a une valeur négative (log(.5) = -0.69).
]

--

&gt; Ici, l'estimé est positif ce qui signifie, qu'en moyenne, il y a plus de succès que d'échecs.

---
# GAM avec d'autres distributions


```
#            edf   Ref.df   Chi.sq p-value
# s(x1) 4.750198 5.791279 799.8463       0
```

.comment[Qu'est ce que le terme de lissage indique?]

Cela représente comment le ratio de succès vs échecs change sur l'échelle de `\(x1\)`.

--

&gt; Puisque les **EDF** &gt; 1, la proportion des succès augmente plus rapidement avec `\(x1\)`


```r
plot(prop_model)
```

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-117-1.png" width="309.6" style="display: block; margin: auto;" /&gt;

---
# Visualiser la tendance au fil du temps

Il y a différente façon de représenter cette relation graphiquement :

- **Contribution/effet partiel** correspond aux effets isolés d'une interaction ou prédiction particulière. Si vous visualisez votre modèle GAM avec `plot()`, vous obtenez les effets partiels.
- **effets additionnés** correspond aux mesures réponse prédites pour une valeur ou niveau donné de prédicteurs. Si vous visualisez votre GAM avec `itsadug::plot_smooth()`, vous obtenez les effets additionnés.


---
# Visualiser la tendance au fil du temps

Que nous disent ces graphes sur les succès et échecs?

&lt;img src="workshop08-pres-fr_files/figure-html/unnamed-chunk-118-1.png" width="648" style="display: block; margin: auto;" /&gt;



.pull-left[
**Contribution / effets partiels**

La valeur logit augmente, donc les succès augmentent et les échecs diminuent.]

.pull-right[
**Valeurs ajustées, effets additionnés, intercepte inclu**

Quantités égales de succès et d'échecs jusqu'à `\(x1 = 400\)`.
]

&lt;!-- this code should be shown but it is not well explained...--&gt;
---
# Visualiser la tendance au fil du temps

Enfin, pour nous aider à interpréter les résultats, nous pouvons re-transformer l'effet sur une échelle de proportions avec la fonction `itsadug::plot_smooth()` :


```r
plot_smooth(prop_model, view = "x1", main = "",
            transform = plogis, ylim = c(0,1), print.summary = F)
abline(h = 0.5, v = diff$start, col = 'red', lty = 2)
```

&lt;img src="workshop08-pres-fr_files/figure-html/fig.width==4-1.png" width="432" style="display: block; margin: auto;" /&gt;

Comme précédemment, la proportion de succès augmente au-dessus de 0.5 à `\(x1 = 400\)`.

&lt;!-- again, lack of explanation here...--&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="qcbsR-macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
