[["index.html", "Atelier 8 : Modèles additifs généralisés en R Série d’ateliers R du CSBQ Préface 0.1 Code de conduit 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 8 : Modèles additifs généralisés en R Série d’ateliers R du CSBQ Développé et maintenu par les contributeurs et contributrices de la Série d’ateliers R du CSBQ1. 2022-02-23 16:57:47 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduit La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Cet atelier a été développé à l’origine par Eric Pedersen et Zofia Taranu, et originalement révisé en français by Cédric Frenette Dussault. Depuis 2014, plusieurs membres du CSBQ ont contribué à développer et à mettre à jour cet atelier collaborativement sur une base régulière, dans le cadre du Prix d’apprentissage et de développement du Centre de science de la biodiversité du Québec. Ces membres sont: Daniel Schoenig, Laurie Maynard, Marie-Hélène Brice, Kevin Cazelles, Pedro Henrique P. Braga, Esteban Gongora, Linley Sherin, Eric Pedersen, Zofia Taranu, Cédric Frenette Dussault, Emmanuelle Chrétien, Vincent Fugère. 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. Les contributeurs et contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage L’objectif de l’atelier d’aujourd’hui sera d’examiner ce que nous entendons par un modèle non-linéaire et comment les GAMs (modèles additifs généralisés) nous permettent de modéliser les relations non-linéaires. Nous examinerons également comment tracer et interpréter ces relations non-linéaires, comment ajouter des interactions, comment prendre en compte la non-indépendance des données (e.g. erreurs autocorrélées) et comment inclure des effets aléatoires en se basant sur les ateliers précédents. Enfin, nous allons brièvement aborder la mécanique derrière le fonctionnement des GAMs. Nous vous recommandons d’avoir une certaine expérience de R, en particulier de la consultation de données et d’objets dans des scripts R, et une connaissance de base de la régression linéaire avant de suivre cet atelier. Plus spécifiquement, cet atelier portera sur comment: Utiliser la librairie mgcv pour modéliser les relations non linéaires Évaluer la sortie d’un GAM afin de mieux comprendre nos données Utiliser des tests pour déterminer si nos relations correspondent à des modèles non linéaires ou linéaires Ajouter des interactions non linéaires entre les variables explicatives Comprendre l’idée d’une fonction de base (basis function) et la raison pour laquelle ça rend les GAMs si puissants ! Comment modéliser la dépendance dans les données (autocorrélation, structure hiérarchique) en utilisant les GAMMs "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Tout le matériel de l’atelier se trouve sur r.qcbs.ca/fr/workshops/r-workshop-08/. Cela inclut un script R qui rassemble tous les morceaux de code présentés dans ce livre. Pour cet atelier, nous travaillerons avec les jeux de données suivants : ISIT.csv other_dist.csv Vous devriez également vous assurer que vous avez téléchargé, installé et chargé les paquets R suivants: ggplot2 itsadug mgcv install.packages(&quot;ggplot2&quot;) install.packages(&quot;mgcv&quot;) install.packages(&quot;itsadug&quot;) library(ggplot2) library(mgcv) library(itsadug) "],["intro-linear-models.html", "Chapitre 3 Le modèle linéaire… et où il échoue", " Chapitre 3 Le modèle linéaire… et où il échoue Que veut-on dire par “modèle linéaire”? La régression est la base des statistiques. La régression linéaire est ce que la plupart des gens apprennent avant tout en statistiques et est parmi les méthodes les plus performantes. Elle nous permet de modéliser une variable réponse en fonction de facteurs prédictifs et d’une erreur résiduelle. Comme on a vu dans l’Atelier 4: Modèles linéaires, le modèle linéaire fait quatre suppositions importantes : Relation linéaire entre les variables de réponse et les variables prédicteurs: \\[y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\] L’erreur est distribuée normalement: \\[\\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^2)\\] La variance des erreurs est constante Chaque erreur est indépendante des autres (homoscédasticité) Un modèle linéaire peut parfois s’adapter à certains types de réponses non linéaires (par exemple \\(x^2\\)), mais cette approche repose fortement sur des décisions qui peuvent être soit arbitraires, soit bien informées, et est beaucoup moins flexible que l’utilisation d’un modèle additif. Par exemple, ce modèle linéaire à prédicteurs multiples peut traiter une réponse non linéaire, mais devient rapidement difficile à interpréter et à maîtriser: \\[y_i = \\beta_0 + \\beta_1x_{1,i}+\\beta_2x_{2,i}+\\beta_3x_{3,i}+...+\\beta_kx_{k,i} + \\epsilon_i\\] Les modèles linéaires fonctionnent très bien dans certains cas spécifiques où tous ces critères sont respectés: Dans la réalité, il est souvent impossible de respecter ces critères. Cela signifie que, dans de nombreux cas, les modèles linéaires sont inappropriés: Alors, comment résoudre ce problème ? Pour répondre à cette question, nous devons d’abord considérer ce que le modèle de régression tente de faire. Un modèle linéaire essaye d’ajuster la meilleure droite qui passe au milieu des données sans sur-ajuster les données, ce qui se produirait si nous tracions simplement une ligne entre chaque point et ses voisins. En revanche, les modèles additifs (GAM) ajustent une fonction de lissage non-linéaire à travers les données, tout en contrôlant le degré de courbure de la ligne our éviter un ajustement excessif. Les modèles additifs peuvent donc capturer des relations non linéaires en ajustant une fonction lisse à travers les données, plutôt qu’une ligne droite. Nous reviendrons plus tard sur le degré de courbure de la ligne! "],["introduction-aux-gams.html", "Chapitre 4 Introduction aux GAMs 4.1 Test de linéarité 4.2 Défi 1", " Chapitre 4 Introduction aux GAMs Utilisons un exemple pour démontrer la différence entre une régression linéaire et un modèle additif. Nous allons utiliser le jeu de données ISIT. Ce jeu de donnée comporte des mesures de bioluminescence en relation à la profondeur (depth), la station de rechercher et la saison (Season). isit &lt;- read.csv(&quot;data/ISIT.csv&quot;) head(isit) ## SampleDepth Sources Station Time Latitude Longitude Xkm Ykm Month Year ## 1 517 28.73 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 2 582 27.90 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 3 547 23.44 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 4 614 18.33 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 5 1068 12.38 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 6 1005 11.23 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## BottomDepth Season Discovery RelativeDepth ## 1 3939 1 252 3422 ## 2 3939 1 252 3357 ## 3 3939 1 252 3392 ## 4 3939 1 252 3325 ## 5 3939 1 252 2871 ## 6 3939 1 252 2934 Prenons que les données de la deuxième saison pour l’instant: isit2 &lt;- subset(isit, Season == 2) Commençons par essayer d’ajuster un modèle de régression linéaire à la relation entre Sources et SampleDepth. Nous pouvons utiliser la commande gam() de la librairie mgcv pour modéliser une régression par les moindres carrés. Nous verrons plus loin comment utiliser gam() pour spécifier un terme lissé et non linéaire. linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2) summary(linear_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ SampleDepth ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 30.9021874 0.7963891 38.80 &lt;2e-16 *** ## SampleDepth -0.0083450 0.0003283 -25.42 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## R-sq.(adj) = 0.588 Deviance explained = 58.9% ## GCV = 60.19 Scale est. = 59.924 n = 453 Le modèle linéaire explique une bonne partie de la variance de notre jeu de données (\\(R_{adj}\\) = 0.588), ce qui veut dire que notre modèle est super bon, non? Voyons comment notre modèle cadre avec les données: data_plot &lt;- ggplot(data = isit2, aes(y = Sources, x = SampleDepth)) + geom_point() + geom_line(aes(y = fitted(linear_model)), colour = &quot;red&quot;, size = 1.2) + theme_bw() data_plot Les suppositions de la régression linéaire énumérées dans le Chapitre 4 sont-elles satisfaites dans ce cas? Comme vous l’avez peut-être remarqué, nous ne respectons pas les conditions du modèle linéaire: Il existe une forte relation non linéaire entre Sources et SampleDepth. L’erreur n’est pas normalement distribuée. La variance de l’erreur n’est pas homoscédastique. Les erreurs ne sont pas indépendantes les unes des autres. Comme nous l’avons brièvement mentionné au Chapitre 2, nous pouvons spécifier manuellement un modèle linéaire avec plusieurs variables prédicteurs pour essayer de prendre en compte cette réponse non linéaire. Par exemple, nous pourrions essayer de construire ce modèle linéaire avec plusieurs prédicteurs: \\[y_i = \\beta_0 + \\beta_1(x_{1,i}) + \\beta_2(x_{2,i}) + ... + \\epsilon\\] Cependant, l’ajustement de ce modèle serait déterminé manuellement sur la base de décisions prises lors de la modélisation, et deviendrait rapidement difficile à utiliser. Un des grands avantages d’utiliser un GAM est que la forme optimale de la non-linéarité, i.e. le degré de lissage de \\(f(x)\\) est contrôlée en utilisant une régression pénalisée qui est déterminée automatiquement est déterminée automatiquement selon la méthode d’ajustement (généralement le maximum de vraisemblance ou maximum likelihood). Nous reviendrons sur ceci un peu plus tard, mais brièvement, les GAMs sont une forme non paramétrique de la régression où le \\(\\beta x_i\\) d’une régression linéaire est remplacé par une fonction de lissage des variables explicatives, \\(f(x_i)\\), et le modèle devient : \\[y_i = f(x_i) + \\epsilon_i\\] où \\(y_i\\) est la variable réponse, \\(x_i\\) est la covariable, et \\(f\\) est la fonction lissage. Étant donné que la fonction de lissage \\(f(x_i)\\) est non linéaire et locale, l’ampleur de l’effet de la variable explicative peut varier en fonction de la relation entre la variable et la réponse. Autrement dit, contrairement à un coefficient fixe \\(\\beta x_i\\), la fonction \\(f\\) peut changer tout au long du gradient \\(x_i\\). Le degré de lissage de \\(f\\) est contrôlée en utilisant une régression pénalisée qui est déterminée automatiquement à l’aide d’une méthode de validation croisée généralisée (GCV) de la librairie mgcv (Wood 2006). Nous pouvons essayer de construire un modèle plus approprié en ajustant les données avec un terme lissé (non-linéaire). Dans mgcv::gam(), les termes lissés sont spécifiés par des expressions de la forme s(x), où \\(x\\) est la variable prédictive non linéaire que nous voulons lisser. Dans ce cas, nous voulons appliquer une fonction de lissage à SampleDepth. gam_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2) summary(gam_model) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(SampleDepth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.8937 0.2471 52.17 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.908 8.998 214.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.81 Deviance explained = 81.4% ## GCV = 28.287 Scale est. = 27.669 n = 453 La variance expliquée par notre modèle a augmenté de plus de 20% (\\(R_{adj}\\) = 0.81)! Lorsque nous comparons l’ajustement des modèles linéaire (rouge) et non linéaire (bleu), il est clair que ce dernier cadre mieux avec nos données: data_plot &lt;- data_plot + geom_line(aes(y = fitted(gam_model)), colour = &quot;blue&quot;, size = 1.2) data_plot Rappel: Contrairement à un coefficient fixe \\(\\beta\\), la fonction de lissage peut changer tout au long du gradient \\(x\\). La librairie mgcv comprend également une fonction plot qui, par défaut, nous permet de visualiser la non-linéarité du modèle. plot(gam_model) 4.1 Test de linéarité Comment tester si le modèle non linéaire offre une amélioration significative par rapport au modèle linéaire? On peut utiliser gam() et AIC() pour tester si une supposition de linéarité est justifiée. Pour ceci, on peut comparer la performance d’un modèle linéaire contenant x comme prédicteur linéaire à la performance d’un modèle non linéaire contenant s(x) comme prédicteur lisse. En d’autres termes, on demande si l’ajout d’une fonction lisse au modèle linéaire améliore l’ajustement du modèle à nos données. Comment utilisons-nous les GAMs pour savoir si un modèle linéaire est suffisant pour modéliser nos données? linear_model &lt;- gam(Sources ~ SampleDepth, data = isit2) smooth_model &lt;- gam(Sources ~ s(SampleDepth), data = isit2) AIC(linear_model, smooth_model) ## df AIC ## linear_model 3.00000 3143.720 ## smooth_model 10.90825 2801.451 Ici, l’AIC du GAM lissé est plus bas, ce qui indique que l’ajout d’une fonction de lissage améliore la performance du modèle. La linéarité n’est donc pas soutenue par nos données. Pour expliquer brièvement, le critère d’information d’Akaike (AIC) est une mesure comparative de la performance d’un modèle, où des valeurs plus basses indiquent qu’un modèle est “plus performant” par rapport aux autres modèles considérés. 4.2 Défi 1 Essayons maintenant de déterminer si les données enregistrées lors de la première saison doivent être modélisées par une régression linéaire ou par un modèle additif. Répétons le test de comparaison avec gam() et AIC() en utilisant les données de la première saison seulement: isit1 &lt;- subset(isit, Season == 1) Ajustez un modèle linéaire et un GAM à la relation entre Sources et SampleDepth. Déterminez si l’hypothèse de linéarité est justifiée pour ces données. Quels sont les degrés de liberté effectifs du terme non-linéaire? Nous n’avons pas encore discuté des degrés de liberté effectifs (EDF), mais ils sont un outil clé pour nous aider à interpréter l’ajustement d’un GAM. Gardez ce terme en tête. Plus sur ce sujet dans les prochaines sections! 4.2.1 Défi 1: Solution 1. Ajustez un modèle linéaire et un GAM à la relation entre Sources et SampleDepth. linear_model_s1 &lt;- gam(Sources ~ SampleDepth, data = isit1) smooth_model_s1 &lt;- gam(Sources ~ s(SampleDepth), data = isit1) 2. Déterminez si l’hypothèse de linéarité est justifiée pour ces données. Comme ci-dessus, la visualisation de la courbe du modèle sur notre ensemble de données est une excellente première étape pour déterminer si notre modèle est bien conçu. ggplot(isit1, aes(x = SampleDepth, y = Sources)) + geom_point() + geom_line(colour = &quot;red&quot;, size = 1.2, aes(y = fitted(linear_model_s1))) + geom_line(colour = &quot;blue&quot;, size = 1.2, aes(y = fitted(smooth_model_s1))) + theme_bw() On peut compléter cela par une comparaison quantitative des performances du modèle en utilisant AIC(). AIC(linear_model_s1, smooth_model_s1) ## df AIC ## linear_model_s1 3.000000 2324.905 ## smooth_model_s1 9.644938 2121.249 Le score AIC moins élevé indique que le modèle lissé est plus performant que le modèle linéaire, ce qui confirme que la linéarité n’est pas appropriée pour notre ensemble de données. 3. Quels sont les degrés de liberté effectifs du terme non-linéaire? Pour obtenir les degrés de liberté effectifs, il suffit d’imprimer notre objet du modèle: smooth_model_s1 ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(SampleDepth) ## ## Estimated degrees of freedom: ## 7.64 total = 8.64 ## ## GCV score: 32.13946 Les degrés de liberté effectifs (EDF) sont &gt;&gt; 1. Gardez cela à l’esprit, car nous reviendrons bientôt sur ceux-ci! Réferences "],["fonctionnement.html", "Chapitre 5 Le fonctionnement des GAMs 5.1 Exemple: une base polynomiale 5.2 Exemple: une base de spline cubique", " Chapitre 5 Le fonctionnement des GAMs Nous allons maintenant prendre quelques minutes pour regarder comment fonctionnent les GAMs. Commençons en considérant d’abord un modèle qui contient une fonction lisse \\(f\\) d’une covariable, \\(x\\) : \\[y_i = f(x_i) + \\epsilon_i\\] Pour estimer la fonction \\(f\\), nous avons besoin de représenter l’équation ci-dessus de manière à ce qu’elle devienne un modèle linéaire. Cela peut être fait en définissant des fonctions de base, \\(b_j(x)\\), dont est composée \\(f\\) : \\[f(x) = \\sum_{j=1}^q b_j(x) \\times \\beta_j\\] 5.1 Exemple: une base polynomiale Supposons que \\(f\\) est considérée comme un polynôme d’ordre 4, de sorte que l’espace des polynômes d’ordre 4 et moins contient \\(f\\). Une base de cet espace serait alors : \\[b_0(x)=1 \\ , \\quad b_1(x)=x \\ , \\quad b_2(x)=x^2 \\ , \\quad b_3(x)=x^3 \\ , \\quad b_4(x)=x^4\\] Alors \\(f(x)\\) devient : \\[f(x) = \\beta_0 + x\\beta_1 + x^2\\beta_2 + x^3\\beta_3 + x^4\\beta_4\\] .. et le modèle complet devient : \\[y_i = \\beta_0 + x_i\\beta_1 + x^2_i\\beta_2 + x^3_i\\beta_3 + x^4_i\\beta_4 + \\epsilon_i\\] Chaque fonction de base est multipliée par un paramètre à valeur réelle, \\(\\beta_j\\), et est ensuite additionnée pour donner la courbe finale \\(f(x)\\). En faisant varier le coefficient \\(\\beta_j\\), on peut faire varier la forme de \\(f(x)\\) pour produire une fonction polynomiale d’ordre 4 ou moins. 5.2 Exemple: une base de spline cubique Un spline cubique est une courbe construite à partir de sections d’un polynôme cubique reliées entre elles de sorte qu’elles sont continues en valeur. Chaque section du spline a des coefficients différents. Voici une représentation d’une fonction lisse utilisant une base de régression spline cubique de rang 5 avec des nœuds situés à incréments de 0.2: Dans cet exemple, les nœuds sont espacés uniformément à travers la gamme des valeurs observées de x. Le choix du degré de finesse du modèle est pré-déterminé par le nombre de nœuds, qui était arbitraire. Y a-t-il une meilleure façon de sélectionner les emplacements des nœuds? 5.2.1 Contrôler le degré de lissage avec des splines de régression pénalisés Au lieu de contrôler le lissage (donc, la non linéarité de la courbe) en modifiant le nombre de nœuds, nous gardons celui-ci fixé à une taille un peu plus grande que raisonnablement nécessaire et on contrôle le lissage du modèle en ajoutant une pénalité sur le niveau de courbure. Donc, plutôt que d’ajuster le modèle en minimisant (comme avec la méthode des moindres carrés) : \\[||y - XB||^{2}\\] Le modèle peut être ajusté en minimisant : \\[||y - XB||^{2} + \\lambda \\int_0^1[f^{&#39;&#39;}(x)]^2dx\\] Quand \\(\\lambda\\) tend vers \\(\\infty\\), le modèle devient linéaire. Si \\(\\lambda\\) est trop élevé, les données seront trop lissées et si elle est trop faible, les données ne seront pas assez lissées. Idéalement, il serait bon de choisir une valeur \\(\\lambda\\) de sorte que le \\(\\hat{f}\\) prédit est aussi proche que possible du \\(f\\) observé. Un critère approprié pourrait être de choisir \\(\\lambda\\) pour minimiser : \\[M = 1/n \\times \\sum_{i=1}^n (\\hat{f_i} - f_i)^2\\] Étant donné que \\(f\\) est inconnue, \\(M\\) doit être estimé. Les méthodes recommandées pour ce faire sont le maximum de vraisemblance (maximum likelihood, ML) ou l’estimation par maximum de vraisemblance restreint (restricted maximum likelihood, REML). La validation croisée généralisée (GCV) est une autre possibilité. Il s’agit d’une technique qui élimine tour à tour chaque donnée des données et considère la capacité prédictive moyenne des modèles adaptés aux données restantes pour prédire la donnée éliminée. Pour plus de détails sur ces méthodes, voir (Wood 2006). Le principe de validation croisée Dans le premier panneau, la courbe correspond à un ajustement faible par rapport aux données et ne fait pas mieux avec le point manquant. Dans le troisième panneau, la courbe ajuste le bruit aussi bien que le signal et la variabilité supplémentaire induite l’amène à prédire la donnée manquante plutôt mal. Dans le deuxième panneau, cependant, nous voyons que l’ajustement de la courbe du signal sous-jacent est très bien, le lissage passe à travers le bruit et la donnée manquante est raisonnablement bien prédite. Dans le premier panneau, \\(\\lambda\\) est trop élevé, et la courbe est trop lissée. Ici, la courbe est mal ajustée aux données et prédit donc très difficilement le point manquant. Dans le troisième panneau, \\(\\lambda\\) est trop élevé, et la courbe est surajustée. Ici, la courbe s’ajuste très étroitement aux données, suivant le signal aussi bien que le bruit qui l’entoure. L’influence de cette variabilité supplémentaire (non informative) fait que le modèle prédit difficilement la donnée manquante. Dans le deuxième panneau, \\(\\lambda\\) est à peu près parfait. La courbe s’ajuste assez bien au signal sous-jacent, tout en lissant le bruit. La donnée manquante est raisonnablement bien prédite. Réferences "],["gam-avec-plusieurs-termes-non-linéaires.html", "Chapitre 6 GAM avec plusieurs termes non-linéaires 6.1 GAM à plusieurs variables 6.2 Degrés de liberté effectifs (edf) 6.3 GAM à plusieurs variables linéaires et lisses 6.4 GAM à plusieurs variables 6.5 Défi 2", " Chapitre 6 GAM avec plusieurs termes non-linéaires 6.1 GAM à plusieurs variables Avec les GAMs, il est facile d’ajouter des termes non-linéaires et linéaires dans un seul modèle, plusieurs termes non-linéaires ou même des interactions non-linéaires. Dans cette section, nous allons utiliser les données de ISIT de nouveau. Nous allons essayer de modéliser la réponse Sources avec les prédicteurs Season and SampleDepth simultanément. Rappelez-vous de ce jeu de données présenté dans les sections précédentes? Le jeu de données ISIT est composé des niveaux de bioluminescence (Sources) en fonction de la profondeur, des saisons et des différentes stations. Tout d’abord, nous devons convertir notre prédicteur qualitatif (Season) en facteur. head(isit) ## SampleDepth Sources Station Time Latitude Longitude Xkm Ykm Month Year ## 1 517 28.73 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 2 582 27.90 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 3 547 23.44 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 4 614 18.33 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 5 1068 12.38 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## 6 1005 11.23 1 3 50.1508 -14.4792 -34.106 16.779 4 2001 ## BottomDepth Season Discovery RelativeDepth ## 1 3939 1 252 3422 ## 2 3939 1 252 3357 ## 3 3939 1 252 3392 ## 4 3939 1 252 3325 ## 5 3939 1 252 2871 ## 6 3939 1 252 2934 isit$Season &lt;- as.factor(isit$Season) Commençons par un modèle de base comprenant un terme non-linéaire (SampleDepth) et un facteur qualitatif (Season avec 2 niveaux). basic_model &lt;- gam(Sources ~ Season + s(SampleDepth), data = isit, method = &quot;REML&quot;) basic_summary &lt;- summary(basic_model) La sortie de p.table donne des informations sur les termes paramétriques : basic_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.253273 0.3612666 20.07734 1.430234e-72 ## Season2 6.156130 0.4825491 12.75752 5.525673e-34 Le tableau s.table nous donne donne des informations sur le terme non-linéaire : basic_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.706426 8.975172 184.3583 0 Les edf indiqués dans le s.table sont les degrés effectifs de liberté (EDF) du terme lisse s(SampleDepth). Plus le nombre de degrés de liberté est élevé, plus les splines sont complexes et ondulées. Lorsqu’un terme a une valeur EDF proche de 1, il est sur le point d’être un terme linéaire. Des valeurs plus élevées indiquent que la courbe spline du terme est plus ondulée, ou en d’autres termes, fortement non-linéaire. Dans notre modèle de base, les EDF de la fonction lisse s(SampleDepth) sont ~9, ce qui suggère une courbe fortement non-linéaire. Traçons les termes lissés (s(SampleDepth)) et linéaires (Season) de notre modèle ajusté: plot(basic_model, all.terms = TRUE, page = 1) Que nous montrent ces graphiques sur la relation entre la bioluminescence, la profondeur de l’échantillon et les saisons? La bioluminescence varie de manière non-linéaire sur le gradient SampleDepth, avec des niveaux de bioluminescence les plus élevés à la surface, suivis d’un second maximum plus petit, juste au-dessus d’une profondeur de 1500, avec des niveaux décroissants à des profondeurs plus basses. Il y a également une différence prononcée dans la bioluminescence entre les saisons, avec des niveaux élevés pendant la saison 2, par rapport à la saison 1. 6.2 Degrés de liberté effectifs (edf) Revenons sur le concept de degrés de liberté effectifs (EDF). Les degrés de liberté effectifs nous donnent beaucoup d’informations sur la relation entre les prédicteurs du modèle et les variables de réponse. Vous reconnaissez peut-être le terme “degrés de liberté” suite à des ateliers précédents sur les modèles linéaires, mais attention ! Les degrés de liberté effectifs d’un GAM sont estimés différemment des degrés de liberté d’une régression linéaire, et sont interprétés différemment. Dans la régression linéaire, les degrés de liberté du modèle sont équivalents au nombre de paramètres libres non redondants, \\(p\\), dans le modèle (et les degrés de liberté résiduels sont égaux à \\(n-p\\)). Parce que le nombre de paramètres libres des splines de lissage (tel que les GAMs) est souvent difficile à définir, les EDF sont liés à \\(\\lambda\\), où l’effet de la pénalité est de réduire les degrés de liberté. La limite supérieure d’EDF est déterminée par les dimensions de base \\(k\\) de la fonction lisse (les EDF ne peut pas dépasser \\(k-1\\)) En pratique, le choix exact de \\(k\\) est arbitraire, mais il devrait être suffisamment grand pour permettre une fonction lisse suffisamment complexe. Nous discuterons du choix de \\(k\\) dans la section [SECTION HERE]. Des EDF plus élevés impliquent des splines plus complexes et plus ondulées. Lorsqu’un terme a une valeur EDF proche de 1, il est sur le point d’être un terme linéaire. Des valeurs plus élevées indiquent que le terme est plus ondulé, ou en d’autres termes, plus non-linéaire! 6.3 GAM à plusieurs variables linéaires et lisses Nous pouvons ajouter un second terme, RelativeDepth, mais spécifier une relation linéaire avec Sources. two_term_model &lt;- gam(Sources ~ Season + s(SampleDepth) + RelativeDepth, data = isit, method = &quot;REML&quot;) two_term_summary &lt;- summary(two_term_model) L’estimation du coefficient de régression pour ce nouveau terme linéaire, RelativeDepth, sera présenté dans le tableau p.table. Rappelez-vous, le tableau p.table montre des informations sur les effets paramétriques (termes linéaires) : two_term_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.808305503 0.6478741951 15.139213 1.446613e-45 ## Season2 6.041930627 0.4767977508 12.671894 1.380010e-33 ## RelativeDepth -0.001401908 0.0002968443 -4.722705 2.761048e-06 Dans s.table, nous trouverons encore une fois le terme non-linéaire, s(SampleDepth), et son paramètre de courbure (edf). Rappelez-vous, le tableau s.table montre des informations sur les effets additifs (termes non-linéaires): two_term_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.699146 8.97396 132.4801 0 Regardons les relations entre les prédicteurs linéaires et non-linéaires et notre variable réponse. plot(two_term_model, page = 1, all.terms = TRUE) 6.4 GAM à plusieurs variables Si nous voulons vérifier que la relation entre Sources et RelativeDepth est non-linéaire, on peut modéliser RelativeDepth avec une fonction non-linéaire. Dans ce modèle, nous aurions deux termes lisses: two_smooth_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth), data = isit, method = &quot;REML&quot;) two_smooth_summary &lt;- summary(two_smooth_model) L’estimation du coefficient de régression pour le seul terme linéaire, Season, sera présenté dans le tableau p.table. Rappelez-vous, le tableau p.table montre des informations sur les effets paramétriques (termes linéaires) : two_smooth_summary$p.table ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.937755 0.3452945 22.98836 1.888513e-89 ## Season2 4.963951 0.4782280 10.37988 1.029016e-23 Dans s.table, nous trouverons maintenant deux termes non-linéaires, s(SampleDepth) et s(RelativeDepth), et leurs paramètres de courbure (edf). Rappelez-vous, le tableau s.table montre des informations sur les effets additifs (termes non-linéaires): two_smooth_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.752103 8.973459 150.37263 0 ## s(RelativeDepth) 8.044197 8.749580 19.97476 0 Regardons les relations entre les prédicteurs linéaires et non-linéaires et notre variable réponse. plot(two_smooth_model, page = 1, all.terms = TRUE) Pensez-vous que la performance de notre modèle est amélioré par l’ajout de ce nouveau terme non-linéaire, pour mieux représenter la relation entre la bioluminescence et la profondeur relative? Comme précédemment, nous pouvons comparer nos modèles avec AIC pour tester si le terme non-linéaire améliore la performance de notre modèle: AIC(basic_model, two_term_model, two_smooth_model) ## df AIC ## basic_model 11.83374 5208.713 ## two_term_model 12.82932 5188.780 ## two_smooth_model 20.46960 5056.841 On peut voir que two_smooth_model a la plus petite valeur AIC. Le modèle le mieux ajusté comprend donc deux fonctions non-linéaires pour SampleDepth et RelativeDepth, et un terme linéaire pour Season. 6.5 Défi 2 Pour notre deuxième défi, nous allons développer notre modèle en ajoutant des variables qui, selon nous, pourraient être des prédicteurs écologiquement significatifs pour expliquer la bioluminescence. 1. Créez deux nouveaux modèles: Ajoutez la variable Latitude à two_smooth_model, premièrement comme paramètre linéaire, et ensuite comme fonction non-linéaire. 2. Est-ce que Latitude est un terme important à inclure dans le modèle? La Latitude a-t-elle un effet linéaire ou non-linéaire? Utilisez des graphiques, les tables des coefficients et la fonction AIC() pour répondre à ces questions. 6.5.1 Défi 2: Solution 1. Créez deux nouveaux modèles: Ajoutez la variable Latitude à two_smooth_model, premièrement comme paramètre linéaire, et ensuite comme fonction non-linéaire. # Ajouter Latitude comme terme linéaire three_term_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + Latitude, data = isit, method = &quot;REML&quot;) (three_term_summary &lt;- summary(three_term_model)) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + Latitude ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -102.7094 40.6913 -2.524 0.01180 * ## Season2 6.0345 0.6179 9.766 &lt; 2e-16 *** ## Latitude 2.2188 0.8159 2.719 0.00669 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.750 8.973 92.84 &lt;2e-16 *** ## s(RelativeDepth) 8.047 8.751 16.90 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.75 Deviance explained = 75.6% ## -REML = 2545.7 Scale est. = 34.309 n = 789 # Ajouter Latitude comme terme non-linéaire three_smooth_model &lt;- gam(Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + s(Latitude), data = isit, method = &quot;REML&quot;) (three_smooth_summary &lt;- summary(three_smooth_model)) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ Season + s(SampleDepth) + s(RelativeDepth) + s(Latitude) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.7045 0.4716 14.215 &lt;2e-16 *** ## Season2 7.1120 0.7441 9.557 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(SampleDepth) 8.767 8.976 68.951 &lt;2e-16 *** ## s(RelativeDepth) 8.007 8.731 17.639 &lt;2e-16 *** ## s(Latitude) 7.431 8.297 8.954 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.771 Deviance explained = 77.8% ## -REML = 2524.5 Scale est. = 31.487 n = 789 2. Est-ce que Latitude est un terme important à inclure dans le modèle? La Latitude a-t-elle un effet linéaire ou non-linéaire? Commençons par visualiser les 4 effets qui sont maintenant inclus dans chaque modèle: plot(three_term_model, page = 1, all.terms = TRUE) plot(three_smooth_model, page = 1, all.terms = TRUE) Nous devrions également examiner nos tableaux de coefficients. Qu’est-ce que les EDF nous disent à propos de l’ondulation, ou la non-linéarité, des effets de nos prédicteurs? three_smooth_summary$s.table ## edf Ref.df F p-value ## s(SampleDepth) 8.766891 8.975682 68.950905 0 ## s(RelativeDepth) 8.007411 8.730625 17.639321 0 ## s(Latitude) 7.431116 8.296838 8.954349 0 Les EDF sont tous élevés pour nos variables, y compris Latitude. Cela nous indique que Latitude est assez ondulée, et qu’elle ne devrait probablement pas être incluse comme terme linéaire. Avant de décider quel modèle est le “meilleur”, nous devrions tester si l’effet Latitude est plus approprié comme terme linéaire ou lisse, en utilisant AIC(): AIC(three_smooth_model, three_term_model) ## df AIC ## three_smooth_model 28.20032 4990.546 ## three_term_model 21.47683 5051.415 Notre modèle incluant la Latitude comme terme non-linéaire a un score AIC inférieur, ce qui signifie qu’il est plus performant que notre modèle incluant la Latitude comme terme linéaire. Mais, est-ce que l’ajout de Latitude comme prédicteur non-linéaire améliore réellement notre “meilleur” modèle (two_smooth_model)? AIC(two_smooth_model, three_smooth_model) ## df AIC ## two_smooth_model 20.46960 5056.841 ## three_smooth_model 28.20032 4990.546 Notre three_smooth_model, qui inclut SampleDepth, RelativeDepth, et Latitude comme termes lisses, et Season comme terme linéaire, a un score AIC inférieur à notre meilleur modèle précédent (two_smooth_model), qui n’incluait pas Latitude. Ceci implique que Latitude est en effet un prédicteur informatif non-linéaire de la bioluminescence. "],["interactions.html", "Chapitre 7 Interactions", " Chapitre 7 Interactions Il y a deux façons de modéliser une interaction entre deux variables: si une variable est quantitative et l’autre est qualitative, on utilise l’argument by → s(x, by=facteur), si les deux variables sont quantitatives, on inclut les deux termes sous une même fonction non linéaire → s(x1, x2). L’argument by permet de faire varier un terme non linéaire selon les différents niveaux d’un facteur. Nous allons examiner ceci en utilisant notre variable qualitative x0 et examiner si la non-linérité de s(x2) varie selon les différents niveaux de x0. Pour déterminer si les courbes diffèrent significativement entre les niveaux du facteur, nous allons utiliser une ANOVA sur l’interaction. categorical_interact &lt;- gam(y ~ x0 + s(x1) + s(x2, by = x0), data = gam_data) categorical_interact_summary &lt;- summary(categorical_interact) print(categorical_interact_summary$s.table) plot(categorical_interact, page = 1) # ou nous pouvons utiliser la fonction vis.gam où theta # représente la rotation du plan x-y vis.gam(categorical_interact, view = c(&quot;x2&quot;, &quot;x0&quot;), theta = 40, n.grid = 500, border = NA) anova(two_smooth_model, categorical_interact, test = &quot;Chisq&quot;) Nous pouvons constater à partir du graphique que les formes des termes non linéaires sont comparables entre les quatre niveaux de x0. L’ANOVA le confirme également (déviance = 98,6, p = 0,2347). Ensuite, nous allons examiner l’interaction non linéaire entre deux termes quantitatifs, x1 et x2. Cette fois-ci, l’argument by est supprimé. smooth_interact &lt;- gam(y ~ x0 + s(x1, x2), data = gam_data) smooth_interact_summary &lt;- summary(smooth_interact) print(smooth_interact_summary$s.table) plot(smooth_interact, page = 1, scheme = 3) # plot(smooth_interact,page=1,scheme=1) donne un graphique # comparable à vis.gam() vis.gam(smooth_interact, view = c(&quot;x1&quot;, &quot;x2&quot;), theta = 40, n.grid = 500, border = NA) anova(two_smooth_model, smooth_interact, test = &quot;Chisq&quot;) L’interaction entre s(x1) et s(x2) est significative et le graphique en deux dimensions illustre très bien cette interaction non linéaire. La relation entre y et x1 change en fonction de la valeur de x2. Vous pouvez changez la valeur de l’argument theta pour tourner l’axe du graphique. Si vous prévoyez exécuter un grand nombre de graphiques, supprimez l’argument n.grid = 500, car ceci fait appel à des calculs intensifs et ralentit R. "],["changer-la-fonction-de-base.html", "Chapitre 8 Changer la fonction de base", " Chapitre 8 Changer la fonction de base Sans entrer dans le détail, sachez qu’il est possible de modifier le modèle de base que nous avons vu avec : des fonctions plus complexes en modifiant la fonction de base (par exemple, cyclique), d’autres distributions : tout ce que vous pouvez faire avec un GLM (tel que spécifier l’argument family) est possible avec les GAMs, des modèles à effets mixtes en utilisant la fonction gamm ou la fonction gamm4 de la librairie gamm4. Nous allons d’abord jeter un coup d’œil au changement de la fonction de base puis une introduction rapide aux autres distributions et les GAMMs (modèles additifs généralisés à effets mixtes) suivra. Commençons par regarder un cas où modifier la fonction de base peut être utile, soit avec des données cycliques. Imaginez que vous avez une série temporelle de données climatiques, divisées en mesures mensuelles, et que vous voulez déterminer s’il y a une tendance de température annuelle. Nous allons utiliser la série temporelle de température de Nottingham pour cette section : data(nottem) n_years &lt;- length(nottem)/12 nottem_month &lt;- rep(1:12, times = n_years) nottem_year &lt;- rep(1920:(1920 + n_years - 1), each = 12) nottem_plot &lt;- qplot(nottem_month, nottem, colour = factor(nottem_year), geom = &quot;line&quot;) + theme_bw() print(nottem_plot) En utilisant les données nottem, nous avons créé trois nouveaux vecteurs ; n_years correspond au nombre d’années de données (20 ans), nottem_month est un codage qualitatif pour les 12 mois de l’année, pour chaque année échantillonnée (série de 1 à 12, répétée 20 fois) et nottem_year est une variable où l’année correspondant à chaque mois est fournie. Données mensuelles des années 1920 à 1940: Pour modéliser cela, nous devons utiliser ce qu’on appelle un spline cubique cyclique, ou \"cc\", pour modéliser les effets du mois et de l’année. year_gam &lt;- gam(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;)) summary(year_gam)$s.table plot(year_gam, page = 1, scale = 0) Il y a une hausse d’environ 1 - 1,5ºC au cours de la série, mais au cours d’une année, il y a une variation d’environ 20ºC. Les données réelles varient autour de ces valeurs prédites et ceci représente donc la variance inexpliquée. Ici, nous pouvons voir l’un des avantages très intéressants de l’utilisation des GAMs. Nous pouvons soit tracer la surface réponse (valeurs prédites) ou les termes (contribution de chaque covariable) tel qu’indiqué ci-haut. Vous pouvez imaginer ce dernier en tant qu’une illustration de la variation des coefficients de régression et comment leur contribution (ou taille de leur effet) varie au fil du temps. Dans le premier graphique, nous voyons que les contributions positives de la température sont survenues après 1930. Sur des échelles de temps plus longues, en utilisant par exemple des données paléolimnologiques, d’autres (Simpson &amp; Anderson 2009;. Fig 3c) ont utilisé des GAMs pour tracer la contribution (effet) de la température sur la composition d’algues dans les lacs afin d’illustrer comment les contributions significatives ont seulement eu lieu au cours de deux périodes extrêmement froides (c’est-à-dire, la contribution est importante lorsque les intervalles de confiance ne recoupent pas la valeur de zéro à environ 300 et 100 ans AVJC). Cela a permis aux auteurs de non seulement déterminer combien de variance est expliquée par la température au cours des derniers siècles, mais aussi de repérer dans le temps cet effet significatif. Si cela vous intéresse, le code pour tracer soit la surface de réponse (type = \"response\") ou les termes (type = \"terms\") est disponible ci-dessous. Lorsque les termes sont sélectionnés, vous obtiendrez la même figure que celle ci-dessus. Graphique de contribution vs réponse ajustée: pred &lt;- predict(year_gam, type = &quot;terms&quot;, se = TRUE) I &lt;- order(nottem_year) plusCI &lt;- I(pred$fit[, 1] + 1.96 * pred$se[, 1]) minusCI &lt;- I(pred$fit[, 1] - 1.96 * pred$se[, 1]) xx &lt;- c(nottem_year[I], rev(nottem_year[I])) yy &lt;- c(plusCI[I], rev(minusCI[I])) plot(xx, yy, type = &quot;n&quot;, cex.axis = 1.2) polygon(xx, yy, col = &quot;light grey&quot;, border = &quot;light grey&quot;) lines(nottem_year[I], pred$fit[, 1][I], lty = 1) abline(h = 0) "],["autres-distributions.html", "Chapitre 9 Autres distributions 9.1 Visualiser la tendance au fil du temps", " Chapitre 9 Autres distributions Pour vous donner un bref aperçu de l’utilisation des GAMs lorsque la variable réponse ne suit pas une distribution normale ou que les données sont des abondances ou proportions (par exemple, distribution Gamma, binomiale, Poisson, binomiale négative), l’exemple qui suit utilise un ensemble de données où une répartition binomiale sera nécessaire, y compris une modélisation d’une relation non linéaire. La variable réponse représente le nombre de succès (l’événement a eu lieu) en fonction des défaillances au cours d’une expérience. gam_data3 &lt;- read.csv(&quot;other_dist.csv&quot;) summary(gam_data3) str(gam_data3) &#39;data.frame&#39;: 514 obs. of 4 variables: $ prop : num 1 1 1 1 0 1 1 1 1 1 ... $ total: int 4 20 20 18 18 18 20 20 20 20 ... $ x1 : int 550 650 750 850 950 650 750 850 950 550 ... $ fac : Factor w/ 4 levels &quot;f1&quot;,&quot;f2&quot;,&quot;f3&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... prop est la variable réponse, égal à la proportion de succès / (succès + échecs). Notez qu’il existe de nombreux cas où la proportion est égal à 1 ou 0 qui indique que les résultats ont toujours été des succès ou des échecs, respectivement, à ce moment mesuré durant l’expérience. x1 est le temps écoulé depuis le début de l’expérience (variable explicative). total représente le nombre de succès + échecs observé au moment x1i de l’expérience. fac est un facteur qui code pour l’essai 1 à 4 de l’expérience (nous n’utiliserons pas cette variable dans cette section). Commençons par la visualisation des données. Nous sommes intéressés par le nombre de succès par rapport aux échecs à mesure que x1 augmente. Étant donné qu’il y a des mesures répétées pour la valeur de x1 (essais 1 à 4, avec nombreuses observations par essai), nous pouvons d’abord présenter la proportion de succès en moyenne par boîte de temps (x1): emptyPlot(range(gam_data3$x1), c(0, 1), h = 0.5, main = &quot;Probability of successes&quot;, ylab = &quot;Probability&quot;, xlab = &quot;x1&quot;) avg &lt;- aggregate(prop ~ x1, data = gam_data3, mean, na.rm = TRUE) lines(avg$x1, avg$prop, col = &quot;orange&quot;, lwd = 2) Notez comment la probabilité de succès augmente avec x1. D’après vous, est-ce que cette tendance est linéaire ou non linéaire? Nous allons tester cela en utilisant un GAM logistique (nous utilisons une distribution binomiale puisque la variable réponse représente des proportions). prop_model &lt;- gam(prop ~ s(x1), data = gam_data3, weights = total, family = &quot;binomial&quot;) prop_summary &lt;- summary(prop_model) print(prop_summary$p.table) print(prop_summary$s.table) plot(prop_model) Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 1.173978 0.02709613 43.32641 0 edf Ref.df Chi.sq p-value s(x1) 4.591542 5.615235 798.9407 2.027751e-164 Qu’est-ce que l’ordonnée représente dans ce modèle? Rappel : le modèle utilise le nombre de succès vs échecs pour calculer le logit, qui est le logarithme du rapport entre les succès et échecs: $\\(logit = log(\\frac{N_{success}}{N_{failures}})\\)$ Si succès = échecs, le rapport est de 1 et le logit est 0 (log (1) = 0). Si les succès ont un nombre plus grand que les échecs, le ratio est supérieur à 1 et le logit a une valeur positive (par exemple, log(2) = 0,69). Si les succès ont un nombre plus petit que les échecs, le ratio est inférieur à 1 et le logit a une valeur négative (par exemple, log(0,5) = -0.69). Donc, l’ordonnée est le logit, et indique s’il y a en moyenne plus de succès que d’échecs. Ici, l’estimé est positif ce qui signifie, qu’en moyenne, il n’y a plus de succès que d’échecs. Qu’est-ce que le terme de lissage indique? Ceci représente la façon dont les chances de succès vs échecs changent sur l’échelle de x1 (l’échelle du temps dans cet exemple). Donc, puisque l’edf &gt; 1, la proportion de succès augmente plus rapidement au fil du temps (si par exemple, la réponse représente le nombre d’individus de l’espèce A vs l’espèce B et que nous augmentons la concentration des nutriments au fil du temps, ces résultats indiqueront que l’espèce A est de plus en plus observée alors que les concentrations de nutriments approchent de l’optimum de cette espèce au cours de l’expérience). 9.1 Visualiser la tendance au fil du temps Enfin, nous allons voir les différentes façons de représenter ces relations graphiquement. par(mfrow = c(1, 2)) plot(prop_model, select = 1, scale = 0, shade = TRUE) abline(h = 0) plot_smooth(prop_model, view = &quot;x1&quot;, main = &quot;&quot;) (diff &lt;- find_difference(out$fv$fit, out$fv$CI, xVals = out$fv$x1)) addInterval(0, lowVals = diff$start, highVals = diff$end, col = &quot;red&quot;, lwd = 2) abline(v = c(diff$start, diff$end), lty = 3, col = &quot;red&quot;) text(mean(c(diff$start, diff$end)), 2.1, &quot;sign. more \\n success&quot;, col = &quot;red&quot;, font = 3) Quels renseignements ces graphiques nous apportent-ils vis à vis les succès et échecs ? Graphique de gauche : contribution (ou effet partiel si nous avions plus qu’une variable explicative) au fil du temps. La valeur logit augmente, donc les succès augmentent et les échecs diminuent. Graphique de droite : valeurs ajustées, ordonnée incluse (somme des effets si nous avions plus d’une variable explicative dans le modèle). Nous voyons ici que la valeur logit est estimée près de zéro au début de l’expérience ; cela signifie qu’il y a des quantités égales de succès et d’échecs. Peu à peu, les succès augmentent et à environ x1 = 400 il y a beaucoup plus de succès que d’échecs (l’effet est significativement différent de zéro). Nous avons également montré comment nous pouvons utiliser le graphique pour déterminer à quelle valeur de x1 cela se produit. Enfin, pour nous aider à interpréter les résultats, nous pouvons re-transformer l’effet sur une échelle de proportions avec la fonction plot_smooth de la librairie itsadug: par(mfrow = c(1, 1)) plot_smooth(prop_model, view = &quot;x1&quot;, main = &quot;&quot;, transform = plogis, ylim = c(0, 1)) abline(h = 0.5, v = diff$start, col = &quot;red&quot;, lty = 2) Comme nous l’avons déjà vu avec le graphique précédent des valeurs logits, nous voyons qu’à approximativement x1 = 400 la proportion de succès augmente de façon significative au-dessus de 0,5. "],["intro-rapide-aux-modèles-additifs-généralisés-à-effets-mixtes-gamms.html", "Chapitre 10 Intro rapide aux modèles additifs généralisés à effets mixtes (GAMMs) 10.1 La non-indépendance des données 10.2 Modélisation avec effets mixtes", " Chapitre 10 Intro rapide aux modèles additifs généralisés à effets mixtes (GAMMs) 10.1 La non-indépendance des données Lorsque les observations ne sont pas indépendantes, les GAMs peuvent être utilisés soit pour incorporer: une structure de corrélation pour modéliser les résidus autocorrélés (autorégressif (AR), moyenne mobile (MA), ou une combinaison des deux (ARMA)) des effets aléatoires qui modélisent l’indépendance entre les observations d’un même site. En plus de changer la fonction de base, nous pouvons aussi complexifier le modèle en intégrant une structure d’auto-corrélation (ou même des effets mixtes) en utilisant les fonctions gamm() dans la librairie mgcv. Bien que nous ne l’utilisions pas ici, la librairie gamm4 peut également être utilisé pour estimer des modèles GAMMs dans R. Pour commencer, nous allons jeter un coup d’œil au premier cas ; un modèle avec autocorrélation temporelle dans les résidus. Ré-examinons le modèle de la température de Nottingham; nous allons vérifier si les résidus sont corrélés en faisant appel à la fonction (partielle) d’autocorrélation. par(mfrow = c(1, 2)) acf(resid(year_gam), lag.max = 36, main = &quot;ACF&quot;) pacf(resid(year_gam), lag.max = 36, main = &quot;pACF&quot;) Les graphiques des fonctions d’autocorrélation suggèrent qu’un modèle AR de faible ordre est nécessaire (avec un ou deux intervalles de temps décalés), donc nous pouvons évaluer deux modèles; ajouter un AR(1) ou un AR(2) au modèle de la température de Nottingham et évaluer le meilleur avec une ANOVA. year_gam &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;)) year_gam_AR1 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), correlation = corARMA(form = ~1 | nottem_year, p = 1)) year_gam_AR2 &lt;- gamm(nottem ~ s(nottem_year) + s(nottem_month, bs = &quot;cc&quot;), correlation = corARMA(form = ~1 | nottem_year, p = 2)) anova(year_gam$lme, year_gam_AR1$lme, year_gam_AR2$lme) Model df AIC BIC logLik Test L.Ratio p-value year_gam$lme 1 5 1109.908 1127.311 -549.9538 year_gam_AR1$lme 2 6 1101.218 1122.102 -544.6092 1 vs 2 10.689206 0.0011 year_gam_AR2$lme 3 7 1101.598 1125.962 -543.7988 2 vs 3 1.620821 0.2030 Le modèle avec la structure AR(1) prévoit une augmentation significative comparativement au premier modèle (LRT = 10,69, p = 0,0011), mais il y a très peu d’intérêt à considérer le modèle AR(2) (LRT = 1,62, p = 0,203). 10.2 Modélisation avec effets mixtes Comme nous l’avons vu dans la section précédente, bs spécifie la fonction de base sous-jacente. Pour les facteurs aléatoires (origine et pente linéaire), nous utilisons bs = \"re\" et pour les pentes aléatoires non linéaires, nous utilisons bs = \"fs\". Trois types d’effets aléatoires différents sont possibles lors de l’utilisation des GAMMs (où fac représente une variable qualitative utilisée pou l’effet aléatoire et x0 est un effet quantitatif fixe) : interceptes aléatoires ajustent la hauteur des termes du modèle avec une valeur constante de pente : s(fac, bs=\\\"re\\\") pentes aléatoires ajustent la pente d’une variable explicative numérique: s(fac, x0, bs=\\\"re\\\") surfaces lisses aléatoires ajustent la tendance d’une prédiction numérique de façon non linéaire: s(x0, fac, bs=\\\"fs\\\", m=1) où l’argument m=1 met une plus grande pénalité au lissage qui s’éloigne de 0, ce qui entraîne un retrait vers la moyenne. Nous examinerons d’abord un GAMM avec un interception aléatoire. Tel que vu précédemment, nous allons utiliser gamSim() pour générer un ensemble de données, cette fois-ci avec une composante d’effet aléatoire. Ensuite, nous construirons un modèle avec un intercepte aléatoire en utilisant fac comme facteur aléatoire. # Générez des données gam_data2 &lt;- gamSim(eg = 6) head(gam_data2) # Faites rouler un modèle avec intercepte aléatoire gamm_intercept &lt;- gam(y ~ s(x0) + s(fac, bs = &quot;re&quot;), data = gam_data2) summary(gamm_intercept) Notez le terme aléatoire dans le tableau. Vous pouvez le visualiser: plot(gamm_intercept, select = 2) # select=2 parce que le terme aléatoire se trouve sur la 2e # ligne du tableau sommaire. Une fonction de traçage vraiment intéressante que nous allons maintenant utiliser est le plot_smooth de la librairie itsadug. Contrairement au graphique par défaut plot.gam, cette fonction présente l’effet additionné du GAMM avec l’option de ne pas inclure les courbes aléatoires dans le graphique. Ici, nous allons premièrement tracer l’effet combiné de x0 (sans les niveaux de l’effet aléatoire) et ensuite une courbe pour les quatre niveaux de fac: par(mfrow = c(1, 2), cex = 1.1) plot_smooth(gamm_intercept, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x1)&quot;, rug = FALSE) plot_smooth(gamm_intercept, view = &quot;x0&quot;, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac)&quot;, col = &quot;orange&quot;, ylim = c(8, 21), rug = FALSE) plot_smooth(gamm_intercept, view = &quot;x0&quot;, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_intercept, view = &quot;x0&quot;, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_intercept, view = &quot;x0&quot;, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) Ensuite, nous allons générer et tracer un modèle avec une pente aléatoire : gamm_slope &lt;- gam(y ~ s(x0) + s(x0, fac, bs = &quot;re&quot;), data = gam_data2) summary(gamm_slope) plot_smooth(gamm_slope, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x0)&quot;, rug = FALSE) plot_smooth(gamm_slope, view = &quot;x0&quot;, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac)&quot;, col = &quot;orange&quot;, ylim = c(7, 22), rug = FALSE) plot_smooth(gamm_slope, view = &quot;x0&quot;, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;) plot_smooth(gamm_slope, view = &quot;x0&quot;, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;) plot_smooth(gamm_slope, view = &quot;x0&quot;, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;) Nous allons maintenant inclure à la fois un intercepte et une pente aléatoires. gamm_int_slope &lt;- gam(y ~ s(x0) + s(fac, bs = &quot;re&quot;) + s(fac, x0, bs = &quot;re&quot;), data = gam_data2) summary(gamm_int_slope) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, rm.ranef = TRUE, main = &quot;intercept + s(x0)&quot;, rug = FALSE) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, cond = list(fac = &quot;1&quot;), main = &quot;... + s(fac) + s(fac, x0)&quot;, col = &quot;orange&quot;, ylim = c(7, 22), rug = FALSE) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, cond = list(fac = &quot;2&quot;), add = TRUE, col = &quot;red&quot;, xpd = TRUE) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, cond = list(fac = &quot;3&quot;), add = TRUE, col = &quot;purple&quot;, xpd = TRUE) plot_smooth(gamm_int_slope, view = &quot;x0&quot;, cond = list(fac = &quot;4&quot;), add = TRUE, col = &quot;turquoise&quot;, xpd = TRUE) Notez que les pentes aléatoires sont statique : plot(gamm_int_slope, select = 3) # select=3 parce que la pente aléatoire se trouve sur la 3e # ligne du tableau sommaire. Enfin, nous allons examiner un modèle avec une surface lisse aléatoire. gamm_smooth &lt;- gam(y ~ s(x0) + s(x0, fac, bs = &quot;fs&quot;, m = 1), data = gam_data2) summary(gamm_smooth) Ici, si les pentes aléatoires variaient selon x0, nous auront vue des courbe variable pour chaque niveau : plot(gamm_smooth, select = 1) # select=1 parce que le terme se trouve sur la 1e ligne du # tableau sommaire. Finalement, tous ces modèles mixes peuvent être compare en utilisant la fonction anova() pour trouver le meilleur modèle. "],["ressources.html", "Chapitre 11 Ressources", " Chapitre 11 Ressources Cet atelier présente une brève introduction aux concepts de base et aux packages populaires pour vous aider à estimer, évaluer et visualiser les GAMs dans R, mais les GAMs offrent bien d’autres possibilités! Nous avons quelques ressources à vous suggérer si vous souhaitez approfondir le sujet des GAMs et comment les implémenter dans R. Beaucoup de ces ressources ont inspiré et contribué au contenu de cet atelier. Il ne s’agit pas d’une liste exhaustive, mais de quelques pistes très utiles. Le livre Generalized Additive Models: An Introduction with R de Simon Wood (l’auteur du paquet mgcv) est probablement la ressource la plus complète que vous pouvez trouver sur les GAMs. Le blogue de Gavin Simpson, From the bottom of the heap, discute de nombreux aspects des GAMs et de leur implémentation dans R. Le paquet de Gavin Simpson, gratia, est une réimplémentation utile des outils de visualisation des GAMs dans ggplot2. Generalized Additive Models: An Introduction with R par Noam Ross est un cours bien conçu, interactif et gratuit qui couvre les GAMs plus en détail. Overview GAMM analysis of time series data par Jacolien van Rij est un tutoriel utile et approfondi sur les GAMM qui a largement inspiré la section GAMM de cet atelier. Simon Wood catalogue également des conférences et des notes sur les GAMM sur son site Web (maths.ed.ac.uk/~swood34/). Hierarchical generalized additive models in ecology: an introduction with mgcv de Pedersen et al. (2019) est une excellente introduction aux GAM hiérarchiques, à la façon de les concevoir et à leur mise en œuvre dans R. Enfin, les pages d’aide, disponibles via ?gam dans R, constituent toujours une excellente ressource. "],["réferences.html", "Chapitre 12 Réferences", " Chapitre 12 Réferences "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
